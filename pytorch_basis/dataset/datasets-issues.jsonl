{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6938","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6938\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6938\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6938\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6938","id":2327568281,"node_id":"PR_kwDODunzps5xHNKm","number":6938,"title":"Fix expected splits when passing data_files or dir","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-05-31T11:04:22Z","updated_at":"2024-05-31T11:10:51Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6938","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6938","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6938.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6938.patch","merged_at":null},"body":"reported on slack:\r\n\r\nThe following code snippet gives an error with v2.19 but not with v2.18:\r\nfrom datasets import load_dataset\r\n```\r\ndataset = load_dataset(\r\n    \"lvwerra\/stack-exchange-paired\",\r\n    split=\"train\",\r\n    cache_dir=None,\r\n    data_dir=\"data\/rl\",\r\n)\r\n```\r\nand the error is:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/load.py\", line 2609, in load_dataset\r\n    builder_instance.download_and_prepare(\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1027, in download_and_prepare\r\n    self._download_and_prepare(\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1140, in _download_and_prepare\r\n    verify_splits(self.info.splits, split_dict)\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/utils\/info_utils.py\", line 92, in verify_splits\r\n    raise ExpectedMoreSplits(str(set(expected_splits) - set(recorded_splits)))\r\ndatasets.utils.info_utils.ExpectedMoreSplits: {'test'}\r\n```\r\n","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6938\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6938\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6937","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6937\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6937\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6937\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6937","id":2327212611,"node_id":"I_kwDODunzps6KtnJD","number":6937,"title":"JSON loader implicitly coerces floats to integers","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-31T08:09:12Z","updated_at":"2024-05-31T08:11:57Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"The JSON loader implicitly coerces floats to integers.\r\n\r\nThe column values `[0.0, 1.0, 2.0]` are coerced to `[0, 1, 2]`.\r\nSee CI error in dataset-viewer: https:\/\/github.com\/huggingface\/dataset-viewer\/actions\/runs\/9290164936\/job\/25576926446\r\n```\r\n =================================== FAILURES ===================================\r\n___________________________ test_statistics_endpoint ___________________________\r\n\r\nnormal_user_public_json_dataset = 'DVUser\/tmp-dataset-17170199043860'\r\n\r\n    def test_statistics_endpoint(normal_user_public_json_dataset: str) -> None:\r\n        dataset = normal_user_public_json_dataset\r\n        config, split = get_default_config_split()\r\n        statistics_response = poll_until_ready_and_assert(\r\n            relative_url=f\"\/statistics?dataset={dataset}&config={config}&split={split}\",\r\n            check_x_revision=True,\r\n            dataset=dataset,\r\n        )\r\n    \r\n        content = statistics_response.json()\r\n        assert len(content) == 3\r\n        assert sorted(content) == [\"num_examples\", \"partial\", \"statistics\"], statistics_response\r\n        statistics = content[\"statistics\"]\r\n        num_examples = content[\"num_examples\"]\r\n        partial = content[\"partial\"]\r\n    \r\n        assert isinstance(statistics, list), statistics\r\n        assert len(statistics) == 6\r\n        assert num_examples == 4\r\n        assert partial is False\r\n    \r\n        string_label_column = statistics[0]\r\n        assert \"column_name\" in string_label_column\r\n        assert \"column_statistics\" in string_label_column\r\n        assert \"column_type\" in string_label_column\r\n        assert string_label_column[\"column_name\"] == \"col_1\"\r\n        assert string_label_column[\"column_type\"] == \"string_label\"  # 4 unique values -> label\r\n        assert isinstance(string_label_column[\"column_statistics\"], dict)\r\n        assert string_label_column[\"column_statistics\"] == {\r\n            \"nan_count\": 0,\r\n            \"nan_proportion\": 0.0,\r\n            \"no_label_count\": 0,\r\n            \"no_label_proportion\": 0.0,\r\n            \"n_unique\": 4,\r\n            \"frequencies\": {\r\n                \"There goes another one.\": 1,\r\n                \"Vader turns round and round in circles as his ship spins into space.\": 1,\r\n                \"We count thirty Rebel ships, Lord Vader.\": 1,\r\n                \"The wingman spots the pirateship coming at him and warns the Dark Lord\": 1,\r\n            },\r\n        }\r\n    \r\n        int_column = statistics[1]\r\n        assert \"column_name\" in int_column\r\n        assert \"column_statistics\" in int_column\r\n        assert \"column_type\" in int_column\r\n        assert int_column[\"column_name\"] == \"col_2\"\r\n        assert int_column[\"column_type\"] == \"int\"\r\n        assert isinstance(int_column[\"column_statistics\"], dict)\r\n        assert int_column[\"column_statistics\"] == {\r\n            \"histogram\": {\"bin_edges\": [0, 1, 2, 3, 3], \"hist\": [1, 1, 1, 1]},\r\n            \"max\": 3,\r\n            \"mean\": 1.5,\r\n            \"median\": 1.5,\r\n            \"min\": 0,\r\n            \"nan_count\": 0,\r\n            \"nan_proportion\": 0.0,\r\n            \"std\": 1.29099,\r\n        }\r\n    \r\n        float_column = statistics[2]\r\n        assert \"column_name\" in float_column\r\n        assert \"column_statistics\" in float_column\r\n        assert \"column_type\" in float_column\r\n        assert float_column[\"column_name\"] == \"col_3\"\r\n>       assert float_column[\"column_type\"] == \"float\"\r\nE       AssertionError: assert 'int' == 'float'\r\nE         - float\r\nE         + int\r\n\r\ntests\/test_14_statistics.py:72: AssertionError\r\n\r\n=========================== short test summary info ============================\r\nFAILED tests\/test_14_statistics.py::test_statistics_endpoint - AssertionError: assert 'int' == 'float'\r\n  - float\r\n  + int\r\n``` \r\n\r\nThis bug was introduced after:\r\n- #6914\r\n\r\nWe have reported the issue to pandas:\r\n- https:\/\/github.com\/pandas-dev\/pandas\/issues\/58866","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6937\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6937\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6936","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6936\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6936\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6936\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6936","id":2326119853,"node_id":"I_kwDODunzps6KpcWt","number":6936,"title":"save_to_disk() freezes when saving on s3 bucket with multiprocessing","user":{"login":"ycattan","id":54974949,"node_id":"MDQ6VXNlcjU0OTc0OTQ5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/54974949?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ycattan","html_url":"https:\/\/github.com\/ycattan","followers_url":"https:\/\/api.github.com\/users\/ycattan\/followers","following_url":"https:\/\/api.github.com\/users\/ycattan\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ycattan\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ycattan\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ycattan\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ycattan\/orgs","repos_url":"https:\/\/api.github.com\/users\/ycattan\/repos","events_url":"https:\/\/api.github.com\/users\/ycattan\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ycattan\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-30T16:48:39Z","updated_at":"2024-05-30T16:49:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nI'm trying to save a `Dataset` using the `save_to_disk()` function with:\r\n- `num_proc > 1`\r\n- `dataset_path` being a s3 bucket path e.g. \"s3:\/\/{bucket_name}\/{dataset_folder}\/\"\r\n\r\nThe hf progress bar shows up but the saving does not seem to start. \r\nWhen using one processor only (`num_proc=1`), everything works fine.\r\nWhen saving the dataset on local disk (as opposed to s3 bucket) with `num_proc > 1`, everything works fine.\r\n\r\nThank you for your help! :)\r\n\r\n### Steps to reproduce the bug\r\n\r\nI tried without any storage options:\r\n\r\n```\r\nfrom datasets import load_dataset\r\n\r\nsandbox_ds = load_dataset(\"openai_humaneval\")\r\nsandbox_ds[\"test\"].save_to_disk(\r\n    \"s3:\/\/bucket-name\/test_multiprocessing_saving\/\",\r\n    num_proc=4,\r\n)\r\n```\r\n\r\n\r\nand with the specific s3fs storage options: \r\n```\r\nfrom datasets import load_dataset\r\nfrom s3fs import S3FileSystem\r\n\r\ndef get_s3fs():\r\n    return S3FileSystem()\r\n\r\nsandbox_ds = load_dataset(\"openai_humaneval\")\r\nsandbox_ds[\"test\"].save_to_disk(\r\n    \"s3:\/\/bucket-name\/test_multiprocessing_saving\/\",\r\n    num_proc=4,\r\n    storage_options=get_s3fs().storage_options, # also tried: storage_options=S3FileSystem().storage_options\r\n)\r\n```\r\n\r\nI'm guessing I might use `storage_options` parameter wrongly, but I didn't find anything online that made it work.\r\n\r\n**NB**: Behavior is the same when trying to save the whole `DatasetDict`.\r\n\r\n### Expected behavior\r\n\r\nProgress bar fills in and saving is carried out.\r\n\r\n### Environment info\r\n\r\n`datasets==2.18.0`","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6936\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6936\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6935","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6935\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6935\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6935\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6935","id":2325612022,"node_id":"I_kwDODunzps6KngX2","number":6935,"title":"Support for pathlib.Path in datasets 2.19.0","user":{"login":"lamyiowce","id":12202811,"node_id":"MDQ6VXNlcjEyMjAyODEx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/12202811?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lamyiowce","html_url":"https:\/\/github.com\/lamyiowce","followers_url":"https:\/\/api.github.com\/users\/lamyiowce\/followers","following_url":"https:\/\/api.github.com\/users\/lamyiowce\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lamyiowce\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lamyiowce\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lamyiowce\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lamyiowce\/orgs","repos_url":"https:\/\/api.github.com\/users\/lamyiowce\/repos","events_url":"https:\/\/api.github.com\/users\/lamyiowce\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lamyiowce\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-30T12:53:36Z","updated_at":"2024-05-30T12:53:36Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nAfter the recent update of `datasets`, Dataset.save_to_disk does not accept a pathlib.Path anymore. It was supported in 2.18.0 and previous versions. Is this intentional? Was it supported before only because of a Python dusk-typing miracle?\n\n### Steps to reproduce the bug\n\n```\r\nfrom datasets import Dataset\r\nimport pathlib\r\n\r\npath = pathlib.Path(\".\/my_out_path\")\r\nDataset.from_dict(\r\n    {\"text\": [\"hello world\"], \"label\": [777], \"split\": [\"train\"]}\r\n.save_to_disk(path)\r\n```\r\nThis results in an error when using datasets 2.19:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 3, in <module>\r\n  File \"\/Users\/jb\/scratch\/venv\/lib\/python3.11\/site-packages\/datasets\/arrow_dataset.py\", line 1515, in save_to_disk\r\n    fs, _ = url_to_fs(dataset_path, **(storage_options or {}))\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Users\/jb\/scratch\/venv\/lib\/python3.11\/site-packages\/fsspec\/core.py\", line 383, in url_to_fs\r\n    chain = _un_chain(url, kwargs)\r\n            ^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Users\/jb\/scratch\/venv\/lib\/python3.11\/site-packages\/fsspec\/core.py\", line 323, in _un_chain\r\n    if \"::\" in path\r\n       ^^^^^^^^^^^^\r\nTypeError: argument of type 'PosixPath' is not iterable\r\n```\r\n\r\nConverting to str works, however.\r\n```\r\nDataset.from_dict(\r\n     {\"text\": [\"hello world\"], \"label\": [777], \"split\": [\"train\"]}\r\n).save_to_disk(str(path))\r\n```\n\n### Expected behavior\n\nMy dataset gets saved to disk without an error.\n\n### Environment info\n\naiohttp==3.9.5\r\naiosignal==1.3.1\r\nattrs==23.2.0\r\ncertifi==2024.2.2\r\ncharset-normalizer==3.3.2\r\ndatasets==2.19.0\r\ndill==0.3.8\r\nfilelock==3.14.0\r\nfrozenlist==1.4.1\r\nfsspec==2024.3.1\r\nhuggingface-hub==0.23.2\r\nidna==3.7\r\nmultidict==6.0.5\r\nmultiprocess==0.70.16\r\nnumpy==1.26.4\r\npackaging==24.0\r\npandas==2.2.2\r\npyarrow==16.1.0\r\npyarrow-hotfix==0.6\r\npython-dateutil==2.9.0.post0\r\npytz==2024.1\r\nPyYAML==6.0.1\r\nrequests==2.32.3\r\nsix==1.16.0\r\ntqdm==4.66.4\r\ntyping_extensions==4.12.0\r\ntzdata==2024.1\r\nurllib3==2.2.1\r\nxxhash==3.4.1\r\nyarl==1.9.4","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6935\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6935\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6934","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6934\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6934\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6934\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6934","id":2325341717,"node_id":"PR_kwDODunzps5w_laB","number":6934,"title":"Revert ci user","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2024-05-30T10:45:26Z","updated_at":"2024-05-31T10:25:08Z","closed_at":"2024-05-30T10:45:37Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6934","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6934","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6934.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6934.patch","merged_at":"2024-05-30T10:45:37Z"},"body":null,"reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6934\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6934\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6933","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6933\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6933\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6933\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6933","id":2325300800,"node_id":"PR_kwDODunzps5w_cW4","number":6933,"title":"update ci user","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-30T10:23:02Z","updated_at":"2024-05-30T10:30:54Z","closed_at":"2024-05-30T10:23:12Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6933","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6933","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6933.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6933.patch","merged_at":"2024-05-30T10:23:12Z"},"body":"token is ok to be public since it's only for the hub-ci","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6933\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6933\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6932","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6932\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6932\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6932\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6932","id":2324729267,"node_id":"PR_kwDODunzps5w9d7w","number":6932,"title":"Update dataset_dict.py","user":{"login":"Arunprakash-A","id":20263729,"node_id":"MDQ6VXNlcjIwMjYzNzI5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/20263729?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Arunprakash-A","html_url":"https:\/\/github.com\/Arunprakash-A","followers_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/followers","following_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/orgs","repos_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/repos","events_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Arunprakash-A\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-30T05:22:35Z","updated_at":"2024-05-30T05:22:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6932","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6932","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6932.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6932.patch","merged_at":null},"body":"shape returns (number of rows, number of columns)","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6932\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6932\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6931","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6931\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6931\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6931\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6931","id":2323457525,"node_id":"PR_kwDODunzps5w5I-Y","number":6931,"title":"[WebDataset] Support compressed files","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-29T14:19:06Z","updated_at":"2024-05-29T16:33:18Z","closed_at":"2024-05-29T16:24:21Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6931","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6931","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6931.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6931.patch","merged_at":"2024-05-29T16:24:21Z"},"body":null,"reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6931\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6931\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6930","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6930\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6930\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6930\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6930","id":2323225922,"node_id":"I_kwDODunzps6KeZ1C","number":6930,"title":"ValueError: Couldn't infer the same data file format for all splits. Got {'train': ('json', {}), 'validation': (None, {})}","user":{"login":"CLL112","id":41767521,"node_id":"MDQ6VXNlcjQxNzY3NTIx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/41767521?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/CLL112","html_url":"https:\/\/github.com\/CLL112","followers_url":"https:\/\/api.github.com\/users\/CLL112\/followers","following_url":"https:\/\/api.github.com\/users\/CLL112\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/CLL112\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/CLL112\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/CLL112\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/CLL112\/orgs","repos_url":"https:\/\/api.github.com\/users\/CLL112\/repos","events_url":"https:\/\/api.github.com\/users\/CLL112\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/CLL112\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-29T12:40:05Z","updated_at":"2024-05-29T12:40:05Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nWhen I run the code en = load_dataset(\"allenai\/c4\", \"en\", streaming=True), I encounter an error: raise ValueError(f\"Couldn't infer the same data file format for all splits. Got {split_modules}\") ValueError: Couldn't infer the same data file format for all splits. Got {'train': ('json', {}), 'validation': (None, {})}.\r\nHowever, running dataset = load_dataset('allenai\/c4', streaming=True, data_files={'validation': 'en\/c4-validation.00003-of-00008.json.gz'}, split='validation') works fine. What is the issue here?\n\n### Steps to reproduce the bug\n\nrun code\uff1a\r\nimport os\r\nos.environ['HF_ENDPOINT'] = 'https:\/\/hf-mirror.com'\r\nfrom datasets import load_dataset\r\n\r\nen = load_dataset(\"allenai\/c4\", \"en\", streaming=True)\n\n### Expected behavior\n\nSuccessfully loaded the dataset.\n\n### Environment info\n\n- `datasets` version: 2.18.0\r\n- Platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.17\r\n- Python version: 3.8.19\r\n- `huggingface_hub` version: 0.22.2\r\n- PyArrow version: 15.0.2\r\n- Pandas version: 2.0.3\r\n- `fsspec` version: 2024.2.0\r\n","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6930\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6930\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6929","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6929\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6929\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6929\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6929","id":2322980077,"node_id":"I_kwDODunzps6Kddzt","number":6929,"title":"Avoid downloading the whole dataset when only README.me has been touched on hub.","user":{"login":"zinc75","id":73740254,"node_id":"MDQ6VXNlcjczNzQwMjU0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/73740254?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/zinc75","html_url":"https:\/\/github.com\/zinc75","followers_url":"https:\/\/api.github.com\/users\/zinc75\/followers","following_url":"https:\/\/api.github.com\/users\/zinc75\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/zinc75\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/zinc75\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/zinc75\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/zinc75\/orgs","repos_url":"https:\/\/api.github.com\/users\/zinc75\/repos","events_url":"https:\/\/api.github.com\/users\/zinc75\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/zinc75\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-29T10:36:06Z","updated_at":"2024-05-29T20:51:56Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Feature request\r\n\r\n`datasets.load_dataset()` triggers a new download of the **whole dataset** when the README.md file has been touched on huggingface hub, even if data files \/ parquet files are the exact same.\r\n\r\nI think the current behaviour of the load_dataset function is triggered whenever a change of the hash of latest commit on huggingface hub, but  is there a clever way to only download again the dataset **if and only if** data is modified ?  \r\n\r\n### Motivation\r\n\r\nThe current behaviour is a waste of network bandwidth \/ disk space \/ research time.\r\n\r\n### Your contribution\r\n\r\nI don't have time to submit a PR, but I hope a simple solution will emerge from this issue ! ","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6929\/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6929\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6928","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6928\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6928\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6928\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6928","id":2322267727,"node_id":"PR_kwDODunzps5w1ECb","number":6928,"title":"Update process.mdx: Code Listings Fixes","user":{"login":"FadyMorris","id":16918280,"node_id":"MDQ6VXNlcjE2OTE4Mjgw","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/16918280?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/FadyMorris","html_url":"https:\/\/github.com\/FadyMorris","followers_url":"https:\/\/api.github.com\/users\/FadyMorris\/followers","following_url":"https:\/\/api.github.com\/users\/FadyMorris\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/FadyMorris\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/FadyMorris\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/FadyMorris\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/FadyMorris\/orgs","repos_url":"https:\/\/api.github.com\/users\/FadyMorris\/repos","events_url":"https:\/\/api.github.com\/users\/FadyMorris\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/FadyMorris\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-29T03:17:07Z","updated_at":"2024-05-29T03:17:07Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6928","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6928","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6928.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6928.patch","merged_at":null},"body":null,"reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6928\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6928\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6927","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6927\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6927\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6927\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6927","id":2322260725,"node_id":"PR_kwDODunzps5w1CmF","number":6927,"title":"Update process.mdx: Minor Code Listings Updates and Fixes","user":{"login":"FadyMorris","id":16918280,"node_id":"MDQ6VXNlcjE2OTE4Mjgw","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/16918280?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/FadyMorris","html_url":"https:\/\/github.com\/FadyMorris","followers_url":"https:\/\/api.github.com\/users\/FadyMorris\/followers","following_url":"https:\/\/api.github.com\/users\/FadyMorris\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/FadyMorris\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/FadyMorris\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/FadyMorris\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/FadyMorris\/orgs","repos_url":"https:\/\/api.github.com\/users\/FadyMorris\/repos","events_url":"https:\/\/api.github.com\/users\/FadyMorris\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/FadyMorris\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-29T03:09:01Z","updated_at":"2024-05-29T03:12:46Z","closed_at":"2024-05-29T03:12:46Z","author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6927","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6927","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6927.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6927.patch","merged_at":null},"body":null,"reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6927\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6927\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6926","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6926\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6926\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6926\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6926","id":2322164287,"node_id":"PR_kwDODunzps5w0uII","number":6926,"title":"Update process.mdx: Fix code listing in Shard section","user":{"login":"FadyMorris","id":16918280,"node_id":"MDQ6VXNlcjE2OTE4Mjgw","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/16918280?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/FadyMorris","html_url":"https:\/\/github.com\/FadyMorris","followers_url":"https:\/\/api.github.com\/users\/FadyMorris\/followers","following_url":"https:\/\/api.github.com\/users\/FadyMorris\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/FadyMorris\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/FadyMorris\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/FadyMorris\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/FadyMorris\/orgs","repos_url":"https:\/\/api.github.com\/users\/FadyMorris\/repos","events_url":"https:\/\/api.github.com\/users\/FadyMorris\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/FadyMorris\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-29T01:25:55Z","updated_at":"2024-05-29T03:11:20Z","closed_at":"2024-05-29T03:11:08Z","author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6926","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6926","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6926.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6926.patch","merged_at":null},"body":null,"reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6926\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6926\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6925","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6925\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6925\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6925\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6925","id":2321084967,"node_id":"PR_kwDODunzps5wxDRE","number":6925,"title":"Fix NonMatchingSplitsSizesError in no-code Hub datasets when passing data_dir, data_files","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-28T13:33:38Z","updated_at":"2024-05-28T14:00:48Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6925","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6925","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6925.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6925.patch","merged_at":null},"body":"Fix `NonMatchingSplitsSizesError` for no-code Hub datasets if the user passes:\r\n- `data_dir`\r\n- `data_files`\r\n\r\nThe proposed solution is to avoid using exported dataset info (from Parquet exports) in these cases.\r\nAdditionally, also if the user passes `revision` other than \"main\" (so that no network requests are made).\r\n\r\nThis PR fixes a bug introduced by:\r\n- #6714\r\n\r\nFix #6918.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6925\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6925\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6924","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6924\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6924\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6924\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6924","id":2320531015,"node_id":"I_kwDODunzps6KUH5H","number":6924,"title":"Caching map result of DatasetDict.","user":{"login":"MostHumble","id":56939432,"node_id":"MDQ6VXNlcjU2OTM5NDMy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/56939432?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/MostHumble","html_url":"https:\/\/github.com\/MostHumble","followers_url":"https:\/\/api.github.com\/users\/MostHumble\/followers","following_url":"https:\/\/api.github.com\/users\/MostHumble\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/MostHumble\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/MostHumble\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/MostHumble\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/MostHumble\/orgs","repos_url":"https:\/\/api.github.com\/users\/MostHumble\/repos","events_url":"https:\/\/api.github.com\/users\/MostHumble\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/MostHumble\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-28T09:07:41Z","updated_at":"2024-05-28T09:07:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"Hi!\r\n\r\nI'm currenty using the map function to tokenize a somewhat large dataset, so I need to use the cache to save ~25 mins.\r\n\r\nChanging num_proc incduces the recomputation of the map, I'm not sure why and if this is excepted behavior? \r\n\r\nhere it says, that cached files are loaded sequentially:\r\n\r\nhttps:\/\/github.com\/huggingface\/datasets\/blob\/bb2664cf540d5ce4b066365e7c8b26e7f1ca4743\/src\/datasets\/arrow_dataset.py#L3005-L3006\r\n\r\nit seems like I can pass in a fingerprint, and load it directly:\r\n\r\nhttps:\/\/github.com\/huggingface\/datasets\/blob\/bb2664cf540d5ce4b066365e7c8b26e7f1ca4743\/src\/datasets\/arrow_dataset.py#L3108-L3125\r\n\r\n**Environment Setup:**\r\n\r\n- Python 3.11.9\r\n- datasets  2.19.1 conda-forge\r\n- Linux 6.1.83-1.el9.elrepo.x86_64\r\n\r\n**MRE**\r\n```python\r\nfixed raw_datasets\r\nfixed tokenize_function\r\n\r\ntokenized_datasets = raw_datasets.map(\r\n                        tokenize_function,\r\n                        batched=True,\r\n                        num_proc=9,\r\n                        remove_columns=['text'],\r\n                        load_from_cache_file= True,\r\n                        desc=\"Running tokenizer on dataset line_by_line\",\r\n                    )\r\n\r\n\r\ntokenized_datasets = raw_datasets.map(\r\n                        tokenize_function,\r\n                        batched=True,\r\n                        num_proc=5,\r\n                        remove_columns=['text'],\r\n                        load_from_cache_file= True,\r\n                        desc=\"Running tokenizer on dataset line_by_line\",\r\n                    )\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6924\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6924\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6923","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6923\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6923\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6923\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6923","id":2319292872,"node_id":"I_kwDODunzps6KPZnI","number":6923,"title":"Export Parquet Tablet Audio-Set is null bytes in Arrow ","user":{"login":"anioji","id":140120605,"node_id":"U_kgDOCFoSHQ","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/140120605?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/anioji","html_url":"https:\/\/github.com\/anioji","followers_url":"https:\/\/api.github.com\/users\/anioji\/followers","following_url":"https:\/\/api.github.com\/users\/anioji\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/anioji\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/anioji\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/anioji\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/anioji\/orgs","repos_url":"https:\/\/api.github.com\/users\/anioji\/repos","events_url":"https:\/\/api.github.com\/users\/anioji\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/anioji\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-27T14:27:57Z","updated_at":"2024-05-27T14:27:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nExporting the processed audio inside the table with the dataset.to_parquet function, the object pyarrow {bytes: null, path: \"Some\/Path\"}\r\nAt the same time, the same dataset uploaded to the hub has bit arrays\r\n\r\n![Screenshot from 2024-05-27 19-14-49](https:\/\/github.com\/huggingface\/datasets\/assets\/140120605\/ddfba089-426f-4659-9df4-7a634c948b9e)\r\n![Screenshot from 2024-05-27 19-12-51](https:\/\/github.com\/huggingface\/datasets\/assets\/140120605\/4cf8c0a1-650e-491b-86c8-b475c284a021)\r\n\n\n### Steps to reproduce the bug\n\n1.Get dataset from audio and cast it \r\n2.Export and push dataset\r\n3.It\u2019s scary to be indignant at the difference in the uploaded dataset and the fact that it was saved locally\r\n```py\r\nfrom datasets import Dataset, Audio \r\ndf = Dataset.from_csv(\".\/datasets.csv\")\r\ndf = df.cast_column(\"audio\", Audio(16000))\r\ndf.to_parquet(\".\/datasets.parquet\")\r\ndf.push_to_hub(repo_id=\"************\", token=\"**********************\")\r\n```\r\n\r\nYou can use \"try replicate case\" for this\r\n[replicate_packet.zip](https:\/\/github.com\/huggingface\/datasets\/files\/15457114\/replicate_packet.zip)\r\n\n\n### Expected behavior\n\nTwo parquet tables identical in content. It is obvious?\n\n### Environment info\n\nPython 3.11+ (I try did it in 3.12 and got same result )","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6923\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6923\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6922","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6922\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6922\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6922\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6922","id":2318602059,"node_id":"PR_kwDODunzps5wolTm","number":6922,"title":"Remove torchaudio remnants from code","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-27T08:45:07Z","updated_at":"2024-05-27T09:08:19Z","closed_at":"2024-05-27T08:59:21Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6922","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6922","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6922.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6922.patch","merged_at":"2024-05-27T08:59:21Z"},"body":"Remove torchaudio remnants from code.\r\n\r\nFollow-up on:\r\n- #5573","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6922\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6922\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6921","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6921\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6921\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6921\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6921","id":2318394398,"node_id":"PR_kwDODunzps5wn4Dz","number":6921,"title":"Support fsspec 2024.5.0","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-27T07:00:59Z","updated_at":"2024-05-27T08:07:16Z","closed_at":"2024-05-27T08:01:08Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6921","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6921","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6921.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6921.patch","merged_at":"2024-05-27T08:01:08Z"},"body":"Support fsspec 2024.5.0.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6921\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6921\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6920","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6920\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6920\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6920\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6920","id":2317648021,"node_id":"PR_kwDODunzps5wlchX","number":6920,"title":"[WebDataset] Add `.pth` support for torch tensors","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-26T11:12:07Z","updated_at":"2024-05-27T09:11:17Z","closed_at":"2024-05-27T09:04:54Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6920","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6920","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6920.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6920.patch","merged_at":"2024-05-27T09:04:54Z"},"body":"In this PR I add support for `.pth` but with `weights_only=True` to disallow the use of pickle","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6920\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6920\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6919","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6919\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6919\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6919\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6919","id":2315618993,"node_id":"I_kwDODunzps6KBYqx","number":6919,"title":"Invalid YAML in README.md: unknown tag !<tag:yaml.org,2002:python\/tuple>","user":{"login":"juanqui","id":67964,"node_id":"MDQ6VXNlcjY3OTY0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/67964?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/juanqui","html_url":"https:\/\/github.com\/juanqui","followers_url":"https:\/\/api.github.com\/users\/juanqui\/followers","following_url":"https:\/\/api.github.com\/users\/juanqui\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/juanqui\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/juanqui\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/juanqui\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/juanqui\/orgs","repos_url":"https:\/\/api.github.com\/users\/juanqui\/repos","events_url":"https:\/\/api.github.com\/users\/juanqui\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/juanqui\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-24T14:59:45Z","updated_at":"2024-05-24T14:59:45Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI wrote a notebook to load an existing dataset, process it, and upload as a private dataset using `dataset.push_to_hub(...)` at the end. The push to hub is failing with:\r\n\r\n```\r\nValueError: Invalid metadata in README.md.\r\n- Invalid YAML in README.md: unknown tag !<tag:yaml.org,2002:python[\/tuple](http:\/\/192.168.1.128:8888\/tuple)> (50:11)\r\n\r\n 47 |             - 4\r\n 48 |             - 4\r\n 49 |             - 8\r\n 50 |           - !!binary |\r\n----------------^\r\n 51 |             TwAAAA==\r\n 52 |           '1': !!python[\/object\/apply](http:\/\/192.168.1.128:8888\/object\/apply):nump ...\r\n```\r\n\r\nMy dataset has a `train` and `validation` dataset.  These are the features:\r\n\r\n```\r\n{'c1': Value(dtype='string', id=None),\r\n 'c2': Value(dtype='string', id=None),\r\n 'c3': [{'value': Value(dtype='string', id=None),\r\n   'start': Value(dtype='int64', id=None),\r\n   'end': Value(dtype='int64', id=None),\r\n   'label': Value(dtype='string', id=None)}],\r\n 'c4': Value(dtype='string', id=None),\r\n 'c5': Value(dtype='string', id=None),\r\n 'c6': Value(dtype='string', id=None),\r\n 'c7': Value(dtype='string', id=None),\r\n 'c8': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\r\n 'c9': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\r\n 'c10': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\r\n 'labels': Sequence(feature=ClassLabel(names=['O', 'B-ABC', 'I-ABC', ...], id=None), length=-1, id=None),\r\n 'c12': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\r\n```\r\n\r\nThis used to work until I decided to cast the `labels` feature to a `Sequence(ClassLabel(...))` type with:\r\n\r\n```\r\nds['train'] = ds['train'].cast_column(\"labels\", Sequence(ClassLabel(names=list(labels))))\r\nds['validation'] = ds['validation'].cast_column(\"labels\", Sequence(ClassLabel(names=list(labels))))\r\n```\n\n### Steps to reproduce the bug\n\n1. Start with any token classification dataset.\r\n2. Add a `labels` column with data such as `[0,0,0,12,13,13,13,0,0]`.\r\n3. Cast the label column from `Sequence` to `Sequence(ClassLabel))` with:\r\n\r\n```\r\nlabels = ['O', 'B-TEST', 'I-TEST']\r\nds = ds.cast_column(\"labels\", Sequence(ClassLabel(names=labels)))\r\n```\r\n\r\n4. Push to hub with `ds.push_to_hub(\"me\/awesome-stuff-dataset\")`\n\n### Expected behavior\n\nI expected `push_to_hub` to successfully push my dataset to the hub without error.\n\n### Environment info\n\nPython 3.11.9\r\n\r\ndatasets==2.19.1\r\ntransformers==4.41.1\r\nPyYAML==6.0.1","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6919\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6919\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6918","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6918\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6918\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6918\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6918","id":2315322738,"node_id":"I_kwDODunzps6KAQVy","number":6918,"title":"NonMatchingSplitsSizesError when using data_dir","user":{"login":"srehaag","id":86664538,"node_id":"MDQ6VXNlcjg2NjY0NTM4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/86664538?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/srehaag","html_url":"https:\/\/github.com\/srehaag","followers_url":"https:\/\/api.github.com\/users\/srehaag\/followers","following_url":"https:\/\/api.github.com\/users\/srehaag\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/srehaag\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/srehaag\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/srehaag\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/srehaag\/orgs","repos_url":"https:\/\/api.github.com\/users\/srehaag\/repos","events_url":"https:\/\/api.github.com\/users\/srehaag\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/srehaag\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"open","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2024-05-24T12:43:39Z","updated_at":"2024-05-28T12:41:22Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nLoading a dataset from with a data_dir argument generates a NonMatchingSplitsSizesError if there are multiple directories in the dataset. \r\n\r\nThis appears to happen because the expected split is calculated based on the data in all the directories whereas the recorded split is calculated based on the data in the directory specified using the data_dir argument. \r\n\r\nThis is recent behavior. Until the past few weeks loading using the data_dir argument worked without any issue.\n\n### Steps to reproduce the bug\n\nSimple test dataset available here: https:\/\/huggingface.co\/datasets\/srehaag\/hf-bug-temp\r\n\r\nThe dataset contains two directories \"data1\" and \"data2\", each with a file called \"train.parquet\" with a 2 x 5 table.\r\n\r\nfrom datasets import load_dataset\r\ndataset = load_dataset(\"srehaag\/hf-bug-temp\", data_dir = \"data1\")\r\n\r\nGenerates:\r\n\r\n---------------------------------------------------------------------------\r\nNonMatchingSplitsSizesError               Traceback (most recent call last)\r\nCell In[3], <a href='vscode-notebook-cell:?execution_count=3&line=2'>line 2<\/a>\r\n      <a href='vscode-notebook-cell:?execution_count=3&line=1'>1<\/a> from datasets import load_dataset\r\n----> <a href='vscode-notebook-cell:?execution_count=3&line=2'>2<\/a> dataset = load_dataset(\"srehaag\/hf-bug-temp\", data_dir = \"data1\")\r\n\r\nFile ~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2609, in load_dataset(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2606'>2606<\/a>     return builder_instance.as_streaming_dataset(split=split)\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2608'>2608<\/a> # Download and prepare data\r\n-> <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2609'>2609<\/a> builder_instance.download_and_prepare(\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2610'>2610<\/a>     download_config=download_config,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2611'>2611<\/a>     download_mode=download_mode,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2612'>2612<\/a>     verification_mode=verification_mode,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2613'>2613<\/a>     num_proc=num_proc,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2614'>2614<\/a>     storage_options=storage_options,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2615'>2615<\/a> )\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2617'>2617<\/a> # Build dataset for splits\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2618'>2618<\/a> keep_in_memory = (\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2619'>2619<\/a>     keep_in_memory if keep_in_memory is not None else is_small_dataset(builder_instance.info.dataset_size)\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/load.py:2620'>2620<\/a> )\r\n\r\nFile ~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1027, in DatasetBuilder.download_and_prepare(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1025'>1025<\/a>     if num_proc is not None:\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1026'>1026<\/a>         prepare_split_kwargs[\"num_proc\"] = num_proc\r\n-> <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1027'>1027<\/a>     self._download_and_prepare(\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1028'>1028<\/a>         dl_manager=dl_manager,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1029'>1029<\/a>         verification_mode=verification_mode,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1030'>1030<\/a>         **prepare_split_kwargs,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1031'>1031<\/a>         **download_and_prepare_kwargs,\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1032'>1032<\/a>     )\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1033'>1033<\/a> # Sync info\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1034'>1034<\/a> self.info.dataset_size = sum(split.num_bytes for split in self.info.splits.values())\r\n\r\nFile ~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1140, in DatasetBuilder._download_and_prepare(self, dl_manager, verification_mode, **prepare_split_kwargs)\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1137'>1137<\/a>     dl_manager.manage_extracted_files()\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1139'>1139<\/a> if verification_mode == VerificationMode.BASIC_CHECKS or verification_mode == VerificationMode.ALL_CHECKS:\r\n-> <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1140'>1140<\/a>     verify_splits(self.info.splits, split_dict)\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1142'>1142<\/a> # Update the info object with the splits.\r\n   <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/builder.py:1143'>1143<\/a> self.info.splits = split_dict\r\n\r\nFile ~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:101, in verify_splits(expected_splits, recorded_splits)\r\n     <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:95'>95<\/a> bad_splits = [\r\n     <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:96'>96<\/a>     {\"expected\": expected_splits[name], \"recorded\": recorded_splits[name]}\r\n     <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:97'>97<\/a>     for name in expected_splits\r\n     <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:98'>98<\/a>     if expected_splits[name].num_examples != recorded_splits[name].num_examples\r\n     <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:99'>99<\/a> ]\r\n    <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:100'>100<\/a> if len(bad_splits) > 0:\r\n--> <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:101'>101<\/a>     raise NonMatchingSplitsSizesError(str(bad_splits))\r\n    <a href='~\/.python\/current\/lib\/python3.10\/site-packages\/datasets\/utils\/info_utils.py:102'>102<\/a> logger.info(\"All the splits matched successfully.\")\r\n\r\nNonMatchingSplitsSizesError: [{'expected': SplitInfo(name='train', num_bytes=212, num_examples=10, shard_lengths=None, dataset_name=None), 'recorded': SplitInfo(name='train', num_bytes=106, num_examples=5, shard_lengths=None, dataset_name='hf-bug-temp')}]\r\n\r\n__________\r\n\r\nBy contrast, this loads the data from both data1\/train.parquet and data2\/train.parquet without any error message:\r\n\r\nfrom datasets import load_dataset\r\ndataset = load_dataset(\"srehaag\/hf-bug-temp\")\r\n\r\n\n\n### Expected behavior\n\nShould load the 5 x 2 table from data1\/train.parquet without error message.\n\n### Environment info\n\nUsed Codespaces to simplify environment (see details below), but bug is present across various configurations.\r\n\r\n- `datasets` version: 2.19.1\r\n- Platform: Linux-6.5.0-1021-azure-x86_64-with-glibc2.31\r\n- Python version: 3.10.13\r\n- `huggingface_hub` version: 0.23.1\r\n- PyArrow version: 16.1.0\r\n- Pandas version: 2.2.2\r\n- `fsspec` version: 2024.3.1","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6918\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6918\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6917","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6917\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6917\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6917\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6917","id":2314683663,"node_id":"I_kwDODunzps6J90UP","number":6917,"title":"WinError 32 The process cannot access the file during load_dataset","user":{"login":"elwe-2808","id":56682168,"node_id":"MDQ6VXNlcjU2NjgyMTY4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/56682168?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/elwe-2808","html_url":"https:\/\/github.com\/elwe-2808","followers_url":"https:\/\/api.github.com\/users\/elwe-2808\/followers","following_url":"https:\/\/api.github.com\/users\/elwe-2808\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/elwe-2808\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/elwe-2808\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/elwe-2808\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/elwe-2808\/orgs","repos_url":"https:\/\/api.github.com\/users\/elwe-2808\/repos","events_url":"https:\/\/api.github.com\/users\/elwe-2808\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/elwe-2808\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-24T07:54:51Z","updated_at":"2024-05-24T07:54:51Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nWhen I try to load the opus_book from hugging face (following the [guide on the website](https:\/\/huggingface.co\/docs\/transformers\/main\/en\/tasks\/translation))\r\n\r\n```python\r\nfrom datasets import load_dataset, Dataset\r\n\r\ndataset = load_dataset(\"Helsinki-NLP\/opus_books\", \"en-fr\", features=[\"id\", \"translation\"])\r\n```\r\n\r\nI get an error:\r\n`PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\/Users\/Me\/.cache\/huggingface\/datasets\/Helsinki-NLP___parquet\/ca-de-a39f1ef185b9b73b\/0.0.0\/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec.incomplete\\\\parquet-train-00000-00000-of-NNNNN.arrow'\r\n`\r\n\r\n\r\n\r\n<details><summary>Full stacktrace<\/summary>\r\n<p>\r\n\r\n```python\r\n\r\nAttributeError                            Traceback (most recent call last)\r\nFile c:\\Users\\Me\\.conda\\envs\\ia\\lib\\site-packages\\datasets\\builder.py:1858, in ArrowBasedBuilder._prepare_split_single(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\r\n   [1857](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/builder.py:1857) _time = time.time()\r\n-> [1858](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/builder.py:1858) for _, table in generator:\r\n   [1859](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/builder.py:1859)     if max_shard_size is not None and writer._num_bytes > max_shard_size:\r\n\r\nFile c:\\Users\\Me\\.conda\\envs\\ia\\lib\\site-packages\\datasets\\packaged_modules\\parquet\\parquet.py:59, in Parquet._generate_tables(self, files)\r\n     [58](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/packaged_modules\/parquet\/parquet.py:58) def _generate_tables(self, files):\r\n---> [59](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/packaged_modules\/parquet\/parquet.py:59)     schema = self.config.features.arrow_schema if self.config.features is not None else None\r\n     [60](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/packaged_modules\/parquet\/parquet.py:60)     if self.config.features is not None and self.config.columns is not None:\r\n\r\nAttributeError: 'list' object has no attribute 'arrow_schema'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\nFile c:\\Users\\Me\\.conda\\envs\\ia\\lib\\site-packages\\datasets\\builder.py:1882, in ArrowBasedBuilder._prepare_split_single(self, gen_kwargs, fpath, file_format, max_shard_size, job_id)\r\n   [1881](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/builder.py:1881) num_shards = shard_id + 1\r\n-> [1882](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/builder.py:1882) num_examples, num_bytes = writer.finalize()\r\n   [1883](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/builder.py:1883) writer.close()\r\n\r\nFile c:\\Users\\Me\\.conda\\envs\\ia\\lib\\site-packages\\datasets\\arrow_writer.py:584, in ArrowWriter.finalize(self, close_stream)\r\n    [583](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/arrow_writer.py:583) # If schema is known, infer features even if no examples were written\r\n--> [584](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/site-packages\/datasets\/arrow_writer.py:584) if self.pa_writer is None and self.schema:\r\n...\r\n--> [627](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/shutil.py:627)         os.unlink(fullname)\r\n    [628](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/shutil.py:628)     except OSError:\r\n    [629](file:\/\/\/C:\/Users\/Me\/.conda\/envs\/ia\/lib\/shutil.py:629)         onerror(os.unlink, fullname, sys.exc_info())\r\n\r\nPermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'C:\/Users\/Me\/.cache\/huggingface\/datasets\/Helsinki-NLP___parquet\/ca-de-a39f1ef185b9b73b\/0.0.0\/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec.incomplete\\\\parquet-train-00000-00000-of-NNNNN.arrow'\r\n``` \r\n\r\n\r\n<\/p>\r\n<\/details> \n\n### Steps to reproduce the bug\n\nSteps to reproduce:\r\n\r\nJust execute these lines\r\n\r\n```python\r\nfrom datasets import load_dataset, Dataset\r\n\r\ndataset = load_dataset(\"Helsinki-NLP\/opus_books\", \"en-fr\", features=[\"id\", \"translation\"])\r\n```\r\n\n\n### Expected behavior\n\nI expect the dataset to be loaded without any errors.\n\n### Environment info\n\n| Package| Version|\r\n|--------|--------|\r\n| transformers| 4.37.2|\r\n| python| 3.9.19|\r\n| pytorch| 2.3.0|\r\n| datasets|2.12.0 | \r\n| arrow  |  1.2.3| \r\n                 \r\nI am using Conda on Windows 11.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6917\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6917\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6916","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6916\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6916\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6916\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6916","id":2311675564,"node_id":"I_kwDODunzps6JyV6s","number":6916,"title":"```push_to_hub()``` - Prevent Automatic Generation of Splits ","user":{"login":"jetlime","id":29337128,"node_id":"MDQ6VXNlcjI5MzM3MTI4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/29337128?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/jetlime","html_url":"https:\/\/github.com\/jetlime","followers_url":"https:\/\/api.github.com\/users\/jetlime\/followers","following_url":"https:\/\/api.github.com\/users\/jetlime\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/jetlime\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/jetlime\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/jetlime\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/jetlime\/orgs","repos_url":"https:\/\/api.github.com\/users\/jetlime\/repos","events_url":"https:\/\/api.github.com\/users\/jetlime\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/jetlime\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-22T23:52:15Z","updated_at":"2024-05-23T00:07:53Z","closed_at":"2024-05-23T00:07:53Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI currently have a dataset which has not been splited. When pushing the dataset to my hugging face dataset repository, it is split into a testing and training set. How can I prevent the split from happening?\n\n### Steps to reproduce the bug\n\n1. Have a unsplit dataset \r\n\r\n```python\r\nDataset({ features: ['input', 'output', 'Attack', '__index_level_0__'], num_rows: 944685 })\r\n```\r\n\r\n2. Push it to huggingface\r\n\r\n```python\r\ndataset.push_to_hub(dataset_name)\r\n```\r\n\r\n3. On the hugging face dataset repo, the dataset then appears to be splited:\r\n\r\n![image](https:\/\/github.com\/huggingface\/datasets\/assets\/29337128\/b4fbc141-42b0-4f49-98df-dd479648fe09)\r\n\r\n4. Indeed, when loading the dataset from this repo, the dataset is split in two testing and training set.\r\n\r\n```python\r\nfrom datasets import load_dataset, Dataset\r\n\r\ndataset = load_dataset(\"Jetlime\/NF-CSE-CIC-IDS2018-v2\", streaming=True)\r\ndataset\r\n```\r\noutput: \r\n\r\n```\r\nIterableDatasetDict({\r\n    train: IterableDataset({\r\n        features: ['input', 'output', 'Attack', '__index_level_0__'],\r\n        n_shards: 2\r\n    })\r\n    test: IterableDataset({\r\n        features: ['input', 'output', 'Attack', '__index_level_0__'],\r\n        n_shards: 1\r\n    })\r\n```\n\n### Expected behavior\n\nThe dataset shall not be splited, as not requested.\n\n### Environment info\n\n- `datasets` version: 2.19.1\r\n- Platform: Linux-6.2.0-35-generic-x86_64-with-glibc2.35\r\n- Python version: 3.10.12\r\n- `huggingface_hub` version: 0.23.0\r\n- PyArrow version: 15.0.2\r\n- Pandas version: 2.2.2\r\n- `fsspec` version: 2024.3.1","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6916\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6916\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6915","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6915\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6915\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6915\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6915","id":2310564961,"node_id":"PR_kwDODunzps5wNIUh","number":6915,"title":"Validate config name and data_files in packaged modules","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-05-22T13:36:33Z","updated_at":"2024-05-22T15:02:04Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6915","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6915","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6915.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6915.patch","merged_at":null},"body":"Validate the config attributes `name` and `data_files` in packaged modules by making the derived classes call their parent `__post_init__` method.\r\n\r\nNote that their parent `BuilderConfig` validates its attributes `name` and `data_files` in its `__post_init__` method: https:\/\/github.com\/huggingface\/datasets\/blob\/60d21efbc01e15d0b596ac1072750cbecd91548a\/src\/datasets\/builder.py#L128-L137\r\n\r\nThis PR makes the derived config classes call their parent `__post_init__` method to validate their `name` and `data_files` attributes.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6915\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6915\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6914","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6914\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6914\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6914\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6914","id":2310107326,"node_id":"PR_kwDODunzps5wLi3e","number":6914,"title":"Preserve JSON column order and support list of strings field","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-22T09:58:54Z","updated_at":"2024-05-29T13:18:47Z","closed_at":"2024-05-29T13:12:23Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6914","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6914","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6914.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6914.patch","merged_at":"2024-05-29T13:12:23Z"},"body":"Preserve column order when loading from a JSON file with a list of dict (or with a field containing a list of dicts).\r\n\r\nAdditionally, support JSON file with a list of strings field.\r\n\r\nFix #6913.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6914\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6914\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6913","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6913\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6913\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6913\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6913","id":2309605889,"node_id":"I_kwDODunzps6JqcoB","number":6913,"title":"Column order is nondeterministic when loading from JSON","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-22T05:30:14Z","updated_at":"2024-05-29T13:12:24Z","closed_at":"2024-05-29T13:12:24Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"As reported by @meg-huggingface, the order of the JSON object keys is not preserved while loading a dataset from a JSON file with a list of objects.\r\n\r\nFor example, when loading a JSON files with a list of objects, each with the following ordered keys:\r\n- [ID, Language, Topic], \r\n\r\nthe resulting dataset may have columns:\r\n- [ID, Topic, Language], or\r\n- [Topic, Language, ID], or\r\n- [Topic, ID, Language],...\r\n\r\nThis issue is caused by the use of a Python set (which does not preserve the order):\r\nhttps:\/\/github.com\/huggingface\/datasets\/blob\/60d21efbc01e15d0b596ac1072750cbecd91548a\/src\/datasets\/packaged_modules\/json\/json.py#L168\r\nintroduced in\r\n- #5772","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6913\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6913\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6912","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6912\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6912\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6912\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6912","id":2309365961,"node_id":"I_kwDODunzps6JpiDJ","number":6912,"title":"Add MedImg for streaming","user":{"login":"lhallee","id":72926928,"node_id":"MDQ6VXNlcjcyOTI2OTI4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/72926928?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhallee","html_url":"https:\/\/github.com\/lhallee","followers_url":"https:\/\/api.github.com\/users\/lhallee\/followers","following_url":"https:\/\/api.github.com\/users\/lhallee\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhallee\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhallee\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhallee\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhallee\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhallee\/repos","events_url":"https:\/\/api.github.com\/users\/lhallee\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhallee\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-22T00:55:30Z","updated_at":"2024-05-31T10:26:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Feature request\r\n\r\nHost the MedImg dataset (similar to Imagenet but for biomedical images). \r\n\r\n### Motivation\r\n\r\nThere is a clear need for biomedical image foundation models and large scale biomedical datasets that are easily streamable. This would be an excellent tool for the biomedical community.\r\n\r\n### Your contribution\r\n\r\nMedImg can be found [here](https:\/\/www.cuilab.cn\/medimg\/#).","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6912\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6912\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6911","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6911\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6911\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6911\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6911","id":2308152711,"node_id":"PR_kwDODunzps5wE2ah","number":6911,"title":"Remove dead code for non-dict data_files from packaged modules","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-21T12:10:24Z","updated_at":"2024-05-23T08:05:58Z","closed_at":"2024-05-23T07:59:57Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6911","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6911","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6911.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6911.patch","merged_at":"2024-05-23T07:59:57Z"},"body":"Remove dead code for non-dict data_files from packaged modules.\r\n\r\nSince the merge of this PR:\r\n- #2986\r\n\r\nthe builders' variable self.config.data_files is always a dict, which makes the condition on (str, list, tuple) dead code.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6911\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6911\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6910","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6910\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6910\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6910\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6910","id":2307570084,"node_id":"PR_kwDODunzps5wC2An","number":6910,"title":"Fix wrong type hints in data_files","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-21T07:41:09Z","updated_at":"2024-05-23T06:04:05Z","closed_at":"2024-05-23T05:58:05Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6910","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6910","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6910.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6910.patch","merged_at":"2024-05-23T05:58:05Z"},"body":"Fix wrong type hints in data_files introduced in:\r\n- #6493","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6910\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6910\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6909","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6909\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6909\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6909\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6909","id":2307508120,"node_id":"PR_kwDODunzps5wCoiE","number":6909,"title":"Update requests >=2.32.1 to fix vulnerability","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-21T07:11:20Z","updated_at":"2024-05-21T07:45:58Z","closed_at":"2024-05-21T07:38:25Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6909","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6909","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6909.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6909.patch","merged_at":"2024-05-21T07:38:25Z"},"body":"Update requests >=2.32.1 to fix vulnerability.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6909\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6909\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6908","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6908\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6908\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6908\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6908","id":2304958116,"node_id":"I_kwDODunzps6JYt6k","number":6908,"title":"Fail to load \"stas\/c4-en-10k\" dataset since 2.16 version","user":{"login":"guch8017","id":38173059,"node_id":"MDQ6VXNlcjM4MTczMDU5","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/38173059?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/guch8017","html_url":"https:\/\/github.com\/guch8017","followers_url":"https:\/\/api.github.com\/users\/guch8017\/followers","following_url":"https:\/\/api.github.com\/users\/guch8017\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/guch8017\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/guch8017\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/guch8017\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/guch8017\/orgs","repos_url":"https:\/\/api.github.com\/users\/guch8017\/repos","events_url":"https:\/\/api.github.com\/users\/guch8017\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/guch8017\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2024-05-20T02:43:59Z","updated_at":"2024-05-24T10:58:09Z","closed_at":"2024-05-24T10:58:09Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nWhen update datasets library to version 2.16+ ( I test it on 2.16, 2.19.0 and 2.19.1), using the following code to load stas\/c4-en-10k dataset \r\n\r\n```python\r\nfrom datasets import load_dataset, Dataset\r\ndataset = load_dataset('stas\/c4-en-10k')\r\n```\r\n\r\nand then it raise UnicodeDecodeError like\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/home\/*\/conda3\/envs\/watermark\/lib\/python3.10\/site-packages\/datasets\/load.py\", line 2523, in load_dataset\r\n    builder_instance = load_dataset_builder(\r\n  File \"\/home\/*\/conda3\/envs\/watermark\/lib\/python3.10\/site-packages\/datasets\/load.py\", line 2195, in load_dataset_builder\r\n    dataset_module = dataset_module_factory(\r\n  File \"\/home\/*\/conda3\/envs\/watermark\/lib\/python3.10\/site-packages\/datasets\/load.py\", line 1846, in dataset_module_factory\r\n    raise e1 from None\r\n  File \"\/home\/*\/conda3\/envs\/watermark\/lib\/python3.10\/site-packages\/datasets\/load.py\", line 1798, in dataset_module_factory\r\n    can_load_config_from_parquet_export = \"DEFAULT_CONFIG_NAME\" not in f.read()\r\n  File \"\/home\/*\/conda3\/envs\/watermark\/lib\/python3.10\/codecs.py\", line 322, in decode\r\n    (result, consumed) = self._buffer_decode(data, self.errors, final)\r\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte\r\n```\r\n\r\nI found that fs.open loads a gzip file and parses it like plain text using utf-8 encoder.\r\n\r\n```python\r\nfs = HfFileSystem('https:\/\/huggingface.co')\r\nfs.open(\"datasets\/stas\/c4-en-10k\/c4-en-10k.py\", \"rb\")\r\ndata = fs.read()    # data is gzip bytes begin with b'\\x1f\\x8b\\x08\\x00\\x00\\tn\\x88\\x00...' \r\ndata2 = unzip_gzip_bytes(data)    #  data2 is what we want: '# coding=utf-8\\n# Copyright 2020 The HuggingFace Datasets...'\r\n```\r\n\r\n### Steps to reproduce the bug\r\n\r\n1. Install datasets between version 2.16 and 2.19\r\n2. Use `datasets.load_dataset` method to load `stas\/c4-en-10k` dataset.\r\n\r\n### Expected behavior\r\n\r\nLoad dataset normally.\r\n\r\n### Environment info\r\n\r\nPlatform = Linux-5.4.0-159-generic-x86_64-with-glibc2.35\r\nPython = 3.10.14\r\nDatasets = 2.19","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6908\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6908\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6907","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6907\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6907\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6907\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6907","id":2303855833,"node_id":"I_kwDODunzps6JUgzZ","number":6907,"title":"Support the deserialization of json lines files comprised of lists","user":{"login":"umarbutler","id":8473183,"node_id":"MDQ6VXNlcjg0NzMxODM=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8473183?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/umarbutler","html_url":"https:\/\/github.com\/umarbutler","followers_url":"https:\/\/api.github.com\/users\/umarbutler\/followers","following_url":"https:\/\/api.github.com\/users\/umarbutler\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/umarbutler\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/umarbutler\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/umarbutler\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/umarbutler\/orgs","repos_url":"https:\/\/api.github.com\/users\/umarbutler\/repos","events_url":"https:\/\/api.github.com\/users\/umarbutler\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/umarbutler\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2024-05-18T05:07:23Z","updated_at":"2024-05-18T08:53:28Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Feature request\n\nI manage a somewhat large and popular Hugging Face dataset known as the [Open Australian Legal Corpus](https:\/\/huggingface.co\/datasets\/umarbutler\/open-australian-legal-corpus). I recently updated my corpus to be stored in a json lines file where each line is an array and each element represents a value at a particular column. Previously, my corpus was stored as a json lines file where each line was a dictionary and the keys were the fields.\r\n\r\nEssentially, a line in my json lines file used to look like this:\r\n```json\r\n{\"version_id\":\"\",\"type\":\"\",\"jurisdiction\":\"\",\"source\":\"\",\"citation\":\"\",\"url\":\"\",\"when_scraped\":\"\",\"text\":\"\"}\r\n```\r\n\r\nAnd now it looks like this:\r\n```json\r\n[\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"]\r\n```\r\n\r\nThis saves 65 bytes per document and allows me very quickly serialise and deserialise documents via `msgspec`.\r\n\r\nAfter making this change, I found that `datasets` was incapable of deserialising my Corpus without a custom loading script, even if I ensured that the `dataset_info` field in my dataset card contained the desired names of my features.\r\n\r\nI would like to request that functionality be added to support this format which is more memory-efficent and faster than using dictionaries.\n\n### Motivation\n\nThe [documentation](https:\/\/huggingface.co\/docs\/datasets\/en\/dataset_script) for creating dataset loading scripts asserts that:\r\n> In the next major release, the new safety features of \ud83e\udd17 Datasets will disable running dataset loading scripts by default, and you will have to pass trust_remote_code=True to load datasets that require running a dataset script.\r\n\r\nI would rather not require my users to pass `trust_remote_code=True` which means that I will need built-in support for this format.\n\n### Your contribution\n\nI would be happy to submit a PR for this if this is something you would incorporate into `datasets` and if I can be pointed to where the code would need to go.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6907\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6907\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6906","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6906\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6906\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6906\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6906","id":2303679119,"node_id":"I_kwDODunzps6JT1qP","number":6906,"title":"irc_disentangle - Issue with splitting data","user":{"login":"eor51355","id":114260604,"node_id":"U_kgDOBs96fA","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/114260604?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/eor51355","html_url":"https:\/\/github.com\/eor51355","followers_url":"https:\/\/api.github.com\/users\/eor51355\/followers","following_url":"https:\/\/api.github.com\/users\/eor51355\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/eor51355\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/eor51355\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/eor51355\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/eor51355\/orgs","repos_url":"https:\/\/api.github.com\/users\/eor51355\/repos","events_url":"https:\/\/api.github.com\/users\/eor51355\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/eor51355\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-17T23:19:37Z","updated_at":"2024-05-17T23:19:37Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI am trying to access your database through python using \"datasets.load_dataset(\"irc_disentangle\")\" and I am getting this error message:\r\n\r\nValueError: Instruction \"train\" corresponds to no data!\n\n### Steps to reproduce the bug\n\nimport datasets\r\nds = datasets.load_dataset('irc_disentangle')\r\nds\n\n### Expected behavior\n\nThe data is supposed to load into ds and be accessable as such:\r\nds['train'][1050], ds['train'][1055]\n\n### Environment info\n\nI tired Python 3.12 and 3.10","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6906\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6906\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6905","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6905\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6905\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6905\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6905","id":2303098587,"node_id":"I_kwDODunzps6JRn7b","number":6905,"title":"Extraction protocol for arrow files is not defined","user":{"login":"radulescupetru","id":26553095,"node_id":"MDQ6VXNlcjI2NTUzMDk1","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/26553095?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/radulescupetru","html_url":"https:\/\/github.com\/radulescupetru","followers_url":"https:\/\/api.github.com\/users\/radulescupetru\/followers","following_url":"https:\/\/api.github.com\/users\/radulescupetru\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/radulescupetru\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/radulescupetru\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/radulescupetru\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/radulescupetru\/orgs","repos_url":"https:\/\/api.github.com\/users\/radulescupetru\/repos","events_url":"https:\/\/api.github.com\/users\/radulescupetru\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/radulescupetru\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-17T16:01:41Z","updated_at":"2024-05-17T16:01:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nPassing files with `.arrow` extension into data_files argument, at least when `streaming=True` is very slow.\n\n### Steps to reproduce the bug\n\n Basically it goes through the `_get_extraction_protocol` method located [here](https:\/\/github.com\/huggingface\/datasets\/blob\/main\/src\/datasets\/utils\/file_utils.py#L820)\r\nThe method then looks at some base known extensions where `arrow` is not defined so it proceeds to determine the compression with the magic number method which is slow when dealing with a lot of files which are stored in s3 and by looking at this predefined list, I don't see `arrow` in there either so in the end it return None:\r\n\r\n```\r\nMAGIC_NUMBER_TO_COMPRESSION_PROTOCOL = {\r\n    bytes.fromhex(\"504B0304\"): \"zip\",\r\n    bytes.fromhex(\"504B0506\"): \"zip\",  # empty archive\r\n    bytes.fromhex(\"504B0708\"): \"zip\",  # spanned archive\r\n    bytes.fromhex(\"425A68\"): \"bz2\",\r\n    bytes.fromhex(\"1F8B\"): \"gzip\",\r\n    bytes.fromhex(\"FD377A585A00\"): \"xz\",\r\n    bytes.fromhex(\"04224D18\"): \"lz4\",\r\n    bytes.fromhex(\"28B52FFD\"): \"zstd\",\r\n}\r\n```\n\n### Expected behavior\n\nMy expectation is that `arrow` would be in the known lists so it would return None without going through the magic number method.\n\n### Environment info\n\ndatasets 2.19.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6905\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6905\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6904","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6904\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6904\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6904\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6904","id":2302912179,"node_id":"PR_kwDODunzps5vzRlD","number":6904,"title":"Fix decoding multi part extension","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2024-05-17T14:32:57Z","updated_at":"2024-05-17T14:52:56Z","closed_at":"2024-05-17T14:46:54Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6904","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6904","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6904.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6904.patch","merged_at":"2024-05-17T14:46:54Z"},"body":"e.g. a field named `url.txt` should be a treated as text\r\n\r\nI also included a small fix to support .npz correctly","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6904\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6904\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6903","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6903\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6903\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6903\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6903","id":2300436053,"node_id":"I_kwDODunzps6JHd5V","number":6903,"title":"Add the option of saving in parquet instead of arrow ","user":{"login":"arita37","id":18707623,"node_id":"MDQ6VXNlcjE4NzA3NjIz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/18707623?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/arita37","html_url":"https:\/\/github.com\/arita37","followers_url":"https:\/\/api.github.com\/users\/arita37\/followers","following_url":"https:\/\/api.github.com\/users\/arita37\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/arita37\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/arita37\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/arita37\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/arita37\/orgs","repos_url":"https:\/\/api.github.com\/users\/arita37\/repos","events_url":"https:\/\/api.github.com\/users\/arita37\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/arita37\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-16T13:35:51Z","updated_at":"2024-05-17T03:40:04Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Feature request\n\nIn dataset.save_to_disk('\/path\/to\/save\/dataset'),\r\n\r\nadd the option to save in parquet format\r\n\r\ndataset.save_to_disk('\/path\/to\/save\/dataset', format=\"parquet\"),\r\n\r\nbecause arrow is not used for Production Big data.... (only parquet)\r\n\r\n\n\n### Motivation\n\nbecause arrow is not used for Production Big data.... (only parquet)\n\n### Your contribution\n\nI can do the testing !","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6903\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6903\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6902","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6902\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6902\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6902\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6902","id":2300256241,"node_id":"PR_kwDODunzps5vqLIv","number":6902,"title":"Make CLI convert_to_parquet not raise error if no rights to create script branch","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-16T12:21:27Z","updated_at":"2024-05-16T12:57:02Z","closed_at":"2024-05-16T12:51:05Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6902","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6902","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6902.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6902.patch","merged_at":"2024-05-16T12:51:04Z"},"body":"Make CLI convert_to_parquet not raise error if no rights to create \"script\" branch.\r\n\r\nNot that before this PR, the error was not critical because it was raised at the end of the script, once all the rest of the steps were already performed.\r\n\r\nFix #6901.\r\n\r\nRelated to:\r\n- #6809","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6902\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6902\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6901","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6901\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6901\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6901\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6901","id":2300167465,"node_id":"I_kwDODunzps6JGcUp","number":6901,"title":"HTTPError 403 raised by CLI convert_to_parquet when creating script branch on 3rd party repos","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-16T11:40:22Z","updated_at":"2024-05-16T12:51:06Z","closed_at":"2024-05-16T12:51:06Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"CLI convert_to_parquet cannot create \"script\" branch on 3rd party repos.\r\n\r\nIt can only create it on repos where the user executing the script has write access.\r\n\r\nOtherwise, a 403 Forbidden HTTPError is raised:\r\n```\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/huggingface_hub\/utils\/_errors.py\", line 304, in hf_raise_for_status\r\n    response.raise_for_status()\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/requests\/models.py\", line 1021, in raise_for_status\r\n    raise HTTPError(http_error_msg, response=self)\r\nrequests.exceptions.HTTPError: 403 Client Error: Forbidden for url: https:\/\/huggingface.co\/api\/datasets\/ORG\/DATASET\/branch\/script\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/bin\/datasets-cli\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/commands\/datasets_cli.py\", line 41, in main\r\n    service.run()\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/commands\/convert_to_parquet.py\", line 92, in run\r\n    create_branch(dataset_id, branch=\"script\", repo_type=\"dataset\", token=token, exist_ok=True)\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/huggingface_hub\/utils\/_validators.py\", line 114, in _inner_fn\r\n    return fn(*args, **kwargs)\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/huggingface_hub\/hf_api.py\", line 5503, in create_branch\r\n    hf_raise_for_status(response)\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/huggingface_hub\/utils\/_errors.py\", line 367, in hf_raise_for_status\r\n    raise HfHubHTTPError(message, response=response) from e\r\nhuggingface_hub.utils._errors.HfHubHTTPError:  (Request ID: Root=1-6645ee0d-4db1ed8a1fbe04956be15897;139a6e23-df7d-4f62-b5ba-adb6d8e6e696)\r\n\r\n403 Forbidden: Forbidden: cannot write to script.\r\nCannot access content at: https:\/\/huggingface.co\/api\/datasets\/ORG\/DATASET\/branch\/script.\r\nIf you are trying to create or update content,make sure you have a token with the `write` role.\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6901\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6901\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6900","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6900\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6900\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6900\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6900","id":2298489733,"node_id":"I_kwDODunzps6JACuF","number":6900,"title":"[WebDataset] KeyError with user-defined `Features` when a field is missing in an example","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-15T17:48:34Z","updated_at":"2024-05-15T17:48:49Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"reported at https:\/\/huggingface.co\/datasets\/ProGamerGov\/synthetic-dataset-1m-dalle3-high-quality-captions\/discussions\/1\r\n\r\n```\r\nFile \"\/src\/services\/worker\/.venv\/lib\/python3.9\/site-packages\/datasets\/packaged_modules\/webdataset\/webdataset.py\", line 109, in _generate_examples\r\n    example[field_name] = {\"path\": example[\"__key__\"] + \".\" + field_name, \"bytes\": example[field_name]}\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6900\/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":1},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6900\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6899","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6899\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6899\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6899\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6899","id":2298059597,"node_id":"I_kwDODunzps6I-ZtN","number":6899,"title":"List of dictionary features get standardized","user":{"login":"sohamparikh94","id":11831521,"node_id":"MDQ6VXNlcjExODMxNTIx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/11831521?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/sohamparikh94","html_url":"https:\/\/github.com\/sohamparikh94","followers_url":"https:\/\/api.github.com\/users\/sohamparikh94\/followers","following_url":"https:\/\/api.github.com\/users\/sohamparikh94\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/sohamparikh94\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/sohamparikh94\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/sohamparikh94\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/sohamparikh94\/orgs","repos_url":"https:\/\/api.github.com\/users\/sohamparikh94\/repos","events_url":"https:\/\/api.github.com\/users\/sohamparikh94\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/sohamparikh94\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-15T14:11:35Z","updated_at":"2024-05-15T14:11:35Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nHi, i\u2019m trying to create a HF dataset from a list using Dataset.from_list.\r\n\r\nEach sample in the list is a dict with the same keys (which will be my features). The values for each feature are a list of dictionaries, and each such dictionary has a different set of keys. However, the datasets library standardizes all dictionaries under a feature and adds all possible keys (with None value) from all the dictionaries under that feature.\r\n\r\nHow can I keep the same set of keys as in the original list for each dictionary under a feature?\n\n### Steps to reproduce the bug\n\n```\r\nfrom datasets import Dataset\r\n\r\n# Define a function to generate a sample with \"tools\" feature\r\ndef generate_sample():\r\n    # Generate random sample data\r\n    sample_data = {\r\n        \"text\": \"Sample text\",\r\n        \"feature_1\": []\r\n    }\r\n    \r\n    # Add feature_1 with random keys for this sample\r\n    feature_1 = [{\"key1\": \"value1\"}, {\"key2\": \"value2\"}]  # Example feature_1 with random keys\r\n    sample_data[\"feature_1\"].extend(feature_1)\r\n    \r\n    return sample_data\r\n\r\n# Generate multiple samples\r\nnum_samples = 10\r\nsamples = [generate_sample() for _ in range(num_samples)]\r\n\r\n# Create a Hugging Face Dataset\r\ndataset = Dataset.from_list(samples)\r\ndataset[0]\r\n```\r\n\r\n```{'text': 'Sample text', 'feature_1': [{'key1': 'value1', 'key2': None}, {'key1': None, 'key2': 'value2'}]}```\n\n### Expected behavior\n\n```{'text': 'Sample text', 'feature_1': [{'key1': 'value1'}, {'key2': 'value2'}]}```\n\n### Environment info\n\n- `datasets` version: 2.19.1\r\n- Platform: Linux-5.15.0-1040-nvidia-x86_64-with-glibc2.35\r\n- Python version: 3.10.13\r\n- `huggingface_hub` version: 0.23.0\r\n- PyArrow version: 15.0.0\r\n- Pandas version: 2.2.0\r\n- `fsspec` version: 2023.10.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6899\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6899\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6898","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6898\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6898\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6898\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6898","id":2294432108,"node_id":"PR_kwDODunzps5vWJ9v","number":6898,"title":"Fix YAML error in README files appearing on GitHub","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2024-05-14T05:21:57Z","updated_at":"2024-05-16T14:36:57Z","closed_at":"2024-05-16T14:28:16Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6898","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6898","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6898.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6898.patch","merged_at":"2024-05-16T14:28:16Z"},"body":"Fix YAML error in README files appearing on GitHub.\r\n\r\nSee error message:\r\n![Screenshot from 2024-05-14 06-58-02](https:\/\/github.com\/huggingface\/datasets\/assets\/8515462\/7984cc4e-96ee-4e83-99a4-4c0c5791fa05)\r\n\r\n\r\nFix #6897.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6898\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6898\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6897","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6897\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6897\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6897\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6897","id":2293428243,"node_id":"I_kwDODunzps6IsvAT","number":6897,"title":"datasets template guide :: issue in documentation YAML","user":{"login":"bghira","id":59658056,"node_id":"MDQ6VXNlcjU5NjU4MDU2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/59658056?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/bghira","html_url":"https:\/\/github.com\/bghira","followers_url":"https:\/\/api.github.com\/users\/bghira\/followers","following_url":"https:\/\/api.github.com\/users\/bghira\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/bghira\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/bghira\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/bghira\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/bghira\/orgs","repos_url":"https:\/\/api.github.com\/users\/bghira\/repos","events_url":"https:\/\/api.github.com\/users\/bghira\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/bghira\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2024-05-13T17:33:59Z","updated_at":"2024-05-16T14:28:17Z","closed_at":"2024-05-16T14:28:17Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nThere is a YAML error at the top of the page, and I don't think it's supposed to be there \n\n### Steps to reproduce the bug\n\n1. Browse to [this tutorial document](https:\/\/github.com\/huggingface\/datasets\/blob\/main\/templates\/README_guide.md)\r\n2. Observe a big red error at the top\r\n3. The rest of the document remains functional\n\n### Expected behavior\n\nI think the YAML block should be displayed or ignored.\n\n### Environment info\n\nN\/A","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6897\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6897\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6896","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6896\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6896\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6896\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6896","id":2293176061,"node_id":"I_kwDODunzps6Irxb9","number":6896,"title":"Regression bug: `NonMatchingSplitsSizesError` for (possibly) overwritten dataset","user":{"login":"finiteautomata","id":167943,"node_id":"MDQ6VXNlcjE2Nzk0Mw==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/167943?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/finiteautomata","html_url":"https:\/\/github.com\/finiteautomata","followers_url":"https:\/\/api.github.com\/users\/finiteautomata\/followers","following_url":"https:\/\/api.github.com\/users\/finiteautomata\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/finiteautomata\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/finiteautomata\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/finiteautomata\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/finiteautomata\/orgs","repos_url":"https:\/\/api.github.com\/users\/finiteautomata\/repos","events_url":"https:\/\/api.github.com\/users\/finiteautomata\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/finiteautomata\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-13T15:41:57Z","updated_at":"2024-05-13T15:44:48Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nWhile trying to load the dataset `https:\/\/huggingface.co\/datasets\/pysentimiento\/spanish-tweets-small`, I get this error:\r\n\r\n```python\r\n---------------------------------------------------------------------------\r\nNonMatchingSplitsSizesError               Traceback (most recent call last)\r\n[<ipython-input-1-d6a3c721d3b8>](https:\/\/localhost:8080\/#) in <cell line: 3>()\r\n      1 from datasets import load_dataset\r\n      2 \r\n----> 3 ds = load_dataset(\"pysentimiento\/spanish-tweets-small\")\r\n\r\n3 frames\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/load.py](https:\/\/localhost:8080\/#) in load_dataset(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, **config_kwargs)\r\n   2150 \r\n   2151     # Download and prepare data\r\n-> 2152     builder_instance.download_and_prepare(\r\n   2153         download_config=download_config,\r\n   2154         download_mode=download_mode,\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in download_and_prepare(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\r\n    946                         if num_proc is not None:\r\n    947                             prepare_split_kwargs[\"num_proc\"] = num_proc\r\n--> 948                         self._download_and_prepare(\r\n    949                             dl_manager=dl_manager,\r\n    950                             verification_mode=verification_mode,\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in _download_and_prepare(self, dl_manager, verification_mode, **prepare_split_kwargs)\r\n   1059 \r\n   1060         if verification_mode == VerificationMode.BASIC_CHECKS or verification_mode == VerificationMode.ALL_CHECKS:\r\n-> 1061             verify_splits(self.info.splits, split_dict)\r\n   1062 \r\n   1063         # Update the info object with the splits.\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/utils\/info_utils.py](https:\/\/localhost:8080\/#) in verify_splits(expected_splits, recorded_splits)\r\n     98     ]\r\n     99     if len(bad_splits) > 0:\r\n--> 100         raise NonMatchingSplitsSizesError(str(bad_splits))\r\n    101     logger.info(\"All the splits matched successfully.\")\r\n    102 \r\n\r\nNonMatchingSplitsSizesError: [{'expected': SplitInfo(name='train', num_bytes=82649695458, num_examples=597433111, shard_lengths=None, dataset_name=None), 'recorded': SplitInfo(name='train', num_bytes=3358310095, num_examples=24898932, shard_lengths=[3626991, 3716991, 4036990, 3506990, 3676990, 3716990, 2616990], dataset_name='spanish-tweets-small')}]\r\n```\r\n\r\nI think I had this dataset updated, might be related to #6271 \r\n\r\nIt is working fine as late in `2.10.0` , but not in `2.13.0` onwards.\r\n\r\n### Steps to reproduce the bug\r\n\r\n\r\n```python\r\n\r\nfrom datasets import load_dataset\r\n\r\nds = load_dataset(\"pysentimiento\/spanish-tweets-small\")\r\n```\r\n\r\nYou can run it in [this notebook](https:\/\/colab.research.google.com\/drive\/1FdhqLiVimHIlkn7B54DbhizeQ4U3vGVl#scrollTo=YgA50cBSibUg)\r\n\r\n### Expected behavior\r\n\r\nLoad the dataset without any error\r\n\r\n### Environment info\r\n\r\n\r\n- `datasets` version: 2.13.0\r\n- Platform: Linux-6.1.58+-x86_64-with-glibc2.35\r\n- Python version: 3.10.12\r\n- Huggingface_hub version: 0.20.3\r\n- PyArrow version: 14.0.2\r\n- Pandas version: 2.0.3","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6896\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6896\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6895","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6895\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6895\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6895\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6895","id":2292993156,"node_id":"PR_kwDODunzps5vRK8P","number":6895,"title":"Document that to_json defaults to JSON Lines","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-13T14:22:34Z","updated_at":"2024-05-16T14:37:25Z","closed_at":"2024-05-16T14:31:26Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6895","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6895","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6895.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6895.patch","merged_at":"2024-05-16T14:31:26Z"},"body":"Document that `Dataset.to_json` defaults to JSON Lines, by adding explanation in the corresponding docstring.\r\n\r\nFix #6894.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6895\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6895\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6894","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6894\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6894\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6894\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6894","id":2292840226,"node_id":"I_kwDODunzps6Iqfci","number":6894,"title":"Better document defaults of to_json","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892861,"node_id":"MDU6TGFiZWwxOTM1ODkyODYx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/documentation","name":"documentation","color":"0075ca","default":true,"description":"Improvements or additions to documentation"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-13T13:30:54Z","updated_at":"2024-05-16T14:31:27Z","closed_at":"2024-05-16T14:31:27Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"Better document defaults of `to_json`: the default format is [JSON-Lines](https:\/\/jsonlines.org\/).\r\n\r\nRelated to:\r\n- #6891 ","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6894\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6894\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6893","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6893\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6893\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6893\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6893","id":2292677439,"node_id":"PR_kwDODunzps5vQFEv","number":6893,"title":"Close gzipped files properly","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":3,"created_at":"2024-05-13T12:24:39Z","updated_at":"2024-05-13T13:53:17Z","closed_at":"2024-05-13T13:01:54Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6893","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6893","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6893.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6893.patch","merged_at":"2024-05-13T13:01:54Z"},"body":"close https:\/\/github.com\/huggingface\/datasets\/issues\/6877","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6893\/reactions","total_count":1,"+1":0,"-1":0,"laugh":1,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6893\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6892","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6892\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6892\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6892\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6892","id":2291201347,"node_id":"PR_kwDODunzps5vLIlp","number":6892,"title":"Add support for categorical\/dictionary types","user":{"login":"EthanSteinberg","id":342233,"node_id":"MDQ6VXNlcjM0MjIzMw==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/342233?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/EthanSteinberg","html_url":"https:\/\/github.com\/EthanSteinberg","followers_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/followers","following_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/orgs","repos_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/repos","events_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/EthanSteinberg\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-12T07:15:08Z","updated_at":"2024-05-12T07:15:37Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6892","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6892","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6892.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6892.patch","merged_at":null},"body":"Arrow has a very useful dictionary\/categorical type (https:\/\/arrow.apache.org\/docs\/python\/generated\/pyarrow.dictionary.html). This data type has significant speed, memory and disk benefits over pa.string() when there are only a few unique text strings in a column.\r\n\r\nUnfortunately, huggingface datasets currently does not support this type. So huggingface datasets cannot natively read many parquet files that use this datatype .This PR adds support for Huggingface Datasets to read categorical\/dictionary data.\r\n\r\nNote: This PR functions by simply converting those dictionary\/categorical types to strings. This means that huggingface datasets cannot take advantage of the compute benefits of categoricals, but it significantly simplifies logic. At this time, I do not think it makes sense to optimize categorical support within huggingface datasets and that we should only try to optimize later, if necessary.\r\n\r\nCloses #5706","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6892\/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6892\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6891","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6891\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6891\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6891\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6891","id":2291118869,"node_id":"I_kwDODunzps6Ij7MV","number":6891,"title":"Unable to load JSON saved using `to_json`","user":{"login":"DarshanDeshpande","id":39432636,"node_id":"MDQ6VXNlcjM5NDMyNjM2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/39432636?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/DarshanDeshpande","html_url":"https:\/\/github.com\/DarshanDeshpande","followers_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/followers","following_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/orgs","repos_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/repos","events_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/DarshanDeshpande\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2024-05-12T01:02:51Z","updated_at":"2024-05-16T14:32:55Z","closed_at":"2024-05-12T07:02:02Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nDatasets stored in the JSON format cannot be loaded using `json.load()`\n\n### Steps to reproduce the bug\n\n```\r\nimport json\r\nfrom datasets import load_dataset\r\n\r\ndataset = load_dataset(\"squad\")\r\ntrain_dataset, test_dataset = dataset[\"train\"], dataset[\"validation\"]\r\ntest_dataset.to_json(\"full_dataset.json\")\r\n\r\n# This works\r\nloaded_test = load_dataset(\"json\", data_files=\"full_dataset.json\")\r\n\r\n# This fails\r\nloaded_test = json.load(open(\"full_dataset.json\", \"r\"))\r\n```\n\n### Expected behavior\n\nThe JSON should be correctly formatted when writing so that it can be loaded using `json.load()`.\n\n### Environment info\n\nColab: https:\/\/colab.research.google.com\/drive\/1st1iStFUVgu9ZPvnzSzL4vDeYWDwYpUm?usp=sharing","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6891\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6891\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6890","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6890\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6890\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6890\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6890","id":2288699041,"node_id":"I_kwDODunzps6Iasah","number":6890,"title":"add `with_transform` and\/or `set_transform` to IterableDataset","user":{"login":"not-lain","id":70411813,"node_id":"MDQ6VXNlcjcwNDExODEz","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/70411813?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/not-lain","html_url":"https:\/\/github.com\/not-lain","followers_url":"https:\/\/api.github.com\/users\/not-lain\/followers","following_url":"https:\/\/api.github.com\/users\/not-lain\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/not-lain\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/not-lain\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/not-lain\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/not-lain\/orgs","repos_url":"https:\/\/api.github.com\/users\/not-lain\/repos","events_url":"https:\/\/api.github.com\/users\/not-lain\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/not-lain\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-10T01:00:12Z","updated_at":"2024-05-10T01:00:46Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Feature request\n\nwhen working with a really large dataset it would save us a lot of time (and compute resources) to use either with_transform or the set_transform from the Dataset class instead of waiting for the entire dataset to map\n\n### Motivation\n\ndon't want to wait for a really long dataset to map, this would give IterableDataset an extra advantage over the Dataset class.\r\nreducing time and resources\n\n### Your contribution\n\nI am a little busy with my job search lately, but would post about this feature in my social media.\r\nApologies again (dad going to kick me out soon), if I ever have some free time I will contribute to making this a reality, but that's going to be hard\r\n  \u00a0\u00a0\u00a0 \/ (\u252c\u252c\ufe4f\u252c\u252c)\\","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6890\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6890\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6889","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6889\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6889\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6889\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6889","id":2287720539,"node_id":"PR_kwDODunzps5u_hW-","number":6889,"title":"fix bug #6877","user":{"login":"arthasking123","id":16257131,"node_id":"MDQ6VXNlcjE2MjU3MTMx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/16257131?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/arthasking123","html_url":"https:\/\/github.com\/arthasking123","followers_url":"https:\/\/api.github.com\/users\/arthasking123\/followers","following_url":"https:\/\/api.github.com\/users\/arthasking123\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/arthasking123\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/arthasking123\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/arthasking123\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/arthasking123\/orgs","repos_url":"https:\/\/api.github.com\/users\/arthasking123\/repos","events_url":"https:\/\/api.github.com\/users\/arthasking123\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/arthasking123\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":9,"created_at":"2024-05-09T13:38:40Z","updated_at":"2024-05-13T13:35:32Z","closed_at":"2024-05-13T13:35:32Z","author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6889","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6889","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6889.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6889.patch","merged_at":null},"body":"fix bug #6877 due to maybe f becomes invaild after yield process\r\nthe results are below:\r\n\r\n\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:01<00:00, 420.41it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 26148.48it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 409731.44it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 289720.84it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 26663.42it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 434056.21it\/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 13222.33files\/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:04<00:00, 180.67files\/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [01:35<00:00,  8.70files\/s]\r\nGenerating train split: 1571592 examples [00:08, 176736.09 examples\/s]\r\nGenerating test split: 85533 examples [00:01, 48224.56 examples\/s]\r\nGenerating validation split: 86246 examples [00:01, 50164.16 examples\/s]\r\n\r\nFix https:\/\/github.com\/huggingface\/datasets\/issues\/6877.\r\n\r\nCC: @natolambert\r\n","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6889\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6889\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6888","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6888\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6888\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6888\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6888","id":2287169676,"node_id":"PR_kwDODunzps5u9omr","number":6888,"title":"Support WebDataset containing file basenames with dots","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2024-05-09T08:25:30Z","updated_at":"2024-05-10T13:54:06Z","closed_at":"2024-05-10T13:54:06Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6888","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6888","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6888.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6888.patch","merged_at":null},"body":"Support WebDataset containing file basenames with dots.\r\n\r\nFix #6880.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6888\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6888\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6887","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6887\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6887\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6887\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6887","id":2286786396,"node_id":"I_kwDODunzps6ITZdc","number":6887,"title":"FAISS load to None","user":{"login":"brainer3220","id":40418544,"node_id":"MDQ6VXNlcjQwNDE4NTQ0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/40418544?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/brainer3220","html_url":"https:\/\/github.com\/brainer3220","followers_url":"https:\/\/api.github.com\/users\/brainer3220\/followers","following_url":"https:\/\/api.github.com\/users\/brainer3220\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/brainer3220\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/brainer3220\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/brainer3220\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/brainer3220\/orgs","repos_url":"https:\/\/api.github.com\/users\/brainer3220\/repos","events_url":"https:\/\/api.github.com\/users\/brainer3220\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/brainer3220\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-05-09T02:43:50Z","updated_at":"2024-05-16T20:44:23Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI've use FAISS with Datasets and save to FAISS.\r\n\r\nThen load to save FAISS then no error, then ds to None\r\n\r\n```python\r\nds.load_faiss_index('embeddings', 'my_index.faiss')\r\n```\n\n### Steps to reproduce the bug\n\n# 1.\r\n```python\r\nds_with_embeddings = ds.map(lambda example: {'embeddings': model(transforms(example['image']).unsqueeze(0)).squeeze()}, batch_size=64)\r\n\r\nds_with_embeddings.add_faiss_index(column='embeddings')\r\n\r\nds_with_embeddings.save_faiss_index('embeddings', 'index.faiss')\r\n```\r\n\r\n# 2.\r\n```python\r\nds.load_faiss_index('embeddings', 'my_index.faiss')\r\n```\n\n### Expected behavior\n\nAdd column in Datasets.\n\n### Environment info\n\nGoogle Colab, SageMaker Notebook","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6887\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6887\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6886","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6886\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6886\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6886\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6886","id":2286328984,"node_id":"I_kwDODunzps6IRpyY","number":6886,"title":"load_dataset with data_dir and cache_dir set fail with not supported","user":{"login":"fah","id":322496,"node_id":"MDQ6VXNlcjMyMjQ5Ng==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/322496?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/fah","html_url":"https:\/\/github.com\/fah","followers_url":"https:\/\/api.github.com\/users\/fah\/followers","following_url":"https:\/\/api.github.com\/users\/fah\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/fah\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/fah\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/fah\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/fah\/orgs","repos_url":"https:\/\/api.github.com\/users\/fah\/repos","events_url":"https:\/\/api.github.com\/users\/fah\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/fah\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-08T19:52:35Z","updated_at":"2024-05-08T19:58:11Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nwith python 3.11 I execute:\r\n```py\r\nfrom transformers import Wav2Vec2Processor, Data2VecAudioModel\r\nimport torch\r\nfrom torch import nn\r\nfrom datasets import load_dataset, concatenate_datasets\r\n\r\n# load demo audio and set processor\r\ndataset_clean = load_dataset(\"librispeech_asr\", \"clean\", split=\"validation\", data_dir=\"data\", cache_dir=\"cache\")\r\n```\r\nThis fails in the last line with \r\n```log\r\nFound cached dataset librispeech_asr (file:\/\/\/Users\/as\/Documents\/Project\/git\/audio2vec\/cache\/librispeech_asr\/clean-data_dir=data\/2.1.0\/cff5df6e7955c80a67f80e27e7e655de71c689e2d2364bece785b972acb37fe7)\r\nTraceback (most recent call last):\r\n  File \"\/Users\/as\/Documents\/Project\/git\/audio2vec\/src\/music2vec-v1.py\", line 7, in <module>\r\n    dataset_clean = load_dataset(\"librispeech_asr\", \"clean\", split=\"validation\", data_dir=\"data\", cache_dir=\"cache\")\r\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Users\/as\/anaconda3\/lib\/python3.11\/site-packages\/datasets\/load.py\", line 1810, in load_dataset\r\n    ds = builder_instance.as_dataset(split=split, verification_mode=verification_mode, in_memory=keep_in_memory)\r\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Users\/as\/anaconda3\/lib\/python3.11\/site-packages\/datasets\/builder.py\", line 1113, in as_dataset\r\n    raise NotImplementedError(f\"Loading a dataset cached in a {type(self._fs).__name__} is not supported.\")\r\nNotImplementedError: Loading a dataset cached in a LocalFileSystem is not supported.\r\n```\r\n\r\n### Steps to reproduce the bug\r\n\r\nI setup an venv with requirements.txt\r\n```txt\r\ntransformers==4.40.2\r\ntorch==2.2.2\r\ndatasets==2.16.0\r\nfsspec==2023.9.2\r\n```\r\n\r\npip freeze is:\r\n```\r\naiohttp==3.9.5\r\naiosignal==1.3.1\r\nattrs==23.2.0\r\ncertifi==2024.2.2\r\ncharset-normalizer==3.3.2\r\ndatasets==2.16.0\r\ndill==0.3.7\r\nfilelock==3.14.0\r\nfrozenlist==1.4.1\r\nfsspec==2023.9.2\r\nhuggingface-hub==0.23.0\r\nidna==3.7\r\nJinja2==3.1.4\r\nMarkupSafe==2.1.5\r\nmpmath==1.3.0\r\nmultidict==6.0.5\r\nmultiprocess==0.70.15\r\nnetworkx==3.3\r\nnumpy==1.26.4\r\npackaging==24.0\r\npandas==2.2.2\r\npyarrow==16.0.0\r\npyarrow-hotfix==0.6\r\npython-dateutil==2.9.0.post0\r\npytz==2024.1\r\nPyYAML==6.0.1\r\nregex==2024.4.28\r\nrequests==2.31.0\r\nsafetensors==0.4.3\r\nsix==1.16.0\r\nsympy==1.12\r\ntokenizers==0.19.1\r\ntorch==2.2.2\r\ntqdm==4.66.4\r\ntransformers==4.40.2\r\ntyping_extensions==4.11.0\r\ntzdata==2024.1\r\nurllib3==2.2.1\r\nxxhash==3.4.1\r\nyarl==1.9.4\r\n\r\n```\r\n\r\nI execute this on a M1 Mac.\r\n\r\n\r\n### Expected behavior\r\n\r\nI don't understand the error message. Why is \"local\" caching not supported. Would it possible to give some additional hint with the error message how to solve this issue?\r\n\r\n\r\n### Environment info\r\n\r\nsource ....\r\npython -u example.py","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6886\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6886\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6885","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6885\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6885\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6885\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6885","id":2285115400,"node_id":"PR_kwDODunzps5u2urB","number":6885,"title":"Support jax 0.4.27 in CI tests","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-08T09:19:37Z","updated_at":"2024-05-08T09:43:19Z","closed_at":"2024-05-08T09:35:16Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6885","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6885","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6885.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6885.patch","merged_at":"2024-05-08T09:35:16Z"},"body":"Support jax 0.4.27 in CI tests by using jax Array `devices` method instead of `device` (which no longer exists).\r\n\r\nFix #6884.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6885\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6885\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6884","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6884\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6884\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6884\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6884","id":2284839687,"node_id":"I_kwDODunzps6IL-MH","number":6884,"title":"CI is broken after jax-0.4.27 release: AttributeError: 'jaxlib.xla_extension.DeviceList' object has no attribute 'device'","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-08T07:01:47Z","updated_at":"2024-05-08T09:35:17Z","closed_at":"2024-05-08T09:35:17Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"After jax-0.4.27 release (https:\/\/github.com\/google\/jax\/releases\/tag\/jax-v0.4.27), our CI is broken with the error:\r\n```Python traceback\r\nAttributeError: 'jaxlib.xla_extension.DeviceList' object has no attribute 'device'. Did you mean: 'devices'?\r\n```\r\n\r\nSee: https:\/\/github.com\/huggingface\/datasets\/actions\/runs\/8997488610\/job\/24715736153\r\n```Python traceback\r\n___________________ FormatterTest.test_jax_formatter_device ____________________\r\n[gw1] linux -- Python 3.10.14 \/opt\/hostedtoolcache\/Python\/3.10.14\/x64\/bin\/python\r\n\r\nself = <tests.test_formatting.FormatterTest testMethod=test_jax_formatter_device>\r\n\r\n    @require_jax\r\n    def test_jax_formatter_device(self):\r\n        import jax\r\n    \r\n        from datasets.formatting import JaxFormatter\r\n    \r\n        pa_table = self._create_dummy_table()\r\n        device = jax.devices()[0]\r\n        formatter = JaxFormatter(device=str(device))\r\n        row = formatter.format_row(pa_table)\r\n>       assert row[\"a\"].device() == device\r\nE       AttributeError: 'jaxlib.xla_extension.DeviceList' object has no attribute 'device'. Did you mean: 'devices'?\r\n\r\ntests\/test_formatting.py:630: AttributeError\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6884\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6884\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6883","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6883\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6883\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6883\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6883","id":2284808399,"node_id":"PR_kwDODunzps5u1sL1","number":6883,"title":"Require Pillow >= 9.4.0 to avoid AttributeError when loading image dataset","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":7,"created_at":"2024-05-08T06:43:29Z","updated_at":"2024-05-21T18:37:55Z","closed_at":"2024-05-16T14:34:02Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6883","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6883","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6883.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6883.patch","merged_at":"2024-05-16T14:34:02Z"},"body":"Require Pillow >= 9.4.0 to avoid AttributeError when loading image dataset.\r\n\r\nThe `PIL.Image.ExifTags` that we use in our code was implemented in Pillow-9.4.0: https:\/\/github.com\/python-pillow\/Pillow\/commit\/24a5405a9f7ea22f28f9c98b3e407292ea5ee1d3\r\n\r\nThe bug #6881 was introduced in datasets-2.19.0 by this PR:\r\n- #6739\r\n\r\nFix #6881.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6883\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6883\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6882","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6882\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6882\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6882\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6882","id":2284803158,"node_id":"I_kwDODunzps6IL1RW","number":6882,"title":"Connection Error When Using By-pass Proxies","user":{"login":"MRNOBODY-ZST","id":78351684,"node_id":"MDQ6VXNlcjc4MzUxNjg0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/78351684?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST","html_url":"https:\/\/github.com\/MRNOBODY-ZST","followers_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/followers","following_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/orgs","repos_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/repos","events_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/MRNOBODY-ZST\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-05-08T06:40:14Z","updated_at":"2024-05-17T06:38:30Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI'm currently using Clash for Windows as my proxy tunnel, after exporting HTTP_PROXY and HTTPS_PROXY to the port that clash provides\ud83e\udd14, it runs into a connection error saying \"Couldn't reach https:\/\/raw.githubusercontent.com\/huggingface\/datasets\/2.19.1\/metrics\/seqeval\/seqeval.py (ConnectionError(MaxRetryError(\"HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: \/huggingface\/datasets\/2.19.1\/metrics\/seqeval\/seqeval.py (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f969d391870>: Failed to establish a new connection: [Errno 111] Connection refused'))\")))\"\r\nI have already read the documentation provided on the hugginface, but I think I didn't see the detailed instruction on how to set up proxies for this library.\n\n### Steps to reproduce the bug\n\n1. Turn on any proxy software like Clash \/ ShadosocksR etc.\r\n2. export system varibles to the port provided by your proxy software in wsl (It's ok for other applications to use proxy expect dataset-library)\r\n3. load any dataset from hugginface online\n\n### Expected behavior\n\n---------------------------------------------------------------------------\r\nConnectionError                           Traceback (most recent call last)\r\nCell In[33], [line 3](vscode-notebook-cell:?execution_count=33&line=3)\r\n      [1](vscode-notebook-cell:?execution_count=33&line=1) from datasets import load_metric\r\n----> [3](vscode-notebook-cell:?execution_count=33&line=3) metric = load_metric(\"seqeval\")\r\n\r\nFile ~\/.local\/lib\/python3.10\/site-packages\/datasets\/utils\/deprecation_utils.py:46, in deprecated.<locals>.decorator.<locals>.wrapper(*args, **kwargs)\r\n     [44](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/utils\/deprecation_utils.py:44)     warnings.warn(warning_msg, category=FutureWarning, stacklevel=2)\r\n     [45](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/utils\/deprecation_utils.py:45)     _emitted_deprecation_warnings.add(func_hash)\r\n---> [46](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/utils\/deprecation_utils.py:46) return deprecated_function(*args, **kwargs)\r\n\r\nFile ~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2104, in load_metric(path, config_name, process_id, num_process, cache_dir, experiment_id, keep_in_memory, download_config, download_mode, revision, trust_remote_code, **metric_init_kwargs)\r\n   [2101](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2101) warnings.filterwarnings(\"ignore\", message=\".*https:\/\/huggingface.co\/docs\/evaluate$\", category=FutureWarning)\r\n   [2103](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2103) download_mode = DownloadMode(download_mode or DownloadMode.REUSE_DATASET_IF_EXISTS)\r\n-> [2104](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2104) metric_module = metric_module_factory(\r\n   [2105](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2105)     path,\r\n   [2106](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2106)     revision=revision,\r\n   [2107](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2107)     download_config=download_config,\r\n   [2108](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2108)     download_mode=download_mode,\r\n   [2109](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2109)     trust_remote_code=trust_remote_code,\r\n   [2110](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2110) ).module_path\r\n   [2111](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2111) metric_cls = import_main_class(metric_module, dataset=False)\r\n   [2112](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2112) metric = metric_cls(\r\n   [2113](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2113)     config_name=config_name,\r\n   [2114](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/load.py:2114)     process_id=process_id,\r\n...\r\n--> [633](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/utils\/file_utils.py:633)     raise ConnectionError(f\"Couldn't reach {url} ({repr(head_error)})\")\r\n    [634](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/utils\/file_utils.py:634) elif response is not None:\r\n    [635](https:\/\/vscode-remote+wsl-002bubuntu-002d22-002e04.vscode-resource.vscode-cdn.net\/home\/noodle\/Transformers-Tutorials\/LayoutLMv3\/~\/.local\/lib\/python3.10\/site-packages\/datasets\/utils\/file_utils.py:635)     raise ConnectionError(f\"Couldn't reach {url} (error {response.status_code})\")\r\n\r\nConnectionError: Couldn't reach https:\/\/raw.githubusercontent.com\/huggingface\/datasets\/2.19.1\/metrics\/seqeval\/seqeval.py (SSLError(MaxRetryError(\"HTTPSConnectionPool(host='raw.githubusercontent.com', port=443): Max retries exceeded with url: \/huggingface\/datasets\/2.19.1\/metrics\/seqeval\/seqeval.py (Caused by SSLError(SSLEOFError(8, '[SSL: UNEXPECTED_EOF_WHILE_READING] EOF occurred in violation of protocol (_ssl.c:1007)')))\")))\n\n### Environment info\n\n- `datasets` version: 2.19.1\r\n- Platform: Linux-5.10.102.1-microsoft-standard-WSL2-x86_64-with-glibc2.35\r\n- Python version: 3.10.12\r\n- `huggingface_hub` version: 0.23.0\r\n- PyArrow version: 16.0.0\r\n- Pandas version: 2.2.2\r\n- `fsspec` version: 2024.2.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6882\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6882\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6881","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6881\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6881\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6881\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6881","id":2284794009,"node_id":"I_kwDODunzps6ILzCZ","number":6881,"title":"AttributeError: module 'PIL.Image' has no attribute 'ExifTags'","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-08T06:33:57Z","updated_at":"2024-05-16T14:34:03Z","closed_at":"2024-05-16T14:34:03Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"When trying to load an image dataset in an old Python environment (with Pillow-8.4.0), an error is raised:\r\n```Python traceback\r\nAttributeError: module 'PIL.Image' has no attribute 'ExifTags'\r\n```\r\nThe error traceback:\r\n```Python traceback\r\n~\/huggingface\/datasets\/src\/datasets\/iterable_dataset.py in __iter__(self)\r\n   1391                 # `IterableDataset` automatically fills missing columns with None.\r\n   1392                 # This is done with `_apply_feature_types_on_example`.\r\n-> 1393                 example = _apply_feature_types_on_example(\r\n   1394                     example, self.features, token_per_repo_id=self._token_per_repo_id\r\n   1395                 )\r\n\r\n~\/huggingface\/datasets\/src\/datasets\/iterable_dataset.py in _apply_feature_types_on_example(example, features, token_per_repo_id)\r\n   1080     encoded_example = features.encode_example(example)\r\n   1081     # Decode example for Audio feature, e.g.\r\n-> 1082     decoded_example = features.decode_example(encoded_example, token_per_repo_id=token_per_repo_id)\r\n   1083     return decoded_example\r\n   1084 \r\n\r\n~\/huggingface\/datasets\/src\/datasets\/features\/features.py in decode_example(self, example, token_per_repo_id)\r\n   1974 \r\n-> 1975         return {\r\n   1976             column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)\r\n   1977             if self._column_requires_decoding[column_name]\r\n\r\n~\/huggingface\/datasets\/src\/datasets\/features\/features.py in <dictcomp>(.0)\r\n   1974 \r\n   1975         return {\r\n-> 1976             column_name: decode_nested_example(feature, value, token_per_repo_id=token_per_repo_id)\r\n   1977             if self._column_requires_decoding[column_name]\r\n   1978             else value\r\n\r\n~\/huggingface\/datasets\/src\/datasets\/features\/features.py in decode_nested_example(schema, obj, token_per_repo_id)\r\n   1339         # we pass the token to read and decode files from private repositories in streaming mode\r\n   1340         if obj is not None and schema.decode:\r\n-> 1341             return schema.decode_example(obj, token_per_repo_id=token_per_repo_id)\r\n   1342     return obj\r\n   1343 \r\n\r\n~\/huggingface\/datasets\/src\/datasets\/features\/image.py in decode_example(self, value, token_per_repo_id)\r\n    187             image = PIL.Image.open(BytesIO(bytes_))\r\n    188         image.load()  # to avoid \"Too many open files\" errors\r\n--> 189         if image.getexif().get(PIL.Image.ExifTags.Base.Orientation) is not None:\r\n    190             image = PIL.ImageOps.exif_transpose(image)\r\n    191         if self.mode and self.mode != image.mode:\r\n\r\n~\/huggingface\/datasets\/venv\/lib\/python3.9\/site-packages\/PIL\/Image.py in __getattr__(name)\r\n     75                 )\r\n     76                 return categories[name]\r\n---> 77         raise AttributeError(f\"module '{__name__}' has no attribute '{name}'\")\r\n     78 \r\n     79 \r\n\r\nAttributeError: module 'PIL.Image' has no attribute 'ExifTags'\r\n```\r\n\r\n### Environment info\r\n\r\nSince datasets 2.19.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6881\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6881\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6880","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6880\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6880\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6880\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6880","id":2283278337,"node_id":"I_kwDODunzps6IGBAB","number":6880,"title":"Webdataset: KeyError: 'png' on some datasets when streaming","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2024-05-07T13:09:02Z","updated_at":"2024-05-14T20:34:05Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"reported at https:\/\/huggingface.co\/datasets\/tbone5563\/tar_images\/discussions\/1\r\n\r\n```python\r\n>>> from datasets import load_dataset\r\n>>> ds = load_dataset(\"tbone5563\/tar_images\")\r\nDownloading\u2007data:\u2007100%\r\n\u20071.41G\/1.41G\u2007[00:48<00:00,\u200717.2MB\/s]\r\nDownloading\u2007data:\u2007100%\r\n\u2007619M\/619M\u2007[00:11<00:00,\u200757.4MB\/s]\r\nGenerating\u2007train\u2007split:\u2007\r\n\u2007970\/0\u2007[00:02<00:00,\u2007534.94\u2007examples\/s]\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in _prepare_split_single(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\r\n   1747                 _time = time.time()\r\n-> 1748                 for key, record in generator:\r\n   1749                     if max_shard_size is not None and writer._num_bytes > max_shard_size:\r\n\r\n7 frames\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/packaged_modules\/webdataset\/webdataset.py](https:\/\/localhost:8080\/#) in _generate_examples(self, tar_paths, tar_iterators)\r\n    108                 for field_name in image_field_names + audio_field_names:\r\n--> 109                     example[field_name] = {\"path\": example[\"__key__\"] + \".\" + field_name, \"bytes\": example[field_name]}\r\n    110                 yield f\"{tar_idx}_{example_idx}\", example\r\n\r\nKeyError: 'png'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nDatasetGenerationError                    Traceback (most recent call last)\r\n[<ipython-input-2-8e0fbb7badc9>](https:\/\/localhost:8080\/#) in <cell line: 3>()\r\n      1 from datasets import load_dataset\r\n      2 \r\n----> 3 ds = load_dataset(\"tbone5563\/tar_images\")\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/load.py](https:\/\/localhost:8080\/#) in load_dataset(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\r\n   2607 \r\n   2608     # Download and prepare data\r\n-> 2609     builder_instance.download_and_prepare(\r\n   2610         download_config=download_config,\r\n   2611         download_mode=download_mode,\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in download_and_prepare(self, output_dir, download_config, download_mode, verification_mode, ignore_verifications, try_from_hf_gcs, dl_manager, base_path, use_auth_token, file_format, max_shard_size, num_proc, storage_options, **download_and_prepare_kwargs)\r\n   1025                         if num_proc is not None:\r\n   1026                             prepare_split_kwargs[\"num_proc\"] = num_proc\r\n-> 1027                         self._download_and_prepare(\r\n   1028                             dl_manager=dl_manager,\r\n   1029                             verification_mode=verification_mode,\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in _download_and_prepare(self, dl_manager, verification_mode, **prepare_splits_kwargs)\r\n   1787 \r\n   1788     def _download_and_prepare(self, dl_manager, verification_mode, **prepare_splits_kwargs):\r\n-> 1789         super()._download_and_prepare(\r\n   1790             dl_manager,\r\n   1791             verification_mode,\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in _download_and_prepare(self, dl_manager, verification_mode, **prepare_split_kwargs)\r\n   1120             try:\r\n   1121                 # Prepare split will record examples associated to the split\r\n-> 1122                 self._prepare_split(split_generator, **prepare_split_kwargs)\r\n   1123             except OSError as e:\r\n   1124                 raise OSError(\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in _prepare_split(self, split_generator, check_duplicate_keys, file_format, num_proc, max_shard_size)\r\n   1625             job_id = 0\r\n   1626             with pbar:\r\n-> 1627                 for job_id, done, content in self._prepare_split_single(\r\n   1628                     gen_kwargs=gen_kwargs, job_id=job_id, **_prepare_split_args\r\n   1629                 ):\r\n\r\n[\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py](https:\/\/localhost:8080\/#) in _prepare_split_single(self, gen_kwargs, fpath, file_format, max_shard_size, split_info, check_duplicate_keys, job_id)\r\n   1782             if isinstance(e, SchemaInferenceError) and e.__context__ is not None:\r\n   1783                 e = e.__context__\r\n-> 1784             raise DatasetGenerationError(\"An error occurred while generating the dataset\") from e\r\n   1785 \r\n   1786         yield job_id, True, (total_num_examples, total_num_bytes, writer._features, num_shards, shard_lengths)\r\n\r\nDatasetGenerationError: An error occurred while generating the dataset\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6880\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6880\/timeline","performed_via_github_app":null,"state_reason":"reopened"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6879","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6879\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6879\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6879\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6879","id":2282968259,"node_id":"I_kwDODunzps6IE1TD","number":6879,"title":"Batched mapping does not raise an error if values for an existing column are empty","user":{"login":"felix-schneider","id":208336,"node_id":"MDQ6VXNlcjIwODMzNg==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/208336?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/felix-schneider","html_url":"https:\/\/github.com\/felix-schneider","followers_url":"https:\/\/api.github.com\/users\/felix-schneider\/followers","following_url":"https:\/\/api.github.com\/users\/felix-schneider\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/felix-schneider\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/felix-schneider\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/felix-schneider\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/felix-schneider\/orgs","repos_url":"https:\/\/api.github.com\/users\/felix-schneider\/repos","events_url":"https:\/\/api.github.com\/users\/felix-schneider\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/felix-schneider\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-07T11:02:40Z","updated_at":"2024-05-07T11:02:40Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nUsing `Dataset.map(fn, batched=True)` allows resizing the dataset by returning a dict of lists, all of which must be the same size. If they are not the same size, an error like `pyarrow.lib.ArrowInvalid: Column 1 named x expected length 1 but got length 0` is raised.\r\n\r\nThis is not the case if the function returns an empty list for an existing column in the dataset. In that case, the dataset is silently resized to 0 rows.\n\n### Steps to reproduce the bug\n\nMWE:\r\n\r\n```\r\nimport datasets\r\ndata = datasets.Dataset.from_dict({\"test\": [1]})\r\n\r\ndef mapping_fn(examples):\r\n    return {\"test\": [], \"y\": [1]}\r\n\r\ndata = data.map(mapping_fn, batched=True)\r\nprint(len(data))\r\n```\r\n\r\nNote  that when returning `\"x\": []`, the error is raised correctly, also when returning `\"test\": [1,2]`.\n\n### Expected behavior\n\nExpected an exception: `pyarrow.lib.ArrowInvalid: Column 1 named test expected length 1 but got length 0` or `pyarrow.lib.ArrowInvalid: Column 2 named y expected length 0 but got length 1`.\r\n\r\nAny exception would be acceptable.\n\n### Environment info\n\n- `datasets` version: 2.19.1\r\n- Platform: Linux-5.4.0-153-generic-x86_64-with-glibc2.31\r\n- Python version: 3.11.8\r\n- `huggingface_hub` version: 0.22.2\r\n- PyArrow version: 15.0.2\r\n- Pandas version: 2.2.1\r\n- `fsspec` version: 2024.2.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6879\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6879\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6878","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6878\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6878\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6878\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6878","id":2282879491,"node_id":"PR_kwDODunzps5uviBh","number":6878,"title":"Create function to convert to parquet","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-07T10:27:07Z","updated_at":"2024-05-16T14:46:44Z","closed_at":"2024-05-16T14:38:23Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6878","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6878","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6878.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6878.patch","merged_at":"2024-05-16T14:38:22Z"},"body":"Analogously with `delete_from_hub`, this PR:\r\n- creates the Python function `convert_to_parquet`\r\n- makes the corresponding CLI command use that function.\r\n\r\nThis way, the functionality can be used both from a terminal and from a Python console.\r\n\r\nThis PR also implements a test for convert_to_parquet function.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6878\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6878\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6877","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6877\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6877\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6877\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6877","id":2282068337,"node_id":"I_kwDODunzps6IBZlx","number":6877,"title":"OSError: [Errno 24] Too many open files","user":{"login":"loicmagne","id":53355258,"node_id":"MDQ6VXNlcjUzMzU1MjU4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/53355258?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/loicmagne","html_url":"https:\/\/github.com\/loicmagne","followers_url":"https:\/\/api.github.com\/users\/loicmagne\/followers","following_url":"https:\/\/api.github.com\/users\/loicmagne\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/loicmagne\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/loicmagne\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/loicmagne\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/loicmagne\/orgs","repos_url":"https:\/\/api.github.com\/users\/loicmagne\/repos","events_url":"https:\/\/api.github.com\/users\/loicmagne\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/loicmagne\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2024-05-07T01:15:09Z","updated_at":"2024-05-13T15:36:08Z","closed_at":"2024-05-13T13:01:55Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI am trying to load the 'default' subset of the following dataset which contains lots of files (828 per split): [https:\/\/huggingface.co\/datasets\/mteb\/biblenlp-corpus-mmteb](https:\/\/huggingface.co\/datasets\/mteb\/biblenlp-corpus-mmteb)\r\n\r\nWhen trying to load it using the `load_dataset` function I get the following error\r\n\r\n```python\r\n>>> from datasets import load_dataset\r\n>>> d = load_dataset('mteb\/biblenlp-corpus-mmteb')\r\nDownloading readme: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 201k\/201k [00:00<00:00, 1.07MB\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 1069.15it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 436182.33it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 2228.75it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 646478.73it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 831032.24it\/s]\r\nResolving data files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:00<00:00, 517645.51it\/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:33<00:00, 24.87files\/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:30<00:00, 27.48files\/s]\r\nDownloading data: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 828\/828 [00:30<00:00, 26.94files\/s]\r\nGenerating train split: 1571592 examples [00:03, 461438.97 examples\/s]\r\nGenerating test split: 11163 examples [00:00, 118190.72 examples\/s]\r\nTraceback (most recent call last):\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1995, in _prepare_split_single\r\n    for _, table in generator:\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/packaged_modules\/json\/json.py\", line 99, in _generate_tables\r\n    with open(file, \"rb\") as f:\r\n         ^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/streaming.py\", line 75, in wrapper\r\n    return function(*args, download_config=download_config, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/utils\/file_utils.py\", line 1224, in xopen\r\n    file_obj = fsspec.open(file, mode=mode, *args, **kwargs).open()\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/core.py\", line 135, in open\r\n    return self.__enter__()\r\n           ^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/core.py\", line 103, in __enter__\r\n    f = self.fs.open(self.path, mode=mode)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/spec.py\", line 1293, in open\r\n    f = self._open(\r\n        ^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/filesystems\/compression.py\", line 81, in _open\r\n    return self.file.open()\r\n           ^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/core.py\", line 135, in open\r\n    return self.__enter__()\r\n           ^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/core.py\", line 103, in __enter__\r\n    f = self.fs.open(self.path, mode=mode)\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/spec.py\", line 1293, in open\r\n    f = self._open(\r\n        ^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/implementations\/local.py\", line 197, in _open\r\n    return LocalFileOpener(path, mode, fs=self, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/implementations\/local.py\", line 322, in __init__\r\n    self._open()\r\n  File \".env\/lib\/python3.12\/site-packages\/fsspec\/implementations\/local.py\", line 327, in _open\r\n    self.f = open(self.path, mode=self.mode)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nOSError: [Errno 24] Too many open files: '.cache\/huggingface\/datasets\/downloads\/3a347186abfc0f9c924dde0221d246db758c7232c0101523f04a87c17d696618'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 981, in incomplete_dir\r\n    yield tmp_dir\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1027, in download_and_prepare\r\n    self._download_and_prepare(\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1122, in _download_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1882, in _prepare_split\r\n    for job_id, done, content in self._prepare_split_single(\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 2038, in _prepare_split_single\r\n    raise DatasetGenerationError(\"An error occurred while generating the dataset\") from e\r\ndatasets.exceptions.DatasetGenerationError: An error occurred while generating the dataset\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/load.py\", line 2609, in load_dataset\r\n    builder_instance.download_and_prepare(\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1007, in download_and_prepare\r\n    with incomplete_dir(self._output_dir) as tmp_output_dir:\r\n  File \"\/usr\/lib\/python3.12\/contextlib.py\", line 158, in __exit__\r\n    self.gen.throw(value)\r\n  File \".env\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 988, in incomplete_dir\r\n    shutil.rmtree(tmp_dir)\r\n  File \"\/usr\/lib\/python3.12\/shutil.py\", line 785, in rmtree\r\n    _rmtree_safe_fd(fd, path, onexc)\r\n  File \"\/usr\/lib\/python3.12\/shutil.py\", line 661, in _rmtree_safe_fd\r\n    onexc(os.scandir, path, err)\r\n  File \"\/usr\/lib\/python3.12\/shutil.py\", line 657, in _rmtree_safe_fd\r\n    with os.scandir(topfd) as scandir_it:\r\n         ^^^^^^^^^^^^^^^^^\r\nOSError: [Errno 24] Too many open files: '.cache\/huggingface\/datasets\/mteb___biblenlp-corpus-mmteb\/default\/0.0.0\/3912ed967b0834547f35b2da9470c4976b357c9a.incomplete'\r\n\r\n\r\n```\r\n\r\nI looked for the maximum number of open files on my machine (Ubuntu 24.04) and it seems to be 1024, but even when I try to load a single split (`load_dataset('mteb\/biblenlp-corpus-mmteb', split='train')`) I get the same error\n\n### Steps to reproduce the bug\n\n```python\r\nfrom datasets import load_dataset\r\nd = load_dataset('mteb\/biblenlp-corpus-mmteb')\r\n```\n\n### Expected behavior\n\nLoad the dataset without error\n\n### Environment info\n\n- `datasets` version: 2.19.0\r\n- Platform: Linux-6.8.0-31-generic-x86_64-with-glibc2.39\r\n- Python version: 3.12.3\r\n- `huggingface_hub` version: 0.23.0\r\n- PyArrow version: 16.0.0\r\n- Pandas version: 2.2.2\r\n- `fsspec` version: 2024.3.1\r\n","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6877\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6877\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6876","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6876\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6876\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6876\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6876","id":2281450743,"node_id":"PR_kwDODunzps5uqs46","number":6876,"title":"Unpin hfh","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":12,"created_at":"2024-05-06T18:10:49Z","updated_at":"2024-05-27T10:20:42Z","closed_at":"2024-05-27T10:14:40Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6876","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6876","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6876.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6876.patch","merged_at":"2024-05-27T10:14:40Z"},"body":"Needed to use those in dataset-viewer:\r\n\r\n- dev version of hfh https:\/\/github.com\/huggingface\/dataset-viewer\/pull\/2781: don't span the hub with \/paths-info requests\r\n- dev version of datasets at https:\/\/github.com\/huggingface\/datasets\/pull\/6875: don't write too big logs in the viewer\r\n\r\nclose https:\/\/github.com\/huggingface\/datasets\/issues\/6863","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6876\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6876\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6875","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6875\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6875\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6875\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6875","id":2281428826,"node_id":"PR_kwDODunzps5uqoJ_","number":6875,"title":"Shorten long logs","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-06T17:57:07Z","updated_at":"2024-05-07T12:31:46Z","closed_at":"2024-05-07T12:25:45Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6875","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6875","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6875.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6875.patch","merged_at":"2024-05-07T12:25:45Z"},"body":"Some datasets may have unexpectedly long features\/types (e.g. if the files are not formatted correctly).\r\n\r\nIn that case we should still be able to log something readable","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6875\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6875\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6874","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6874\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6874\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6874\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6874","id":2280717233,"node_id":"PR_kwDODunzps5uoOk-","number":6874,"title":"Use pandas ujson in JSON loader to improve performance","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2024-05-06T12:01:27Z","updated_at":"2024-05-17T16:28:29Z","closed_at":"2024-05-17T16:22:27Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6874","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6874","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6874.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6874.patch","merged_at":"2024-05-17T16:22:27Z"},"body":"Use pandas ujson in JSON loader to improve performance.\r\n\r\nNote that `datasets` has `pandas` as required dependency. And `pandas` includes `ujson` in `pd.io.json.ujson_loads`.\r\n\r\nFix #6867.\r\n\r\nCC: @natolambert","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6874\/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6874\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6873","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6873\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6873\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6873\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6873","id":2280463182,"node_id":"PR_kwDODunzps5unXnq","number":6873,"title":"Set dev version","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-06T09:43:18Z","updated_at":"2024-05-06T10:03:19Z","closed_at":"2024-05-06T09:57:12Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6873","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6873","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6873.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6873.patch","merged_at":"2024-05-06T09:57:12Z"},"body":null,"reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6873\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6873\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6872","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6872\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6872\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6872\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6872","id":2280438432,"node_id":"PR_kwDODunzps5unSPA","number":6872,"title":"Release 2.19.1","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-06T09:29:15Z","updated_at":"2024-05-06T09:35:33Z","closed_at":"2024-05-06T09:35:32Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6872","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6872","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6872.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6872.patch","merged_at":"2024-05-06T09:35:32Z"},"body":null,"reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6872\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6872\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6871","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6871\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6871\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6871\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6871","id":2280102869,"node_id":"PR_kwDODunzps5umJS6","number":6871,"title":"Fix download for dict of dicts of URLs","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":4,"created_at":"2024-05-06T06:06:52Z","updated_at":"2024-05-06T09:32:03Z","closed_at":"2024-05-06T09:25:52Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6871","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6871","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6871.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6871.patch","merged_at":"2024-05-06T09:25:52Z"},"body":"Fix download for a dict of dicts of URLs when batched (default), introduced by:\r\n- #6794\r\n\r\nThis PR also implements regression tests.\r\n\r\nFix #6869, fix #6850.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6871\/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6871\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6870","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6870\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6870\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6870\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6870","id":2280084008,"node_id":"PR_kwDODunzps5umFOL","number":6870,"title":"Update tqdm >= 4.66.3 to fix vulnerability","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-06T05:49:36Z","updated_at":"2024-05-06T06:08:06Z","closed_at":"2024-05-06T06:02:00Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6870","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6870","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6870.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6870.patch","merged_at":"2024-05-06T06:02:00Z"},"body":"Update tqdm >= 4.66.3 to fix vulnerability,","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6870\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6870\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6869","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6869\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6869\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6869\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6869","id":2280048297,"node_id":"I_kwDODunzps6H5sap","number":6869,"title":"Download is broken for dict of dicts: FileNotFoundError","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-06T05:13:36Z","updated_at":"2024-05-06T09:25:53Z","closed_at":"2024-05-06T09:25:53Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"It seems there is a bug when downloading a dict of dicts of URLs introduced by:\r\n- #6794\r\n\r\n## Steps to reproduce the bug:\r\n```python\r\nfrom datasets import DownloadManager\r\n\r\ndl_manager = DownloadManager()\r\npaths = dl_manager.download({\"train\": {\"frr\": \"hf:\/\/datasets\/wikimedia\/wikipedia\/20231101.frr\/train-00000-of-00001.parquet\"}})\r\n```\r\n\r\nStack trace:\r\n```\r\n---------------------------------------------------------------------------\r\nFileNotFoundError                         Traceback (most recent call last)\r\n<ipython-input-7-0e0d76d25b09> in <module>\r\n----> 1 paths = dl_manager.download({\"train\": {\"frr\": \"hf:\/\/datasets\/wikimedia\/wikipedia\/20231101.frr\/train-00000-of-00001.parquet\"}})\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/download\/download_manager.py in download(self, url_or_urls)\r\n    255         start_time = datetime.now()\r\n    256         with stack_multiprocessing_download_progress_bars():\r\n--> 257             downloaded_path_or_paths = map_nested(\r\n    258                 download_func,\r\n    259                 url_or_urls,\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/utils\/py_utils.py in map_nested(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\r\n    506                 batch_size = max(len(iterable) \/\/ num_proc + int(len(iterable) % num_proc > 0), 1)\r\n    507             iterable = list(iter_batched(iterable, batch_size))\r\n--> 508         mapped = [\r\n    509             _single_map_nested((function, obj, batched, batch_size, types, None, True, None))\r\n    510             for obj in hf_tqdm(iterable, disable=disable_tqdm, desc=desc)\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/utils\/py_utils.py in <listcomp>(.0)\r\n    507             iterable = list(iter_batched(iterable, batch_size))\r\n    508         mapped = [\r\n--> 509             _single_map_nested((function, obj, batched, batch_size, types, None, True, None))\r\n    510             for obj in hf_tqdm(iterable, disable=disable_tqdm, desc=desc)\r\n    511         ]\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/utils\/py_utils.py in _single_map_nested(args)\r\n    375         and all(not isinstance(v, types) for v in data_struct)\r\n    376     ):\r\n--> 377         return [mapped_item for batch in iter_batched(data_struct, batch_size) for mapped_item in function(batch)]\r\n    378 \r\n    379     # Reduce logging to keep things readable in multiprocessing with tqdm\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/utils\/py_utils.py in <listcomp>(.0)\r\n    375         and all(not isinstance(v, types) for v in data_struct)\r\n    376     ):\r\n--> 377         return [mapped_item for batch in iter_batched(data_struct, batch_size) for mapped_item in function(batch)]\r\n    378 \r\n    379     # Reduce logging to keep things readable in multiprocessing with tqdm\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/download\/download_manager.py in _download_batched(self, url_or_filenames, download_config)\r\n    311             )\r\n    312         else:\r\n--> 313             return [\r\n    314                 self._download_single(url_or_filename, download_config=download_config)\r\n    315                 for url_or_filename in url_or_filenames\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/download\/download_manager.py in <listcomp>(.0)\r\n    312         else:\r\n    313             return [\r\n--> 314                 self._download_single(url_or_filename, download_config=download_config)\r\n    315                 for url_or_filename in url_or_filenames\r\n    316             ]\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/download\/download_manager.py in _download_single(self, url_or_filename, download_config)\r\n    321             # append the relative path to the base_path\r\n    322             url_or_filename = url_or_path_join(self._base_path, url_or_filename)\r\n--> 323         out = cached_path(url_or_filename, download_config=download_config)\r\n    324         out = tracked_str(out)\r\n    325         out.set_origin(url_or_filename)\r\n\r\n...\/huggingface\/datasets\/src\/datasets\/utils\/file_utils.py in cached_path(url_or_filename, download_config, **download_kwargs)\r\n    220     elif is_local_path(url_or_filename):\r\n    221         # File, but it doesn't exist.\r\n--> 222         raise FileNotFoundError(f\"Local file {url_or_filename} doesn't exist\")\r\n    223     else:\r\n    224         # Something unknown\r\n\r\nFileNotFoundError: Local file ...\/huggingface\/datasets\/{'frr': 'hf:\/datasets\/wikimedia\/wikipedia\/20231101.frr\/train-00000-of-00001.parquet'} doesn't exist\r\n```\r\n\r\nRelated to:\r\n- #6850\r\n","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6869\/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6869\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6868","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6868\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6868\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6868\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6868","id":2279385159,"node_id":"I_kwDODunzps6H3KhH","number":6868,"title":"datasets.BuilderConfig does not work.","user":{"login":"jdm4pku","id":148830652,"node_id":"U_kgDOCN75vA","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/148830652?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/jdm4pku","html_url":"https:\/\/github.com\/jdm4pku","followers_url":"https:\/\/api.github.com\/users\/jdm4pku\/followers","following_url":"https:\/\/api.github.com\/users\/jdm4pku\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/jdm4pku\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/jdm4pku\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/jdm4pku\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/jdm4pku\/orgs","repos_url":"https:\/\/api.github.com\/users\/jdm4pku\/repos","events_url":"https:\/\/api.github.com\/users\/jdm4pku\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/jdm4pku\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-05-05T08:08:55Z","updated_at":"2024-05-05T12:15:02Z","closed_at":"2024-05-05T12:15:01Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI custom a BuilderConfig and GeneratorBasedBuilder.\r\nHere is the code for BuilderConfig\r\n```\r\nclass UIEConfig(datasets.BuilderConfig):\r\n\r\n    def __init__(\r\n            self,\r\n            *args,\r\n            data_dir=None,\r\n            instruction_file=None,\r\n            instruction_strategy=None,\r\n            task_config_dir=None,\r\n            num_examples=None,\r\n            max_num_instances_per_task=None,\r\n            max_num_instances_per_eval_task=None,\r\n            over_sampling=None,\r\n            **kwargs\r\n    ):\r\n        super().__init__(*args, **kwargs)\r\n        self.data_dir = data_dir\r\n        self.num_examples = num_examples\r\n        self.over_sampling = over_sampling\r\n        self.instructions = self._parse_instruction(instruction_file)\r\n        self.task_configs = self._parse_task_config(task_config_dir)\r\n        self.instruction_strategy = instruction_strategy\r\n        self.max_num_instances_per_task = max_num_instances_per_task\r\n        self.max_num_instances_per_eval_task = max_num_instances_per_eval_task\r\n```\r\nBesides, here is the code for GeneratorBasedBuilder.\r\n```\r\nclass UIEInstructions(datasets.GeneratorBasedBuilder):\r\n    VERSION = datasets.Version(\"2.0.0\")\r\n    BUILDER_CONFIG_CLASS = UIEConfig\r\n    BUILDER_CONFIGS = [\r\n        UIEConfig(name=\"default\", description=\"Default config for NaturalInstructions\")\r\n    ]\r\n    DEFAULT_CONFIG_NAME = \"default\"\r\n```\r\n\r\nHere is the load_dataset\r\n```\r\nraw_datasets = load_dataset(\r\n        os.path.join(CURRENT_DIR, \"uie_dataset.py\"),\r\n        data_dir=data_args.data_dir,\r\n        task_config_dir=data_args.task_config_dir,\r\n        instruction_file=data_args.instruction_file,\r\n        instruction_strategy=data_args.instruction_strategy,\r\n        cache_dir=data_cache_dir,  # for debug, change dataset size, otherwise open it\r\n        max_num_instances_per_task=data_args.max_num_instances_per_task,\r\n        max_num_instances_per_eval_task=data_args.max_num_instances_per_eval_task,\r\n        num_examples=data_args.num_examples,\r\n        over_sampling=data_args.over_sampling\r\n    )\r\n```\r\nFinally, I met the error.\r\n```\r\nBuilderConfig UIEConfig(name='default', version=0.0.0, data_dir=None, data_files=None, description='Default config for NaturalInstructions') doesn't have a 'task_config_dir' key.\r\n```\r\n\r\nI debugged the code, but I find the parameters added by me may not work.\n\n### Steps to reproduce the bug\n\nhttps:\/\/github.com\/BeyonderXX\/InstructUIE\/blob\/master\/src\/uie_dataset.py\n\n### Expected behavior\n\n```\r\nBuilderConfig UIEConfig(name='default', version=0.0.0, data_dir=None, data_files=None, description='Default config for NaturalInstructions') doesn't have a 'task_config_dir' key.\r\n```\n\n### Environment info\n\ntorch                     2.3.0+cu118\r\ntransformers              4.40.1\r\npython 3.8","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6868\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6868\/timeline","performed_via_github_app":null,"state_reason":"not_planned"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6867","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6867\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6867\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6867\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6867","id":2279059787,"node_id":"I_kwDODunzps6H17FL","number":6867,"title":"Improve performance of JSON loader","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":5,"created_at":"2024-05-04T15:04:16Z","updated_at":"2024-05-17T16:22:28Z","closed_at":"2024-05-17T16:22:28Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"As reported by @natolambert, loading regular JSON files with `datasets` shows poor performance.\r\n\r\nThe cause is that we use the `json` Python standard library instead of other faster libraries. See my old comment: https:\/\/github.com\/huggingface\/datasets\/pull\/2638#pullrequestreview-706983714\r\n> There are benchmarks that compare different JSON packages, with the Standard Library one among the worst performant: \r\n> - https:\/\/github.com\/ultrajson\/ultrajson#benchmarks\r\n> - https:\/\/github.com\/ijl\/orjson#performance\r\n\r\nI remember having a discussion about this and it was decided that it was better not to include an additional dependency on a 3rd-party library.\r\n\r\nHowever:\r\n- We already depend on `pandas` and `pandas` depends on `ujson`: so we have an indirect dependency on `ujson`\r\n- Even if the above were not the case, we always could include `ujson` as an optional extra dependency, and check at runtime if it is installed to decide which library to use, either json or ujson","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6867\/reactions","total_count":3,"+1":3,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6867\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6866","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6866\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6866\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6866\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6866","id":2278736221,"node_id":"I_kwDODunzps6H0sFd","number":6866,"title":"DataFilesNotFoundError for datasets in the open-llm-leaderboard","user":{"login":"jerome-white","id":6140840,"node_id":"MDQ6VXNlcjYxNDA4NDA=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/6140840?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/jerome-white","html_url":"https:\/\/github.com\/jerome-white","followers_url":"https:\/\/api.github.com\/users\/jerome-white\/followers","following_url":"https:\/\/api.github.com\/users\/jerome-white\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/jerome-white\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/jerome-white\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/jerome-white\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/jerome-white\/orgs","repos_url":"https:\/\/api.github.com\/users\/jerome-white\/repos","events_url":"https:\/\/api.github.com\/users\/jerome-white\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/jerome-white\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2024-05-04T04:59:00Z","updated_at":"2024-05-14T08:09:56Z","closed_at":"2024-05-14T08:09:56Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nWhen trying to get config names or load any dataset within the open-llm-leaderboard ecosystem (`open-llm-leaderboard\/details_`) I receive the DataFilesNotFoundError. For the last month or so I've been loading datasets from the leaderboard almost everyday; yesterday was the first time I started seeing this.\n\n### Steps to reproduce the bug\n\nThis snippet has three cells:\r\n1. Loads the modules\r\n2. Tries to get config names\r\n3. Tries to load the dataset\r\n\r\nI've chosen \"davidkim205\"'s Rhea-72b-v0.5 model because it is one of the best performers on the leaderboard should likely have no dataset issues:\r\n\r\n```python\r\nIn [1]: from datasets import load_dataset, get_dataset_config_names\r\n\r\nIn [2]: get_dataset_config_names(\"open-llm-leaderboard\/details_davidkim205__Rhea\r\n   ...: -72b-v0.5\")\r\n---------------------------------------------------------------------------\r\nDataFilesNotFoundError                    Traceback (most recent call last)\r\nCell In[2], line 1\r\n----> 1 get_dataset_config_names(\"open-llm-leaderboard\/details_davidkim205__Rhea-72b-v0.5\")\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/inspect.py:347, in get_dataset_config_names(path, revision, download_config, download_mode, dynamic_modules_path, data_files, **download_kwargs)\r\n    291 def get_dataset_config_names(\r\n    292     path: str,\r\n    293     revision: Optional[Union[str, Version]] = None,\r\n   (...)\r\n    298     **download_kwargs,\r\n    299 ):\r\n    300     \"\"\"Get the list of available config names for a particular dataset.\r\n    301 \r\n    302     Args:\r\n   (...)\r\n    345     ```\r\n    346     \"\"\"\r\n--> 347     dataset_module = dataset_module_factory(\r\n    348         path,\r\n    349         revision=revision,\r\n    350         download_config=download_config,\r\n    351         download_mode=download_mode,\r\n    352         dynamic_modules_path=dynamic_modules_path,\r\n    353         data_files=data_files,\r\n    354         **download_kwargs,\r\n    355     )\r\n    356     builder_cls = get_dataset_builder_class(dataset_module, dataset_name=os.path.basename(path))\r\n    357     return list(builder_cls.builder_configs.keys()) or [\r\n    358         dataset_module.builder_kwargs.get(\"config_name\", builder_cls.DEFAULT_CONFIG_NAME or \"default\")\r\n    359     ]\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:1821, in dataset_module_factory(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\r\n   1812     return LocalDatasetModuleFactoryWithScript(\r\n   1813         combined_path,\r\n   1814         download_mode=download_mode,\r\n   1815         dynamic_modules_path=dynamic_modules_path,\r\n   1816         trust_remote_code=trust_remote_code,\r\n   1817     ).get_module()\r\n   1818 elif os.path.isdir(path):\r\n   1819     return LocalDatasetModuleFactoryWithoutScript(\r\n   1820         path, data_dir=data_dir, data_files=data_files, download_mode=download_mode\r\n-> 1821     ).get_module()\r\n   1822 # Try remotely\r\n   1823 elif is_relative_path(path) and path.count(\"\/\") <= 1:\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:1039, in LocalDatasetModuleFactoryWithoutScript.get_module(self)\r\n   1033     patterns = get_data_patterns(base_path)\r\n   1034 data_files = DataFilesDict.from_patterns(\r\n   1035     patterns,\r\n   1036     base_path=base_path,\r\n   1037     allowed_extensions=ALL_ALLOWED_EXTENSIONS,\r\n   1038 )\r\n-> 1039 module_name, default_builder_kwargs = infer_module_for_data_files(\r\n   1040     data_files=data_files,\r\n   1041     path=self.path,\r\n   1042 )\r\n   1043 data_files = data_files.filter_extensions(_MODULE_TO_EXTENSIONS[module_name])\r\n   1044 # Collect metadata files if the module supports them\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:597, in infer_module_for_data_files(data_files, path, download_config)\r\n    595     raise ValueError(f\"Couldn't infer the same data file format for all splits. Got {split_modules}\")\r\n    596 if not module_name:\r\n--> 597     raise DataFilesNotFoundError(\"No (supported) data files found\" + (f\" in {path}\" if path else \"\"))\r\n    598 return module_name, default_builder_kwargs\r\n\r\nDataFilesNotFoundError: No (supported) data files found in open-llm-leaderboard\/details_davidkim205__Rhea-72b-v0.5\r\n\r\nIn [3]: data = load_dataset(\"open-llm-leaderboard\/details_davidkim205__Rhea-72b-\r\n   ...: v0.5\", \"harness_winogrande_5\")\r\n---------------------------------------------------------------------------\r\nDataFilesNotFoundError                    Traceback (most recent call last)\r\nCell In[3], line 1\r\n----> 1 data = load_dataset(\"open-llm-leaderboard\/details_davidkim205__Rhea-72b-v0.5\", \"harness_winogrande_5\")\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:2587, in load_dataset(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\r\n   2582 verification_mode = VerificationMode(\r\n   2583     (verification_mode or VerificationMode.BASIC_CHECKS) if not save_infos else VerificationMode.ALL_CHECKS\r\n   2584 )\r\n   2586 # Create a dataset builder\r\n-> 2587 builder_instance = load_dataset_builder(\r\n   2588     path=path,\r\n   2589     name=name,\r\n   2590     data_dir=data_dir,\r\n   2591     data_files=data_files,\r\n   2592     cache_dir=cache_dir,\r\n   2593     features=features,\r\n   2594     download_config=download_config,\r\n   2595     download_mode=download_mode,\r\n   2596     revision=revision,\r\n   2597     token=token,\r\n   2598     storage_options=storage_options,\r\n   2599     trust_remote_code=trust_remote_code,\r\n   2600     _require_default_config_name=name is None,\r\n   2601     **config_kwargs,\r\n   2602 )\r\n   2604 # Return iterable dataset in case of streaming\r\n   2605 if streaming:\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:2259, in load_dataset_builder(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\r\n   2257     download_config = download_config.copy() if download_config else DownloadConfig()\r\n   2258     download_config.storage_options.update(storage_options)\r\n-> 2259 dataset_module = dataset_module_factory(\r\n   2260     path,\r\n   2261     revision=revision,\r\n   2262     download_config=download_config,\r\n   2263     download_mode=download_mode,\r\n   2264     data_dir=data_dir,\r\n   2265     data_files=data_files,\r\n   2266     cache_dir=cache_dir,\r\n   2267     trust_remote_code=trust_remote_code,\r\n   2268     _require_default_config_name=_require_default_config_name,\r\n   2269     _require_custom_configs=bool(config_kwargs),\r\n   2270 )\r\n   2271 # Get dataset builder class from the processing script\r\n   2272 builder_kwargs = dataset_module.builder_kwargs\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:1821, in dataset_module_factory(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\r\n   1812     return LocalDatasetModuleFactoryWithScript(\r\n   1813         combined_path,\r\n   1814         download_mode=download_mode,\r\n   1815         dynamic_modules_path=dynamic_modules_path,\r\n   1816         trust_remote_code=trust_remote_code,\r\n   1817     ).get_module()\r\n   1818 elif os.path.isdir(path):\r\n   1819     return LocalDatasetModuleFactoryWithoutScript(\r\n   1820         path, data_dir=data_dir, data_files=data_files, download_mode=download_mode\r\n-> 1821     ).get_module()\r\n   1822 # Try remotely\r\n   1823 elif is_relative_path(path) and path.count(\"\/\") <= 1:\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:1039, in LocalDatasetModuleFactoryWithoutScript.get_module(self)\r\n   1033     patterns = get_data_patterns(base_path)\r\n   1034 data_files = DataFilesDict.from_patterns(\r\n   1035     patterns,\r\n   1036     base_path=base_path,\r\n   1037     allowed_extensions=ALL_ALLOWED_EXTENSIONS,\r\n   1038 )\r\n-> 1039 module_name, default_builder_kwargs = infer_module_for_data_files(\r\n   1040     data_files=data_files,\r\n   1041     path=self.path,\r\n   1042 )\r\n   1043 data_files = data_files.filter_extensions(_MODULE_TO_EXTENSIONS[module_name])\r\n   1044 # Collect metadata files if the module supports them\r\n\r\nFile ~\/open-llm-bda\/venv\/lib\/python3.11\/site-packages\/datasets\/load.py:597, in infer_module_for_data_files(data_files, path, download_config)\r\n    595     raise ValueError(f\"Couldn't infer the same data file format for all splits. Got {split_modules}\")\r\n    596 if not module_name:\r\n--> 597     raise DataFilesNotFoundError(\"No (supported) data files found\" + (f\" in {path}\" if path else \"\"))\r\n    598 return module_name, default_builder_kwargs\r\n\r\nDataFilesNotFoundError: No (supported) data files found in open-llm-leaderboard\/details_davidkim205__Rhea-72b-v0.5\r\n```\n\n### Expected behavior\n\nNo exceptions from `get_dataset_config_names` or `load_dataset`\n\n### Environment info\n\n- `datasets` version: 2.19.0\r\n- Platform: Linux-6.5.0-1018-aws-aarch64-with-glibc2.35\r\n- Python version: 3.11.8\r\n- `huggingface_hub` version: 0.23.0\r\n- PyArrow version: 16.0.0\r\n- Pandas version: 2.2.2\r\n- `fsspec` version: 2024.3.1","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6866\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6866\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6865","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6865\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6865\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6865\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6865","id":2277304832,"node_id":"I_kwDODunzps6HvOoA","number":6865,"title":"Example on Semantic segmentation contains bug","user":{"login":"ducha-aiki","id":4803565,"node_id":"MDQ6VXNlcjQ4MDM1NjU=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/4803565?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/ducha-aiki","html_url":"https:\/\/github.com\/ducha-aiki","followers_url":"https:\/\/api.github.com\/users\/ducha-aiki\/followers","following_url":"https:\/\/api.github.com\/users\/ducha-aiki\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/ducha-aiki\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/ducha-aiki\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/ducha-aiki\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/ducha-aiki\/orgs","repos_url":"https:\/\/api.github.com\/users\/ducha-aiki\/repos","events_url":"https:\/\/api.github.com\/users\/ducha-aiki\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/ducha-aiki\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-03T09:40:12Z","updated_at":"2024-05-03T09:40:12Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nhttps:\/\/huggingface.co\/docs\/datasets\/en\/semantic_segmentation shows wrong example with torchvision transforms.\r\nSpecifically, as one can see in screenshot below, the object boundaries have weird colors. \r\n\r\n<img width=\"689\" alt=\"image\" src=\"https:\/\/github.com\/huggingface\/datasets\/assets\/4803565\/59aa0e2c-2e3e-415b-9d42-2314044c5aee\">\r\n\r\n\r\nOriginal example with `albumentations` is correct \r\n<img width=\"705\" alt=\"image\" src=\"https:\/\/github.com\/huggingface\/datasets\/assets\/4803565\/27dbd725-cea5-4e48-ba59-7050c3ce17b3\">\r\n\r\n\r\nThat is because `torch vision.transforms.Resize` interpolates with bilinear everything which is wrong when used for segmentation labels - you just cannot mix them. Overall, `torchvision.transforms` is designed for classification only and cannot be used to images and masks together, unless you write two separate branches of augmentations.\r\n\r\n\r\nThe correct way would be to use `v2` version of transforms and convert the segmentation labels to https:\/\/pytorch.org\/vision\/main\/generated\/torchvision.tv_tensors.Mask.html#torchvision.tv_tensors.Mask object\r\n\r\n\r\n\n\n### Steps to reproduce the bug\n\nGo to the website.\r\n<img width=\"689\" alt=\"image\" src=\"https:\/\/github.com\/huggingface\/datasets\/assets\/4803565\/ea1276d0-d69a-48cf-b9c2-cd61217815ef\">\r\n\r\nhttps:\/\/huggingface.co\/docs\/datasets\/en\/semantic_segmentation\n\n### Expected behavior\n\nResults, similar to `albumentation`. Or remove the torch vision part altogether. Or use `kornia` instead.\n\n### Environment info\n\nIrrelevant","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6865\/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6865\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6864","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6864\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6864\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6864\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6864","id":2276986981,"node_id":"I_kwDODunzps6HuBBl","number":6864,"title":"Dataset 'rewardsignal\/reddit_writing_prompts' doesn't exist on the Hub","user":{"login":"vinodrajendran001","id":5783246,"node_id":"MDQ6VXNlcjU3ODMyNDY=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/5783246?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/vinodrajendran001","html_url":"https:\/\/github.com\/vinodrajendran001","followers_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/followers","following_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/orgs","repos_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/repos","events_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/vinodrajendran001\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2024-05-03T06:03:30Z","updated_at":"2024-05-06T06:36:42Z","closed_at":"2024-05-06T06:36:41Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nThe dataset `rewardsignal\/reddit_writing_prompts` is missing in Huggingface Hub.\r\n\r\n### Steps to reproduce the bug\r\n\r\n```\r\nfrom datasets import load_dataset\r\n\r\nprompt_response_dataset = load_dataset(\"rewardsignal\/reddit_writing_prompts\", data_files=\"prompt_responses_full.csv\", split='train[:80%]')\r\n```\r\n\r\n### Expected behavior\r\n\r\nDatasetNotFoundError: Dataset 'rewardsignal\/reddit_writing_prompts' doesn't exist on the Hub or cannot be accessed\r\n\r\n### Environment info\r\n\r\nNothing to do with versions","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6864\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6864\/timeline","performed_via_github_app":null,"state_reason":"not_planned"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6863","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6863\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6863\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6863\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6863","id":2276977534,"node_id":"I_kwDODunzps6Ht-t-","number":6863,"title":"Revert temporary pin huggingface-hub < 0.23.0","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-03T05:53:55Z","updated_at":"2024-05-27T10:14:41Z","closed_at":"2024-05-27T10:14:41Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"Revert temporary pin huggingface-hub < 0.23.0 introduced by\r\n- #6861\r\n\r\nonce the following issue is fixed and released:\r\n- huggingface\/transformers#30618","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6863\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6863\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6862","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6862\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6862\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6862\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6862","id":2276763745,"node_id":"PR_kwDODunzps5ubOoL","number":6862,"title":"Issue 6598: load_dataset broken for data_files on s3","user":{"login":"matstrand","id":544843,"node_id":"MDQ6VXNlcjU0NDg0Mw==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/544843?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/matstrand","html_url":"https:\/\/github.com\/matstrand","followers_url":"https:\/\/api.github.com\/users\/matstrand\/followers","following_url":"https:\/\/api.github.com\/users\/matstrand\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/matstrand\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/matstrand\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/matstrand\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/matstrand\/orgs","repos_url":"https:\/\/api.github.com\/users\/matstrand\/repos","events_url":"https:\/\/api.github.com\/users\/matstrand\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/matstrand\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-03T01:43:47Z","updated_at":"2024-05-03T09:04:55Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6862","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6862","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6862.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6862.patch","merged_at":null},"body":"Fixes huggingface\/datasets\/issues\/6598\r\n\r\nI've added a new test case and a solution. Before applying the solution the test case was failing with the same error described in the linked issue. I encountered this issue while following the Hugging Face documentation, trying to perform GPT-2 fine-tuning using `run_clm.py` on SageMaker with a data file stored on S3. \r\n\r\nMRE:\r\n```\r\npip install \"datasets[s3]\"\r\npython -c \"from datasets import load_dataset; load_dataset('csv', data_files={'train': 's3:\/\/noaa-gsod-pds\/2024\/A5125600451.csv'})\"\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6862\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6862\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6861","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6861\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6861\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6861\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6861","id":2275988990,"node_id":"PR_kwDODunzps5uYkMy","number":6861,"title":"Fix CI by temporarily pinning huggingface-hub < 0.23.0","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-02T16:40:04Z","updated_at":"2024-05-02T16:59:42Z","closed_at":"2024-05-02T16:53:42Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6861","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6861","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6861.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6861.patch","merged_at":"2024-05-02T16:53:42Z"},"body":"As a hotfix for CI, temporarily pin `huggingface-hub` upper version\r\n\r\nFix #6860.\r\n\r\nRevert once root cause is fixed, see:\r\n- https:\/\/github.com\/huggingface\/transformers\/issues\/30618","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6861\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6861\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6860","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6860\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6860\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6860\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6860","id":2275537137,"node_id":"I_kwDODunzps6HofDx","number":6860,"title":"CI fails after huggingface_hub-0.23.0 release: FutureWarning: \"resume_download\"","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2024-05-02T13:24:17Z","updated_at":"2024-05-02T16:53:45Z","closed_at":"2024-05-02T16:53:45Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"CI fails after latest huggingface_hub-0.23.0 release: https:\/\/github.com\/huggingface\/huggingface_hub\/releases\/tag\/v0.23.0\r\n\r\n```\r\nFAILED tests\/test_metric_common.py::LocalMetricTest::test_load_metric_bertscore - FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\nFAILED tests\/test_metric_common.py::LocalMetricTest::test_load_metric_frugalscore - FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\nFAILED tests\/test_metric_common.py::LocalMetricTest::test_load_metric_perplexity - FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\nFAILED tests\/test_fingerprint.py::TokenizersHashTest::test_hash_tokenizer - FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\nFAILED tests\/test_fingerprint.py::TokenizersHashTest::test_hash_tokenizer_with_cache - FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\nFAILED tests\/test_arrow_dataset.py::MiscellaneousDatasetTest::test_set_format_encode - FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6860\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6860\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6859","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6859\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6859\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6859\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6859","id":2274996774,"node_id":"PR_kwDODunzps5uVIoZ","number":6859,"title":"Support folder-based datasets with large metadata.jsonl","user":{"login":"gbenson","id":580564,"node_id":"MDQ6VXNlcjU4MDU2NA==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/580564?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/gbenson","html_url":"https:\/\/github.com\/gbenson","followers_url":"https:\/\/api.github.com\/users\/gbenson\/followers","following_url":"https:\/\/api.github.com\/users\/gbenson\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/gbenson\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/gbenson\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/gbenson\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/gbenson\/orgs","repos_url":"https:\/\/api.github.com\/users\/gbenson\/repos","events_url":"https:\/\/api.github.com\/users\/gbenson\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/gbenson\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-05-02T09:07:26Z","updated_at":"2024-05-02T09:07:26Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6859","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6859","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6859.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6859.patch","merged_at":null},"body":"I tried creating an `imagefolder` dataset with a 714MB `metadata.jsonl` but got the error below.  This pull request fixes the problem by increasing the block size like the message suggests.\r\n```\r\n>>> from datasets import load_dataset\r\n>>> dataset = load_dataset(\"imagefolder\", data_dir=\"data-for-upload\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"\/path\/to\/datasets\/load.py\", line 2609, in load_dataset\r\n    builder_instance.download_and_prepare(\r\n      ...\r\n  File \"\/path\/to\/datasets\/packaged_modules\/folder_based_builder\/folder_based_builder.py\", line 245, in _read_metadata\r\n    return paj.read_json(f)\r\n  File \"pyarrow\/_json.pyx\", line 308, in pyarrow._json.read_json\r\n  File \"pyarrow\/error.pxi\", line 154, in pyarrow.lib.pyarrow_internal_check_status\r\n  File \"pyarrow\/error.pxi\", line 91, in pyarrow.lib.check_status\r\npyarrow.lib.ArrowInvalid: straddling object straddles two block boundaries (try to increase block size?)\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6859\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6859\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6858","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6858\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6858\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6858\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6858","id":2274917185,"node_id":"I_kwDODunzps6HmHtB","number":6858,"title":"Segmentation fault","user":{"login":"scampion","id":554155,"node_id":"MDQ6VXNlcjU1NDE1NQ==","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/554155?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/scampion","html_url":"https:\/\/github.com\/scampion","followers_url":"https:\/\/api.github.com\/users\/scampion\/followers","following_url":"https:\/\/api.github.com\/users\/scampion\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/scampion\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/scampion\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/scampion\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/scampion\/orgs","repos_url":"https:\/\/api.github.com\/users\/scampion\/repos","events_url":"https:\/\/api.github.com\/users\/scampion\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/scampion\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-02T08:28:49Z","updated_at":"2024-05-03T08:43:21Z","closed_at":"2024-05-03T08:42:36Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nUsing various version for datasets, I'm no more longer able to load that dataset without a segmentation fault. \r\nSeveral others files are also concerned. \n\n### Steps to reproduce the bug\n\n# Create a new venv \r\npython3 -m venv venv_test \r\nsource venv_test\/bin\/activate\r\n\r\n# Install the latest version \r\npip install datasets\r\n\r\n# Load that dataset\r\npython3 -q -X faulthandler -c \"from datasets import load_dataset;  load_dataset('EuropeanParliament\/Eurovoc', '1998-09')\"\n\n### Expected behavior\n\nData must be loaded \n\n### Environment info\n\ndatasets==2.19.0\r\nPython 3.11.7\r\nDarwin  22.5.0 Darwin Kernel Version 22.5.0: Mon Apr 24 20:51:50 PDT 2023; root:xnu-8796.121.2~5\/RELEASE_X86_64 x86_64","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6858\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6858\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6857","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6857\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6857\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6857\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6857","id":2274849730,"node_id":"PR_kwDODunzps5uUooF","number":6857,"title":"Fix line-endings in tests on Windows","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-05-02T07:49:15Z","updated_at":"2024-05-02T11:49:35Z","closed_at":"2024-05-02T11:43:00Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6857","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6857","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6857.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6857.patch","merged_at":"2024-05-02T11:43:00Z"},"body":"EDIT:\r\n~~Fix test_delete_from_hub on Windows by passing explicit encoding.~~\r\nFix test_delete_from_hub and test_xgetsize_private by uploading the README file content directly (encoding the string), instead of writing a local file and uploading it.\r\n\r\nNote that local files created on Windows will have \"\\r\\n\" line endings, instead of \"\\n\".\r\nThese are no longer transformed to \"\\n\" by the Hub.\r\n\r\nFix #6856.","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6857\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6857\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6856","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6856\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6856\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6856\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6856","id":2274828933,"node_id":"I_kwDODunzps6HlyKF","number":6856,"title":"CI fails on Windows for test_delete_from_hub and test_xgetsize_private due to new-line character","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":1,"created_at":"2024-05-02T07:37:03Z","updated_at":"2024-05-02T11:43:01Z","closed_at":"2024-05-02T11:43:01Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"CI fails on Windows for test_delete_from_hub after the merge of:\r\n- #6820\r\n\r\nThis is weird because the CI was green in the PR branch before merging to main.\r\n\r\n```\r\nFAILED tests\/test_hub.py::test_delete_from_hub - AssertionError: assert [CommitOperat...\\r\\n---\\r\\n')] == [CommitOperat...in\/*\\n---\\n')]\r\n  \r\n  At index 1 diff: CommitOperationAdd(path_in_repo='README.md', path_or_fileobj=b'---\\r\\nconfigs:\\r\\n- config_name: cats\\r\\n  data_files:\\r\\n  - split: train\\r\\n    path: cats\/train\/*\\r\\n---\\r\\n') != CommitOperationAdd(path_in_repo='README.md', path_or_fileobj=b'---\\nconfigs:\\n- config_name: cats\\n  data_files:\\n  - split: train\\n    path: cats\/train\/*\\n---\\n')\r\n  \r\n  Full diff:\r\n    [\r\n        CommitOperationDelete(\r\n            path_in_repo='dogs\/train\/0000.csv',\r\n            is_folder=False,\r\n        ),\r\n        CommitOperationAdd(\r\n            path_in_repo='README.md',\r\n  -         path_or_fileobj=b'---\\nconfigs:\\n- config_name: cats\\n  data_files:\\n '\r\n  ?                                                                       --------\r\n  +         path_or_fileobj=b'---\\r\\nconfigs:\\r\\n- config_name: cats\\r\\n  data_f'\r\n  ?                               ++          ++                     ++\r\n  -                         b' - split: train\\n    path: cats\/train\/*\\n---\\n',\r\n  ?                                                                   ^^^^^^ -\r\n  +                         b'iles:\\r\\n  - split: train\\r\\n    path: cats\/train\/*\\r'\r\n  ?                           ++++++++++                ++                        ^\r\n  +                         b'\\n---\\r\\n',\r\n        ),\r\n    ]\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6856\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6856\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6855","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6855\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6855\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6855\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6855","id":2274777812,"node_id":"PR_kwDODunzps5uUZNT","number":6855,"title":"Fix dataset name for community Hub script-datasets","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":6,"created_at":"2024-05-02T07:05:44Z","updated_at":"2024-05-03T15:58:00Z","closed_at":"2024-05-03T15:51:57Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6855","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6855","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6855.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6855.patch","merged_at":"2024-05-03T15:51:57Z"},"body":"Fix dataset name for community Hub script-datasets by passing explicit dataset_name to HubDatasetModuleFactoryWithScript.\r\n\r\nFix #6854.\r\n\r\nCC: @Wauplin ","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6855\/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6855\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6854","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6854\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6854\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6854\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6854","id":2274767686,"node_id":"I_kwDODunzps6HljNG","number":6854,"title":"Wrong example of usage when config name is missing for community script-datasets","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892857,"node_id":"MDU6TGFiZWwxOTM1ODkyODU3","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/bug","name":"bug","color":"d73a4a","default":true,"description":"Something isn't working"}],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2024-05-02T06:59:39Z","updated_at":"2024-05-03T15:51:59Z","closed_at":"2024-05-03T15:51:58Z","author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"As reported by @Wauplin, when loading a community dataset with script, there is a bug in the example of usage of the error message if the dataset has multiple configs (and no default config) and the user does not pass any config. For example:\r\n```python\r\n>>> ds = load_dataset(\"google\/fleurs\")\r\nValueError: Config name is missing.\r\nPlease pick one among the available configs: ['af_za', 'am_et', 'ar_eg', 'as_in', 'ast_es', 'az_az', 'be_by', 'bg_bg', 'bn_in', 'bs_ba', 'ca_es', 'ceb_ph', 'ckb_iq', 'cmn_hans_cn', 'cs_cz', 'cy_gb', 'da_dk', 'de_de', 'el_gr', 'en_us', 'es_419', 'et_ee', 'fa_ir', 'ff_sn', 'fi_fi', 'fil_ph', 'fr_fr', 'ga_ie', 'gl_es', 'gu_in', 'ha_ng', 'he_il', 'hi_in', 'hr_hr', 'hu_hu', 'hy_am', 'id_id', 'ig_ng', 'is_is', 'it_it', 'ja_jp', 'jv_id', 'ka_ge', 'kam_ke', 'kea_cv', 'kk_kz', 'km_kh', 'kn_in', 'ko_kr', 'ky_kg', 'lb_lu', 'lg_ug', 'ln_cd', 'lo_la', 'lt_lt', 'luo_ke', 'lv_lv', 'mi_nz', 'mk_mk', 'ml_in', 'mn_mn', 'mr_in', 'ms_my', 'mt_mt', 'my_mm', 'nb_no', 'ne_np', 'nl_nl', 'nso_za', 'ny_mw', 'oc_fr', 'om_et', 'or_in', 'pa_in', 'pl_pl', 'ps_af', 'pt_br', 'ro_ro', 'ru_ru', 'sd_in', 'sk_sk', 'sl_si', 'sn_zw', 'so_so', 'sr_rs', 'sv_se', 'sw_ke', 'ta_in', 'te_in', 'tg_tj', 'th_th', 'tr_tr', 'uk_ua', 'umb_ao', 'ur_pk', 'uz_uz', 'vi_vn', 'wo_sn', 'xh_za', 'yo_ng', 'yue_hant_hk', 'zu_za', 'all']\r\nExample of usage:\r\n\t`load_dataset('fleurs', 'af_za')`\r\n```\r\n\r\nNote the example of usage in the error message suggests loading \"fleurs\" instead of \"google\/fleurs\".","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6854\/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6854\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6853","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6853\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6853\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6853\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6853","id":2272570000,"node_id":"I_kwDODunzps6HdKqQ","number":6853,"title":"Support soft links for load_datasets imagefolder","user":{"login":"billytcl","id":10386511,"node_id":"MDQ6VXNlcjEwMzg2NTEx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/10386511?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/billytcl","html_url":"https:\/\/github.com\/billytcl","followers_url":"https:\/\/api.github.com\/users\/billytcl\/followers","following_url":"https:\/\/api.github.com\/users\/billytcl\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/billytcl\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/billytcl\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/billytcl\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/billytcl\/orgs","repos_url":"https:\/\/api.github.com\/users\/billytcl\/repos","events_url":"https:\/\/api.github.com\/users\/billytcl\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/billytcl\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-04-30T22:14:29Z","updated_at":"2024-04-30T22:14:29Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Feature request\n\nLoad_dataset from a folder of images doesn't seem to support soft links. It would be nice if it did, especially during methods development where image folders are being curated.\n\n### Motivation\n\nImages are coming from a complex variety of sources and we'd like to be able to soft link directly from the originating folders as opposed to copying. Having a copy of the file ensures that there may be issues with image versioning as well as having double the amount of required disk space.\n\n### Your contribution\n\nN\/A","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6853\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6853\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6852","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6852\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6852\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6852\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6852","id":2272465011,"node_id":"I_kwDODunzps6HcxBz","number":6852,"title":"Write token isn't working while pushing to datasets","user":{"login":"zaibutcooler","id":130903099,"node_id":"U_kgDOB81sOw","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/130903099?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/zaibutcooler","html_url":"https:\/\/github.com\/zaibutcooler","followers_url":"https:\/\/api.github.com\/users\/zaibutcooler\/followers","following_url":"https:\/\/api.github.com\/users\/zaibutcooler\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/zaibutcooler\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/zaibutcooler\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/zaibutcooler\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/zaibutcooler\/orgs","repos_url":"https:\/\/api.github.com\/users\/zaibutcooler\/repos","events_url":"https:\/\/api.github.com\/users\/zaibutcooler\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/zaibutcooler\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-04-30T21:18:20Z","updated_at":"2024-05-02T00:55:46Z","closed_at":"2024-05-02T00:55:46Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\n<img width=\"1001\" alt=\"Screenshot 2024-05-01 at 3 37 06 AM\" src=\"https:\/\/github.com\/huggingface\/datasets\/assets\/130903099\/00fcf12c-fcc1-4749-8592-d263d4efcbcc\">\r\n\r\nAs you can see I logged in to my account and the write token is valid.\r\n\r\nBut I can't upload on my main account and I am getting that error. It was okay on my test account at first try.\r\n\r\n(I refreshed the token, tried a new token but still doesn't work)\n\n### Steps to reproduce the bug\n\n1. I loaded a dataset.\r\n\r\n2. I logged in using both cli and huggingface_hub\r\n\r\n3. I pushed to my down dataset\r\n(It went well without any issues on my test account)\n\n### Expected behavior\n\nIt should have gone smoothly and this is not even my first time uploading to huggingface datasets\n\n### Environment info\n\ncolab, dataset (tried multiple versions)","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6852\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6852\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6851","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6851\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6851\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6851\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6851","id":2270965503,"node_id":"I_kwDODunzps6HXC7_","number":6851,"title":"load_dataset('emotion')    UnicodeDecodeError","user":{"login":"L-Block-C","id":32314558,"node_id":"MDQ6VXNlcjMyMzE0NTU4","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/32314558?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/L-Block-C","html_url":"https:\/\/github.com\/L-Block-C","followers_url":"https:\/\/api.github.com\/users\/L-Block-C\/followers","following_url":"https:\/\/api.github.com\/users\/L-Block-C\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/L-Block-C\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/L-Block-C\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/L-Block-C\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/L-Block-C\/orgs","repos_url":"https:\/\/api.github.com\/users\/L-Block-C\/repos","events_url":"https:\/\/api.github.com\/users\/L-Block-C\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/L-Block-C\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-04-30T09:25:01Z","updated_at":"2024-04-30T09:25:01Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\n**emotions = load_dataset('emotion')**\r\n\r\n_UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte_\n\n### Steps to reproduce the bug\n\nload_dataset('emotion') \n\n### Expected behavior\n\nsuccese\n\n### Environment info\n\npy3.10\r\ntransformers  4.41.0.dev0\r\ndatasets     2.19.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6851\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6851\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6850","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6850\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6850\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6850\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6850","id":2269500624,"node_id":"I_kwDODunzps6HRdTQ","number":6850,"title":"Problem loading voxpopuli dataset ","user":{"login":"Namangarg110","id":40496687,"node_id":"MDQ6VXNlcjQwNDk2Njg3","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/40496687?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Namangarg110","html_url":"https:\/\/github.com\/Namangarg110","followers_url":"https:\/\/api.github.com\/users\/Namangarg110\/followers","following_url":"https:\/\/api.github.com\/users\/Namangarg110\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Namangarg110\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Namangarg110\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Namangarg110\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Namangarg110\/orgs","repos_url":"https:\/\/api.github.com\/users\/Namangarg110\/repos","events_url":"https:\/\/api.github.com\/users\/Namangarg110\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Namangarg110\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"assignees":[{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":3,"created_at":"2024-04-29T16:46:51Z","updated_at":"2024-05-06T09:25:54Z","closed_at":"2024-05-06T09:25:54Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\n```\r\nException has occurred: FileNotFoundError\r\nCouldn't find file at https:\/\/huggingface.co\/datasets\/facebook\/voxpopuli\/resolve\/main\/{'en': 'data\/en\/asr_train.tsv'}\r\n```\r\n\r\nError in logic for link url creation. The link should be  https:\/\/huggingface.co\/datasets\/facebook\/voxpopuli\/resolve\/main\/data\/en\/asr_train.tsv \r\n\r\nBasically there should be links directly under ```metadata[\"train\"]```, not under ```metadata[\"train\"][self.config.languages[0]]```\r\n\r\nsame for audio urls\n\n### Steps to reproduce the bug\n\n```\r\nfrom datasets import load_dataset\r\n\r\ndataset = load_dataset(\"facebook\/voxpopuli\",\"en\")\r\n```\n\n### Expected behavior\n\nDataset should be loaded successfully.\n\n### Environment info\n\n- `datasets` version: 2.19.0\r\n- Platform: Linux-5.15.0-1041-aws-x86_64-with-glibc2.31\r\n- Python version: 3.10.13\r\n- `huggingface_hub` version: 0.22.2\r\n- PyArrow version: 16.0.0\r\n- Pandas version: 2.2.0\r\n- `fsspec` version: 2023.12.2","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6850\/reactions","total_count":2,"+1":2,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6850\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6849","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6849\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6849\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6849\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6849","id":2268718355,"node_id":"PR_kwDODunzps5t_wnu","number":6849,"title":"fix webdataset filename split","user":{"login":"Bowser1704","id":43539191,"node_id":"MDQ6VXNlcjQzNTM5MTkx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/43539191?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/Bowser1704","html_url":"https:\/\/github.com\/Bowser1704","followers_url":"https:\/\/api.github.com\/users\/Bowser1704\/followers","following_url":"https:\/\/api.github.com\/users\/Bowser1704\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/Bowser1704\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/Bowser1704\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/Bowser1704\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/Bowser1704\/orgs","repos_url":"https:\/\/api.github.com\/users\/Bowser1704\/repos","events_url":"https:\/\/api.github.com\/users\/Bowser1704\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/Bowser1704\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-04-29T10:57:18Z","updated_at":"2024-04-29T11:14:41Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6849","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6849","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6849.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6849.patch","merged_at":null},"body":"use `os.path.splitext` to parse field_name.\r\n\r\nfix filename which has dot. like:\r\n\r\n```\r\na.b.jpeg\r\na.b.txt\r\n```","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6849\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6849\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6848","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6848\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6848\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6848\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6848","id":2268622609,"node_id":"I_kwDODunzps6HOG8R","number":6848,"title":"Cant Downlaod Common Voice 17.0 hy-AM ","user":{"login":"mheryerznkanyan","id":31586104,"node_id":"MDQ6VXNlcjMxNTg2MTA0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/31586104?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/mheryerznkanyan","html_url":"https:\/\/github.com\/mheryerznkanyan","followers_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/followers","following_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/orgs","repos_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/repos","events_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/mheryerznkanyan\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-04-29T10:06:02Z","updated_at":"2024-05-13T06:09:30Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nI want to download Common Voice 17.0 hy-AM but it returns an error. \r\n```\r\n\r\nThe version_base parameter is not specified.\r\nPlease specify a compatability version level, or None.\r\nWill assume defaults for version 1.1\r\n  @hydra.main(config_name='hfds_config', config_path=None)\r\n\/usr\/local\/lib\/python3.10\/dist-packages\/hydra\/_internal\/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\r\nSee https:\/\/hydra.cc\/docs\/1.2\/upgrades\/1.1_to_1.2\/changes_to_job_working_dir\/ for more information.\r\n  ret = run_job(\r\n\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/load.py:1429: FutureWarning: The repository for mozilla-foundation\/common_voice_17_0 contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https:\/\/hf.co\/datasets\/mozilla-foundation\/common_voice_17_0\r\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\r\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\r\n  warnings.warn(\r\nReading metadata...: 6180it [00:00, 133224.37it\/s]les\/s]\r\nGenerating train split: 0 examples [00:00, ? examples\/s]\r\nHuggingFace datasets failed due to some reason (stack trace below).\r\nFor certain datasets (eg: MCV), it may be necessary to login to the huggingface-cli (via `huggingface-cli login`).\r\nOnce logged in, you need to set `use_auth_token=True` when calling this script.\r\n\r\nTraceback error for reference :\r\n\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1743, in _prepare_split_single\r\n    example = self.info.features.encode_example(record) if self.info.features is not None else record\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/features\/features.py\", line 1878, in encode_example\r\n    return encode_nested_example(self, example)\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/features\/features.py\", line 1243, in encode_nested_example\r\n    {\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/features\/features.py\", line 1243, in <dictcomp>\r\n    {\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/utils\/py_utils.py\", line 326, in zip_dict\r\n    yield key, tuple(d[key] for d in dicts)\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/utils\/py_utils.py\", line 326, in <genexpr>\r\n    yield key, tuple(d[key] for d in dicts)\r\nKeyError: 'sentence_id'\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/workspace\/nemo\/scripts\/speech_recognition\/convert_hf_dataset_to_nemo.py\", line 358, in main\r\n    dataset = load_dataset(\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/load.py\", line 2549, in load_dataset\r\n    builder_instance.download_and_prepare(\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1005, in download_and_prepare\r\n    self._download_and_prepare(\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1767, in _download_and_prepare\r\n    super()._download_and_prepare(\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1100, in _download_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1605, in _prepare_split\r\n    for job_id, done, content in self._prepare_split_single(\r\n  File \"\/usr\/local\/lib\/python3.10\/dist-packages\/datasets\/builder.py\", line 1762, in _prepare_split_single\r\n    raise DatasetGenerationError(\"An error occurred while generating the dataset\") from e\r\ndatasets.exceptions.DatasetGenerationError: An error occurred while generating the dataset\r\n```\r\n\r\n### Steps to reproduce the bug\r\n\r\n```\r\nfrom datasets import load_dataset\r\n\r\ncv_17 = load_dataset(\"mozilla-foundation\/common_voice_17_0\", \"hy-AM\")\r\n```\r\n\r\n### Expected behavior\r\n\r\nIt works fine with common_voice_16_1\r\n\r\n### Environment info\r\n\r\n- `datasets` version: 2.18.0\r\n- Platform: Linux-5.15.0-1042-nvidia-x86_64-with-glibc2.35\r\n- Python version: 3.11.6\r\n- `huggingface_hub` version: 0.22.2\r\n- PyArrow version: 15.0.2\r\n- Pandas version: 2.2.2\r\n- `fsspec` version: 2024.2.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6848\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6848\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6847","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6847\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6847\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6847\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6847","id":2268589177,"node_id":"I_kwDODunzps6HN-x5","number":6847,"title":"[Streaming] Only load requested splits without resolving files for the other splits","user":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false},"assignees":[{"login":"lhoestq","id":42851186,"node_id":"MDQ6VXNlcjQyODUxMTg2","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/42851186?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/lhoestq","html_url":"https:\/\/github.com\/lhoestq","followers_url":"https:\/\/api.github.com\/users\/lhoestq\/followers","following_url":"https:\/\/api.github.com\/users\/lhoestq\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/lhoestq\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/lhoestq\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/lhoestq\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/lhoestq\/orgs","repos_url":"https:\/\/api.github.com\/users\/lhoestq\/repos","events_url":"https:\/\/api.github.com\/users\/lhoestq\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/lhoestq\/received_events","type":"User","site_admin":false}],"milestone":null,"comments":2,"created_at":"2024-04-29T09:49:32Z","updated_at":"2024-05-07T04:43:59Z","closed_at":null,"author_association":"MEMBER","active_lock_reason":null,"draft":null,"pull_request":null,"body":"e.g. [thangvip](https:\/\/huggingface.co\/thangvip)\/[cosmopedia_vi_math](https:\/\/huggingface.co\/datasets\/thangvip\/cosmopedia_vi_math) has 300 splits and it takes a very long time to load only one split.\r\n\r\nThis is due to `load_dataset()` resolving the files of all the splits even if only one is needed.\r\n\r\nIn `dataset-viewer` the splits are loaded in different jobs so it results in 300 jobs that resolve 300 splits -> 90k calls to `\/paths-info`","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6847\/reactions","total_count":1,"+1":1,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6847\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6846","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6846\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6846\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6846\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6846","id":2267352120,"node_id":"I_kwDODunzps6HJQw4","number":6846,"title":"Unimaginable super slow iteration","user":{"login":"rangehow","id":88258534,"node_id":"MDQ6VXNlcjg4MjU4NTM0","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/88258534?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/rangehow","html_url":"https:\/\/github.com\/rangehow","followers_url":"https:\/\/api.github.com\/users\/rangehow\/followers","following_url":"https:\/\/api.github.com\/users\/rangehow\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/rangehow\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/rangehow\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/rangehow\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/rangehow\/orgs","repos_url":"https:\/\/api.github.com\/users\/rangehow\/repos","events_url":"https:\/\/api.github.com\/users\/rangehow\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/rangehow\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-04-28T05:24:14Z","updated_at":"2024-05-06T08:30:03Z","closed_at":"2024-05-06T08:30:03Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nAssuming there is a dataset with 52000 sentences, each with a length of 500, it takes 20 seconds to extract a sentence from the dataset\u2026\u2026\uff1fIs there something wrong with my iteration?\r\n\r\n### Steps to reproduce the bug\r\n\r\n```python\r\nimport datasets\r\nimport time\r\nimport random\r\n\r\nnum_rows = 52000\r\nnum_cols = 500\r\n\r\nrandom_input = [[random.randint(1, 100) for _ in range(num_cols)] for _ in range(num_rows)]\r\nrandom_output = [[random.randint(1, 100) for _ in range(num_cols)] for _ in range(num_rows)]\r\n\r\n\r\ns=time.time()\r\nd={'random_input':random_input,'random_output':random_output}\r\ndataset=datasets.Dataset.from_dict(d)\r\nprint('from dict',time.time()-s)\r\nprint(dataset)\r\n\r\n\r\nfor i in range(len(dataset)):\r\n    aa=time.time()\r\n    a,b=dataset['random_input'][i],dataset['random_output'][i]\r\n    print(time.time()-aa)\r\n\r\n```\r\n\r\ncorresponding output\r\n```bash\r\nfrom dict 9.215498685836792\r\nDataset({\r\n    features: ['random_input', 'random_output'],\r\n    num_rows: 52000\r\n})\r\n19.129778146743774\r\n19.329464197158813\r\n19.27668261528015\r\n19.28557538986206\r\n19.247620582580566\r\n19.624247074127197\r\n19.28673791885376\r\n19.301053047180176\r\n19.290496110916138\r\n19.291821718215942\r\n19.357765197753906\r\n\r\n```\r\n\r\n### Expected behavior\r\n\r\nUnder normal circumstances, iteration should be very rapid as it does not involve the main tasks other than getting items\r\n\r\n### Environment info\r\n\r\n- `datasets` version: 2.19.0\r\n- Platform: Linux-3.10.0-1160.71.1.el7.x86_64-x86_64-with-glibc2.17\r\n- Python version: 3.10.13\r\n- `huggingface_hub` version: 0.21.4\r\n- PyArrow version: 15.0.0\r\n- Pandas version: 2.2.1\r\n- `fsspec` version: 2024.2.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6846\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6846\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6845","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6845\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6845\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6845\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6845","id":2265876551,"node_id":"I_kwDODunzps6HDohH","number":6845,"title":"load_dataset doesn't support list column","user":{"login":"arthasking123","id":16257131,"node_id":"MDQ6VXNlcjE2MjU3MTMx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/16257131?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/arthasking123","html_url":"https:\/\/github.com\/arthasking123","followers_url":"https:\/\/api.github.com\/users\/arthasking123\/followers","following_url":"https:\/\/api.github.com\/users\/arthasking123\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/arthasking123\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/arthasking123\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/arthasking123\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/arthasking123\/orgs","repos_url":"https:\/\/api.github.com\/users\/arthasking123\/repos","events_url":"https:\/\/api.github.com\/users\/arthasking123\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/arthasking123\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":1,"created_at":"2024-04-26T14:11:44Z","updated_at":"2024-05-15T12:06:59Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\ndataset = load_dataset(\"Doraemon-AI\/text-to-neo4j-cypher-chinese\")\r\n\r\ngot exception:\r\nGenerating train split: 1834 examples [00:00, 5227.98 examples\/s]\r\nTraceback (most recent call last):\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/builder.py\", line 2011, in _prepare_split_single\r\n    writer.write_table(table)\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/arrow_writer.py\", line 585, in write_table\r\n    pa_table = table_cast(pa_table, self._schema)\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 2295, in table_cast\r\n    return cast_table_to_schema(table, schema)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 2254, in cast_table_to_schema\r\n    arrays = [cast_array_to_feature(table[name], feature) for name, feature in features.items()]\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 2254, in <listcomp>\r\n    arrays = [cast_array_to_feature(table[name], feature) for name, feature in features.items()]\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 1802, in wrapper\r\n    return pa.chunked_array([func(chunk, *args, **kwargs) for chunk in array.chunks])\r\n                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 1802, in <listcomp>\r\n    return pa.chunked_array([func(chunk, *args, **kwargs) for chunk in array.chunks])\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 2018, in cast_array_to_feature\r\n    casted_array_values = _c(array.values, feature[0])\r\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 1804, in wrapper\r\n    return func(array, *args, **kwargs)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/table.py\", line 2115, in cast_array_to_feature\r\n    raise TypeError(f\"Couldn't cast array of type\\n{array.type}\\nto\\n{feature}\")\r\nTypeError: Couldn't cast array of type\r\nstruct<m.name: string, x.name: string, p.name: string, n.name: string, h.name: string, name: string, c: int64, collect(r.name): list<item: string>, q.name: string, rel.name: string, count(p): int64, 1: int64, p.location: string, max(n.name): null, mn.name: string, p.time: int64, min(q.name): string>\r\nto\r\n{'q.name': Value(dtype='string', id=None), 'mn.name': Value(dtype='string', id=None), 'x.name': Value(dtype='string', id=None), 'p.name': Value(dtype='string', id=None), 'n.name': Value(dtype='string', id=None), 'name': Value(dtype='string', id=None), 'm.name': Value(dtype='string', id=None), 'h.name': Value(dtype='string', id=None), 'count(p)': Value(dtype='int64', id=None), 'rel.name': Value(dtype='string', id=None), 'c': Value(dtype='int64', id=None), 'collect(r.name)': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), '1': Value(dtype='int64', id=None), 'p.location': Value(dtype='string', id=None), 'substring(h.name,0,5)': Value(dtype='string', id=None), 'p.time': Value(dtype='int64', id=None)}\r\n\r\nThe above exception was the direct cause of the following exception:\r\n\r\nTraceback (most recent call last):\r\n  File \"\/home\/ubuntu\/llm\/train-2.py\", line 150, in <module>\r\n    dataset = load_dataset(\"Doraemon-AI\/text-to-neo4j-cypher-chinese\")\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/load.py\", line 2609, in load_dataset\r\n    builder_instance.download_and_prepare(\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/builder.py\", line 1027, in download_and_prepare\r\n    self._download_and_prepare(\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/builder.py\", line 1122, in _download_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/builder.py\", line 1882, in _prepare_split\r\n    for job_id, done, content in self._prepare_split_single(\r\n  File \"\/usr\/local\/lib\/python3.11\/dist-packages\/datasets\/builder.py\", line 2038, in _prepare_split_single\r\n    raise DatasetGenerationError(\"An error occurred while generating the dataset\") from e\r\ndatasets.exceptions.DatasetGenerationError: An error occurred while generating the dataset\n\n### Steps to reproduce the bug\n\ndataset = load_dataset(\"Doraemon-AI\/text-to-neo4j-cypher-chinese\")\r\n\n\n### Expected behavior\n\nno exception\n\n### Environment info\n\npython 3.11\r\ndatasets 2.19.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6845\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6845\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6844","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6844\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6844\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6844\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6844","id":2265870546,"node_id":"PR_kwDODunzps5t2PRA","number":6844,"title":"Retry on HF Hub error when streaming","user":{"login":"mariosasko","id":47462742,"node_id":"MDQ6VXNlcjQ3NDYyNzQy","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/47462742?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/mariosasko","html_url":"https:\/\/github.com\/mariosasko","followers_url":"https:\/\/api.github.com\/users\/mariosasko\/followers","following_url":"https:\/\/api.github.com\/users\/mariosasko\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/mariosasko\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/mariosasko\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/mariosasko\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/mariosasko\/orgs","repos_url":"https:\/\/api.github.com\/users\/mariosasko\/repos","events_url":"https:\/\/api.github.com\/users\/mariosasko\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/mariosasko\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-04-26T14:09:04Z","updated_at":"2024-04-26T15:37:42Z","closed_at":"2024-04-26T15:37:42Z","author_association":"COLLABORATOR","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6844","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6844","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6844.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6844.patch","merged_at":null},"body":"Retry on the `huggingface_hub`'s `HfHubHTTPError` in the streaming mode.\r\n\r\nFix #6843 ","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6844\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6844\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6843","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6843\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6843\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6843\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6843","id":2265432897,"node_id":"I_kwDODunzps6HB8NB","number":6843,"title":"IterableDataset raises exception instead of retrying","user":{"login":"bauwenst","id":145220868,"node_id":"U_kgDOCKflBA","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/145220868?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/bauwenst","html_url":"https:\/\/github.com\/bauwenst","followers_url":"https:\/\/api.github.com\/users\/bauwenst\/followers","following_url":"https:\/\/api.github.com\/users\/bauwenst\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/bauwenst\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/bauwenst\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/bauwenst\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/bauwenst\/orgs","repos_url":"https:\/\/api.github.com\/users\/bauwenst\/repos","events_url":"https:\/\/api.github.com\/users\/bauwenst\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/bauwenst\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":5,"created_at":"2024-04-26T10:00:43Z","updated_at":"2024-04-30T13:14:13Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\r\n\r\nIn light of the recent server outages, I decided to look into whether I could somehow wrap my IterableDataset streams to retry rather than error out immediately. To my surprise, `datasets` [already supports retries](https:\/\/github.com\/huggingface\/datasets\/issues\/6172#issuecomment-1794876229). Since a commit by @lhoestq [last week](https:\/\/github.com\/huggingface\/datasets\/commit\/a188022dc43a76a119d90c03832d51d6e4a94d91), that code lives here:\r\n\r\nhttps:\/\/github.com\/huggingface\/datasets\/blob\/fe2bea6a4b09b180bd23b88fe96dfd1a11191a4f\/src\/datasets\/utils\/file_utils.py#L1097C1-L1111C19\r\n\r\nIf GitHub code snippets still aren't working, here's a copy:\r\n```python\r\n    def read_with_retries(*args, **kwargs):\r\n        disconnect_err = None\r\n        for retry in range(1, max_retries + 1):\r\n            try:\r\n                out = read(*args, **kwargs)\r\n                break\r\n            except (ClientError, TimeoutError) as err:\r\n                disconnect_err = err\r\n                logger.warning(\r\n                    f\"Got disconnected from remote data host. Retrying in {config.STREAMING_READ_RETRY_INTERVAL}sec [{retry}\/{max_retries}]\"\r\n                )\r\n                time.sleep(config.STREAMING_READ_RETRY_INTERVAL)\r\n        else:\r\n            raise ConnectionError(\"Server Disconnected\") from disconnect_err\r\n        return out\r\n```\r\n\r\nWith the latest outage, the end of my stack trace looked like this:\r\n```\r\n...\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/site-packages\/datasets\/download\/streaming_download_manager.py\", line 342, in read_with_retries\r\n    out = read(*args, **kwargs)\r\n          ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/gzip.py\", line 301, in read\r\n    return self._buffer.read(size)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/_compression.py\", line 68, in readinto\r\n    data = self.read(len(byte_view))\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/gzip.py\", line 505, in read\r\n    buf = self._fp.read(io.DEFAULT_BUFFER_SIZE)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/gzip.py\", line 88, in read\r\n    return self.file.read(size)\r\n           ^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/site-packages\/fsspec\/spec.py\", line 1856, in read\r\n    out = self.cache._fetch(self.loc, self.loc + length)\r\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/site-packages\/fsspec\/caching.py\", line 189, in _fetch\r\n    self.cache = self.fetcher(start, end)  # new block replaces old\r\n                 ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/site-packages\/huggingface_hub\/hf_file_system.py\", line 626, in _fetch_range\r\n    hf_raise_for_status(r)\r\n  File \"\/miniconda3\/envs\/draft\/lib\/python3.11\/site-packages\/huggingface_hub\/utils\/_errors.py\", line 333, in hf_raise_for_status\r\n    raise HfHubHTTPError(str(e), response=response) from e\r\nhuggingface_hub.utils._errors.HfHubHTTPError: 504 Server Error: Gateway Time-out for url: https:\/\/huggingface.co\/datasets\/allenai\/c4\/resolve\/1588ec454efa1a09f29cd18ddd04fe05fc8653a2\/en\/c4-train.00346-of-01024.json.gz\r\n```\r\n\r\nIndeed, the code for retries only catches `ClientError`s and `TimeoutError`s, and all other exceptions, *including HuggingFace's own custom HTTP error class*, **are not caught. Nothing is retried,** and instead the exception is propagated upwards immediately.\r\n\r\n### Steps to reproduce the bug\r\n\r\nNot sure how you reproduce this. Maybe unplug your Ethernet cable while streaming a dataset; the issue is pretty clear from the stack trace.\r\n\r\n### Expected behavior\r\n\r\nAll HTTP errors while iterating a streamable dataset should cause retries.\r\n\r\n### Environment info\r\n\r\nOutput from `datasets-cli env`:\r\n- `datasets` version: 2.18.0\r\n- Platform: Linux-4.18.0-513.24.1.el8_9.x86_64-x86_64-with-glibc2.28\r\n- Python version: 3.11.7\r\n- `huggingface_hub` version: 0.20.3\r\n- PyArrow version: 15.0.0\r\n- Pandas version: 2.2.0\r\n- `fsspec` version: 2023.10.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6843\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6843\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6842","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6842\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6842\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6842\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6842","id":2264692159,"node_id":"I_kwDODunzps6G_HW_","number":6842,"title":"Datasets with files with colon : in filenames cannot be used on Windows","user":{"login":"jacobjennings","id":1038927,"node_id":"MDQ6VXNlcjEwMzg5Mjc=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/1038927?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/jacobjennings","html_url":"https:\/\/github.com\/jacobjennings","followers_url":"https:\/\/api.github.com\/users\/jacobjennings\/followers","following_url":"https:\/\/api.github.com\/users\/jacobjennings\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/jacobjennings\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/jacobjennings\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/jacobjennings\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/jacobjennings\/orgs","repos_url":"https:\/\/api.github.com\/users\/jacobjennings\/repos","events_url":"https:\/\/api.github.com\/users\/jacobjennings\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/jacobjennings\/received_events","type":"User","site_admin":false},"labels":[],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-04-26T00:14:16Z","updated_at":"2024-04-26T00:14:16Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nDatasets (such as https:\/\/huggingface.co\/datasets\/MLCommons\/peoples_speech) cannot be used on Windows due to the fact that windows does not allow colons \":\" in filenames. These should be converted into alternative strings.\r\n\r\n\n\n### Steps to reproduce the bug\n\n1. Attempt to run load_dataset on MLCommons\/peoples_speech\n\n### Expected behavior\n\nDoes not crash during extraction\n\n### Environment info\n\nWindows 11, NTFS filesystem, Python 3.12\r\n","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6842\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6842\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6841","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6841\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6841\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6841\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6841","id":2264687683,"node_id":"I_kwDODunzps6G_GRD","number":6841,"title":"Unable to load wiki_auto_asset_turk from GEM","user":{"login":"abhinavsethy","id":23074600,"node_id":"MDQ6VXNlcjIzMDc0NjAw","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/23074600?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/abhinavsethy","html_url":"https:\/\/github.com\/abhinavsethy","followers_url":"https:\/\/api.github.com\/users\/abhinavsethy\/followers","following_url":"https:\/\/api.github.com\/users\/abhinavsethy\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/abhinavsethy\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/abhinavsethy\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/abhinavsethy\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/abhinavsethy\/orgs","repos_url":"https:\/\/api.github.com\/users\/abhinavsethy\/repos","events_url":"https:\/\/api.github.com\/users\/abhinavsethy\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/abhinavsethy\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":8,"created_at":"2024-04-26T00:08:47Z","updated_at":"2024-05-29T13:54:03Z","closed_at":"2024-04-26T16:12:29Z","author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Describe the bug\n\nI am unable to load the wiki_auto_asset_turk dataset. I get a fatal error while trying to access wiki_auto_asset_turk and load it with datasets.load_dataset. The error (TypeError: expected str, bytes or os.PathLike object, not NoneType) is from filenames_for_dataset_split in a os.path.join call \r\n\r\n\r\n>>import datasets\r\n>>print (datasets.__version__)\r\n>>dataset = datasets.load_dataset(\"GEM\/wiki_auto_asset_turk\")\r\n\r\nSystem output:\r\n\r\nGenerating train split: 100%|\u2588| 483801\/483801 [00:03<00:00, 127164.26 examples\/s\r\nGenerating validation split: 100%|\u2588| 20000\/20000 [00:00<00:00, 116052.94 example\r\nGenerating test_asset split: 100%|\u2588\u2588| 359\/359 [00:00<00:00, 76155.93 examples\/s]\r\nGenerating test_turk split: 100%|\u2588\u2588\u2588| 359\/359 [00:00<00:00, 87691.76 examples\/s]\r\nTraceback (most recent call last):\r\n  File \"\/Users\/abhinav.sethy\/Code\/openai_evals\/evals\/evals\/grammarly_tasks\/gem_sari.py\", line 3, in <module>\r\n    dataset = datasets.load_dataset(\"GEM\/wiki_auto_asset_turk\")\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/load.py\", line 2582, in load_dataset\r\n    builder_instance.download_and_prepare(\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1005, in download_and_prepare\r\n    self._download_and_prepare(\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1767, in _download_and_prepare\r\n    super()._download_and_prepare(\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1100, in _download_and_prepare\r\n    self._prepare_split(split_generator, **prepare_split_kwargs)\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/builder.py\", line 1565, in _prepare_split\r\n    split_info = self.info.splits[split_generator.name]\r\n                 ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/splits.py\", line 532, in __getitem__\r\n    instructions = make_file_instructions(\r\n                   ^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/arrow_reader.py\", line 121, in make_file_instructions\r\n    info.name: filenames_for_dataset_split(\r\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"\/Library\/Frameworks\/Python.framework\/Versions\/3.12\/lib\/python3.12\/site-packages\/datasets\/naming.py\", line 72, in filenames_for_dataset_split\r\n    prefix = os.path.join(path, prefix)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"<frozen posixpath>\", line 76, in join\r\nTypeError: expected str, bytes or os.PathLike object, not NoneType\n\n### Steps to reproduce the bug\n\nimport datasets\r\nprint (datasets.__version__)\r\ndataset = datasets.load_dataset(\"GEM\/wiki_auto_asset_turk\")\r\n\n\n### Expected behavior\n\nShould be able to load the dataset without any issues\n\n### Environment info\n\ndatasets version 2.18.0 (was able to reproduce bug with older versions 2.16 and 2.14 also)\r\nPython 3.12.0","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6841\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6841\/timeline","performed_via_github_app":null,"state_reason":"completed"}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6840","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6840\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6840\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6840\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/issues\/6840","id":2264604766,"node_id":"I_kwDODunzps6G-yBe","number":6840,"title":"Delete uploaded files from the UI","user":{"login":"saicharan2804","id":62512681,"node_id":"MDQ6VXNlcjYyNTEyNjgx","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/62512681?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/saicharan2804","html_url":"https:\/\/github.com\/saicharan2804","followers_url":"https:\/\/api.github.com\/users\/saicharan2804\/followers","following_url":"https:\/\/api.github.com\/users\/saicharan2804\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/saicharan2804\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/saicharan2804\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/saicharan2804\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/saicharan2804\/orgs","repos_url":"https:\/\/api.github.com\/users\/saicharan2804\/repos","events_url":"https:\/\/api.github.com\/users\/saicharan2804\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/saicharan2804\/received_events","type":"User","site_admin":false},"labels":[{"id":1935892871,"node_id":"MDU6TGFiZWwxOTM1ODkyODcx","url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/labels\/enhancement","name":"enhancement","color":"a2eeef","default":true,"description":"New feature or request"}],"state":"open","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":0,"created_at":"2024-04-25T22:33:57Z","updated_at":"2024-04-25T22:33:57Z","closed_at":null,"author_association":"NONE","active_lock_reason":null,"draft":null,"pull_request":null,"body":"### Feature request\n\nOnce a file is uploaded and the commit is made, I am unable to delete individual files without completely deleting the whole dataset via the website UI.\n\n### Motivation\n\nWould be a useful addition\n\n### Your contribution\n\nWould love to help out with some guidance","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6840\/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6840\/timeline","performed_via_github_app":null,"state_reason":null}
{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6839","repository_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets","labels_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6839\/labels{\/name}","comments_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6839\/comments","events_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6839\/events","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6839","id":2263761062,"node_id":"PR_kwDODunzps5tvC1c","number":6839,"title":"Remove token arg from CLI examples","user":{"login":"albertvillanova","id":8515462,"node_id":"MDQ6VXNlcjg1MTU0NjI=","avatar_url":"https:\/\/avatars.githubusercontent.com\/u\/8515462?v=4","gravatar_id":"","url":"https:\/\/api.github.com\/users\/albertvillanova","html_url":"https:\/\/github.com\/albertvillanova","followers_url":"https:\/\/api.github.com\/users\/albertvillanova\/followers","following_url":"https:\/\/api.github.com\/users\/albertvillanova\/following{\/other_user}","gists_url":"https:\/\/api.github.com\/users\/albertvillanova\/gists{\/gist_id}","starred_url":"https:\/\/api.github.com\/users\/albertvillanova\/starred{\/owner}{\/repo}","subscriptions_url":"https:\/\/api.github.com\/users\/albertvillanova\/subscriptions","organizations_url":"https:\/\/api.github.com\/users\/albertvillanova\/orgs","repos_url":"https:\/\/api.github.com\/users\/albertvillanova\/repos","events_url":"https:\/\/api.github.com\/users\/albertvillanova\/events{\/privacy}","received_events_url":"https:\/\/api.github.com\/users\/albertvillanova\/received_events","type":"User","site_admin":false},"labels":[],"state":"closed","locked":false,"assignee":null,"assignees":[],"milestone":null,"comments":2,"created_at":"2024-04-25T14:36:58Z","updated_at":"2024-04-26T17:03:51Z","closed_at":"2024-04-26T16:57:40Z","author_association":"MEMBER","active_lock_reason":null,"draft":false,"pull_request":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/pulls\/6839","html_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6839","diff_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6839.diff","patch_url":"https:\/\/github.com\/huggingface\/datasets\/pull\/6839.patch","merged_at":"2024-04-26T16:57:40Z"},"body":"Remove token arg from CLI examples.\r\n\r\nFix #6838.\r\n\r\nCC: @Wauplin ","reactions":{"url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6839\/reactions","total_count":1,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":1,"rocket":0,"eyes":0},"timeline_url":"https:\/\/api.github.com\/repos\/huggingface\/datasets\/issues\/6839\/timeline","performed_via_github_app":null,"state_reason":null}
