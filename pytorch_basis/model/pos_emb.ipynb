{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "41f8de94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from typing import Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "60ba22e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 8\n",
    "model_dim = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8c7292a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "position = torch.arange(seq_len)\n",
    "position.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "a5ff4f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_i = torch.arange(0, model_dim, 2)\n",
    "even_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "36e67c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_i = torch.arange(1, model_dim, 2)\n",
    "odd_i.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0e9d5ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_pe = torch.cos(torch.outer(position, 1.0 / (10000 ** (odd_i / model_dim))))\n",
    "odd_pe.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "891146da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 3])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_pe = torch.sin(torch.outer(position, 1.0 / (10000 ** (even_i / model_dim))))\n",
    "even_pe.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "bc798745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 1.0000, 1.0000],\n",
       "        [0.9769, 0.9999, 1.0000],\n",
       "        [0.9086, 0.9998, 1.0000],\n",
       "        [0.7983, 0.9996, 1.0000],\n",
       "        [0.6511, 0.9992, 1.0000],\n",
       "        [0.4738, 0.9988, 1.0000],\n",
       "        [0.2746, 0.9982, 1.0000],\n",
       "        [0.0627, 0.9976, 1.0000]])"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odd_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "b290f901",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000],\n",
       "        [ 0.8415,  0.0464,  0.0022],\n",
       "        [ 0.9093,  0.0927,  0.0043],\n",
       "        [ 0.1411,  0.1388,  0.0065],\n",
       "        [-0.7568,  0.1846,  0.0086],\n",
       "        [-0.9589,  0.2300,  0.0108],\n",
       "        [-0.2794,  0.2749,  0.0129],\n",
       "        [ 0.6570,  0.3192,  0.0151]])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "even_pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "1b832780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000],\n",
       "         [ 0.0000,  1.0000]],\n",
       "\n",
       "        [[ 0.8415,  0.9769],\n",
       "         [ 0.0464,  0.9999],\n",
       "         [ 0.0022,  1.0000]],\n",
       "\n",
       "        [[ 0.9093,  0.9086],\n",
       "         [ 0.0927,  0.9998],\n",
       "         [ 0.0043,  1.0000]],\n",
       "\n",
       "        [[ 0.1411,  0.7983],\n",
       "         [ 0.1388,  0.9996],\n",
       "         [ 0.0065,  1.0000]],\n",
       "\n",
       "        [[-0.7568,  0.6511],\n",
       "         [ 0.1846,  0.9992],\n",
       "         [ 0.0086,  1.0000]],\n",
       "\n",
       "        [[-0.9589,  0.4738],\n",
       "         [ 0.2300,  0.9988],\n",
       "         [ 0.0108,  1.0000]],\n",
       "\n",
       "        [[-0.2794,  0.2746],\n",
       "         [ 0.2749,  0.9982],\n",
       "         [ 0.0129,  1.0000]],\n",
       "\n",
       "        [[ 0.6570,  0.0627],\n",
       "         [ 0.3192,  0.9976],\n",
       "         [ 0.0151,  1.0000]]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked = torch.stack([even_pe, odd_pe], dim=2)\n",
    "stacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "947ae870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000,  0.0000,  1.0000],\n",
       "        [ 0.8415,  0.9769,  0.0464,  0.9999,  0.0022,  1.0000],\n",
       "        [ 0.9093,  0.9086,  0.0927,  0.9998,  0.0043,  1.0000],\n",
       "        [ 0.1411,  0.7983,  0.1388,  0.9996,  0.0065,  1.0000],\n",
       "        [-0.7568,  0.6511,  0.1846,  0.9992,  0.0086,  1.0000],\n",
       "        [-0.9589,  0.4738,  0.2300,  0.9988,  0.0108,  1.0000],\n",
       "        [-0.2794,  0.2746,  0.2749,  0.9982,  0.0129,  1.0000],\n",
       "        [ 0.6570,  0.0627,  0.3192,  0.9976,  0.0151,  1.0000]])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe = torch.flatten(stacked, start_dim=1, end_dim=2)\n",
    "pe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "5625e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_freqs_cis(dim: int, end: int, theta: float = 10000.0):\n",
    "    \"\"\"\n",
    "    Precompute the frequency tensor for complex exponentials (cis) with given dimensions.\n",
    "\n",
    "    This function calculates a frequency tensor with complex exponentials using the given dimension 'dim'\n",
    "    and the end index 'end'. The 'theta' parameter scales the frequencies.\n",
    "    The returned tensor contains complex values in complex64 data type.\n",
    "\n",
    "    Args:\n",
    "        dim (int): Dimension of the frequency tensor.\n",
    "        end (int): End index for precomputing frequencies.\n",
    "        theta (float, optional): Scaling factor for frequency computation. Defaults to 10000.0.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Precomputed frequency tensor with complex exponentials.\n",
    "\n",
    "    \n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    freqs = 1.0 / (theta ** (torch.arange(0, dim, 2)[: (dim // 2)].float() / dim))\n",
    "    t = torch.arange(end, device=freqs.device)  # type: ignore\n",
    "    freqs = torch.outer(t, freqs).float()  # type: ignore\n",
    "    freqs_cis = torch.polar(torch.ones_like(freqs), freqs)  # complex64\n",
    "    return freqs_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "a71def60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs_cis = precompute_freqs_cis(6, 4)\n",
    "freqs_cis.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "b29d8af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_for_broadcast(freqs_cis: torch.Tensor, x: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Reshape frequency tensor for broadcasting it with another tensor.\n",
    "\n",
    "    This function reshapes the frequency tensor to have the same shape as the target tensor 'x'\n",
    "    for the purpose of broadcasting the frequency tensor during element-wise operations.\n",
    "\n",
    "    Args:\n",
    "        freqs_cis (torch.Tensor): Frequency tensor to be reshaped.\n",
    "        x (torch.Tensor): Target tensor for broadcasting compatibility.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: Reshaped frequency tensor.\n",
    "\n",
    "    Raises:\n",
    "        AssertionError: If the frequency tensor doesn't match the expected shape.\n",
    "        AssertionError: If the target tensor 'x' doesn't have the expected number of dimensions.\n",
    "    \"\"\"\n",
    "    print(\"freqs_cis before:\",freqs_cis.shape)\n",
    "    ndim = x.ndim\n",
    "    assert 0 <= 1 < ndim\n",
    "    assert freqs_cis.shape == (x.shape[1], x.shape[-1])\n",
    "    print(\"x.shape: \",x.shape)\n",
    "    shape = [d if i == 1 or i == ndim - 1 else 1 for i, d in enumerate(x.shape)]\n",
    "    print(\"after:\",shape)\n",
    "    return freqs_cis.view(*shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "2da21da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rotary_emb(\n",
    "    xq: torch.Tensor,\n",
    "    xk: torch.Tensor,\n",
    "    freqs_cis: torch.Tensor,\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Apply rotary embeddings to input tensors using the given frequency tensor.\n",
    "\n",
    "    This function applies rotary embeddings to the given query 'xq' and key 'xk' tensors using the provided\n",
    "    frequency tensor 'freqs_cis'. The input tensors are reshaped as complex numbers, and the frequency tensor\n",
    "    is reshaped for broadcasting compatibility. The resulting tensors contain rotary embeddings and are\n",
    "    returned as real tensors.\n",
    "\n",
    "    Args:\n",
    "        xq (torch.Tensor): Query tensor to apply rotary embeddings.\n",
    "        xk (torch.Tensor): Key tensor to apply rotary embeddings.\n",
    "        freqs_cis (torch.Tensor): Precomputed frequency tensor for complex exponentials.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[torch.Tensor, torch.Tensor]: Tuple of modified query tensor and key tensor with rotary embeddings.\n",
    "\n",
    "        \n",
    "\n",
    "    \"\"\"\n",
    "    print(\"xq reshape:\",xq.float().reshape(*xq.shape[:-1], -1, 2).shape)\n",
    "    xq_ = torch.view_as_complex(xq.float().reshape(*xq.shape[:-1], -1, 2))\n",
    "    print(\"xq_.shape:\",xq_.shape)\n",
    "    xk_ = torch.view_as_complex(xk.float().reshape(*xk.shape[:-1], -1, 2))\n",
    "    print(\"xk_.shape:\",xk_.shape)\n",
    "    freqs_cis = reshape_for_broadcast(freqs_cis, xq_)\n",
    "    print(\"freqs_cis.shape:\",freqs_cis.shape)\n",
    "    xq_out = torch.view_as_real(xq_ * freqs_cis).flatten(3)\n",
    "    xk_out = torch.view_as_real(xk_ * freqs_cis).flatten(3)\n",
    "    print(\"xq_out,xk_out shape:\",xq_out.shape,xk_out.shape)\n",
    "    return xq_out.type_as(xq), xk_out.type_as(xk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "c69faccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.+2.j, 3.+4.j])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1.0, 2.0],\n",
    "                  [3.0, 4.0]])  # shape [2, 2]\n",
    "torch.view_as_complex(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "107b248b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xq reshape: torch.Size([1, 4, 2, 3, 2])\n",
      "xq_.shape: torch.Size([1, 4, 2, 3])\n",
      "xk_.shape: torch.Size([1, 4, 2, 3])\n",
      "freqs_cis before: torch.Size([4, 3])\n",
      "x.shape:  torch.Size([1, 4, 2, 3])\n",
      "after: [1, 4, 1, 3]\n",
      "freqs_cis.shape: torch.Size([1, 4, 1, 3])\n",
      "xq_out,xk_out shape: torch.Size([1, 4, 2, 6]) torch.Size([1, 4, 2, 6])\n"
     ]
    }
   ],
   "source": [
    "# (batch_size, seq_len, num_heads, head_dim)\n",
    "xq = torch.randn(1,4,2,6)\n",
    "xk = torch.randn(1,4,2,6)\n",
    "xq,xk = apply_rotary_emb(xq,xk,freqs_cis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
