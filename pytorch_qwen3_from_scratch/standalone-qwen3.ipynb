{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6191328",
   "metadata": {},
   "source": [
    "[standalone-qwen3.ipynb](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/11_qwen3/standalone-qwen3.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "38951f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface_hub version: 0.30.1\n",
      "tokenizers version: 0.21.1\n",
      "torch version: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "pkg = [\n",
    "    'huggingface_hub',\n",
    "    'tokenizers',\n",
    "    'torch'\n",
    "]\n",
    "for p in pkg:\n",
    "    print(f\"{p} version: {version(p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7534e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_BASE_MODEL = False\n",
    "USE_RESONING_MODEL = True\n",
    "USE_INSTRUCT_MODEL = False\n",
    "\n",
    "if (USE_BASE_MODEL + USE_RESONING_MODEL + USE_INSTRUCT_MODEL) != 1:\n",
    "    raise ValueError(\"Exactly one of USE_BASE_MODEL, USE_RESONING_MODEL, or USE_INSTRUCT_MODEL must be True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b9ee8f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(cfg[\"emb_dim\"],cfg[\"hidden_dim\"],dtype=cfg[\"dtype\"],bias=False)\n",
    "        self.fc2 = nn.Linear(cfg[\"emb_dim\"],cfg[\"hidden_dim\"],dtype=cfg[\"dtype\"],bias=False)\n",
    "        self.fc3 = nn.Linear(cfg[\"hidden_dim\"],cfg[\"emb_dim\"],dtype=cfg[\"dtype\"],bias=False)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x)\n",
    "        x = nn.functional.silu(x_fc1) * x_fc2\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4a9d62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RMSNorm(nn.Module):\n",
    "    def __init__(self,emb_dim,eps=1e-6,bias=False,qwen3_compatible=True):\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.qwen3_compatible = qwen3_compatible\n",
    "        self.scale = nn.Parameter(torch.one(emb_dim))\n",
    "        self.shift = nn.Parameter(torch.zeros(emb_dim)) if bias else None\n",
    "\n",
    "    def forward(self,x):\n",
    "        input_dtype = x.dtype\n",
    "\n",
    "        if self.qwen3_compatible:\n",
    "            x = x.to(torch.float32)\n",
    "        \n",
    "        variance = x.pow(2).mean(dim=-1,keepdim=True)\n",
    "        norm_x = x * torch.rsqrt(variance + self.eps)\n",
    "        norm_x = norm_x * self.scale\n",
    "\n",
    "        if self.shift is not None:\n",
    "            norm_x = norm_x * self.shift\n",
    "        \n",
    "        return norm_x.to(input_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "21743bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6., 8.], dtype=torch.float16)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtype = torch.float16\n",
    "theta_base=10_000\n",
    "head_dim = 10\n",
    "\n",
    "torch.arange(0, head_dim, 2, dtype=dtype)\n",
    "#inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
    "#inv_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5eb920c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positions: tensor([[0.0000e+00],\n",
      "        [1.0000e+00],\n",
      "        [2.0000e+00],\n",
      "        ...,\n",
      "        [4.0920e+03],\n",
      "        [4.0940e+03],\n",
      "        [4.0960e+03]], dtype=torch.float16) torch.Size([4096, 1])\n",
      "inv_freq: tensor([[1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04]]) torch.Size([1, 5])\n",
      "rope: tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [1.0000e+00, 1.5849e-01, 2.5119e-02, 3.9811e-03, 6.3096e-04],\n",
      "        [2.0000e+00, 3.1698e-01, 5.0238e-02, 7.9621e-03, 1.2619e-03],\n",
      "        ...,\n",
      "        [4.0920e+03, 6.4854e+02, 1.0279e+02, 1.6291e+01, 2.5819e+00],\n",
      "        [4.0940e+03, 6.4886e+02, 1.0284e+02, 1.6299e+01, 2.5831e+00],\n",
      "        [4.0960e+03, 6.4917e+02, 1.0289e+02, 1.6306e+01, 2.5844e+00]]) torch.Size([4096, 5])\n"
     ]
    }
   ],
   "source": [
    "context_length=4096\n",
    "theta_base=10_000\n",
    "head_dim=10\n",
    "inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
    "positions = torch.arange(context_length, dtype=dtype)\n",
    "print(\"positions:\",positions.unsqueeze(1),positions.unsqueeze(1).shape)   \n",
    "print(\"inv_freq:\",inv_freq.unsqueeze(0),inv_freq.unsqueeze(0).shape)\n",
    "print(\"rope:\",positions.unsqueeze(1) * inv_freq.unsqueeze(0),(positions.unsqueeze(1) * inv_freq.unsqueeze(0)).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff3ed2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rope_params(head_dim, theta_base=10_000, context_length=4096, dtype=torch.float32):\n",
    "    assert head_dim % 2 == 0, \"Embedding dimension must be even\"\n",
    "\n",
    "    # Compute the inverse frequencies\n",
    "    inv_freq = 1.0 / (theta_base ** (torch.arange(0, head_dim, 2, dtype=dtype)[: (head_dim // 2)].float() / head_dim))\n",
    "\n",
    "    # Generate position indices\n",
    "    positions = torch.arange(context_length, dtype=dtype)\n",
    "\n",
    "    # Compute the angles\n",
    "    angles = positions.unsqueeze(1) * inv_freq.unsqueeze(0)  # Shape: (context_length, head_dim // 2)\n",
    "\n",
    "    # Expand angles to match the head_dim\n",
    "    angles = torch.cat([angles, angles], dim=1)  # Shape: (context_length, head_dim)\n",
    "\n",
    "    # Precompute sine and cosine\n",
    "    cos = torch.cos(angles)\n",
    "    sin = torch.sin(angles)\n",
    "\n",
    "    return cos, sin\n",
    "\n",
    "\n",
    "def apply_rope(x, cos, sin):\n",
    "    # x: (batch_size, num_heads, seq_len, head_dim)\n",
    "    batch_size, num_heads, seq_len, head_dim = x.shape\n",
    "    assert head_dim % 2 == 0, \"Head dimension must be even\"\n",
    "\n",
    "    # Split x into first half and second half\n",
    "    x1 = x[..., : head_dim // 2]  # First half\n",
    "    x2 = x[..., head_dim // 2 :]  # Second half\n",
    "\n",
    "    # Adjust sin and cos shapes\n",
    "    cos = cos[:seq_len, :].unsqueeze(0).unsqueeze(0)  # Shape: (1, 1, seq_len, head_dim)\n",
    "    sin = sin[:seq_len, :].unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # Apply the rotary transformation\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    x_rotated = (x * cos) + (rotated * sin)\n",
    "\n",
    "    # It's ok to use lower-precision after applying cos and sin rotation\n",
    "    return x_rotated.to(dtype=x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bedc7a3",
   "metadata": {},
   "source": [
    "这段代码对应的公式可以理解为用同一组角度生成余弦和正弦两个分量，从而把原本只有 head_dim/2 个角度扩展到 head_dim 维度：\n",
    "\n",
    "原始 angles：由 positions 与逆频率相乘得到，形状为 (context_length, head_dim/2)，对应旋转嵌入中的基本角度 θ.\n",
    "\n",
    "torch.cat([angles, angles], dim=1)：把同样的角度矩阵在列方向上拼接两次，相当于得到 [θ, θ]。在后续计算中，一半会用于 cos(θ)，另一半会用于 sin(θ)，从而配合二维旋转公式：\n",
    "\n",
    "[x_even’, x_odd’] = [x_even * cos(θ) - x_odd * sin(θ), \n",
    "                     x_even * sin(θ) + x_odd * cos(θ)]\n",
    "这个拼接确保准备好的角度矩阵与头维度 (head_dim) 匹配，使每个偶数和奇数通道都能得到对应的 θ。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24f0b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupedQueryAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,d_in,num_heads,num_kv_groups,head_dim=None,qk_norm=False,dtype=None      \n",
    "    ):\n",
    "        super().__init__()\n",
    "        assert num_heads % num_kv_groups == 0,\"num_heads must be divisble by num_by_groups\"\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        self.num_kv_groups = num_kv_groups\n",
    "        self.group_size = num_heads // num_kv_groups\n",
    "\n",
    "        if head_dim is None:\n",
    "            assert d_in % num_heads == 0 , \"`d_in` must be divisible by `num_heads` if `head_dim` is not set\"\n",
    "            head_dim = d_in // num_heads\n",
    "        \n",
    "        self.head_dim = head_dim\n",
    "        self.d_out = num_heads * head_dim\n",
    "\n",
    "        self.W_query = nn.Linear(d_in,self.d_out,bias=False,dtype=dtype)\n",
    "        self.W_key = nn.Linear(d_in,num_kv_groups*head_dim,bias=False,dtype=dtype)\n",
    "        self.W_value = nn.Linear(d_in,num_kv_groups*head_dim,bias=False,dtype=dtype)\n",
    "\n",
    "        self.out_proj = nn.Linear(self.d_out,d_in,bias=False,dtype=dtype)\n",
    "\n",
    "        if qk_norm:\n",
    "            self.q_norm = RMSNorm(head_dim,eps=1e-6)\n",
    "            self.k_norm = RMSNorm(head_dim,eps=1e-6)\n",
    "        else:\n",
    "            self.q_norm = self.k_norm = None\n",
    "\n",
    "    def forward(self,x,mask,cos,sin):\n",
    "        b,num_tokens,_ = x.shape\n",
    "\n",
    "        queries = self.W_query(x)\n",
    "        keys = self.W_key(x)\n",
    "        values = self.W_value(x)\n",
    "\n",
    "        queries = queries.view(b,num_tokens,self.num_heads,self.head_dim).transpose(1,2)\n",
    "        keys = keys.view(b,num_tokens,self.num_kv_groups,self.head_dim).transpose(1,2)\n",
    "        values = values.view(b,num_tokens,self.num_kv_groups,self.head_dim).transpose(1,2)\n",
    "\n",
    "        if self.q_norm:\n",
    "            queries = self.q_norm(queries)\n",
    "        if self.k_norm:\n",
    "            keys = self.k_norm(keys)\n",
    "\n",
    "        queries = apply_rope(queries,cos,sin)\n",
    "        keys = apply_rope(keys,cos,sin)\n",
    "\n",
    "        keys = keys.repeat_interleave(self.group_size,dim=1)\n",
    "        values = values.repeat_interleave(self.group_size,dim=1)\n",
    "\n",
    "        attn_scores = queries @ keys.transpose(2,3)\n",
    "        attn_scores = attn_scores.masked_fill(mask,-torch.inf)\n",
    "        attn_weights = torch.softmax(attn_scores / self.head_dim**0.5,dim=-1)\n",
    "\n",
    "        context = (attn_weights @ values).transpose(1,2).reshape(b,num_tokens,self.d_out)\n",
    "        return self.out_proj(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f4b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self,cfg):\n",
    "        super().__init__()\n",
    "        self.att = GroupedQueryAttention(\n",
    "            d_in=cfg[\"emb_dim\"],\n",
    "            num_heads=cfg[\"n_heads\"],\n",
    "            head_dim=cfg[\"head_dim\"]\n",
    "            num_kv_groups=cfg[\"num_kv_groups\"],\n",
    "            qk_norm=cfg[\"qk_norm\"],\n",
    "            dtype=cfg[\"dtype\"]                                                             \n",
    "        )\n",
    "        self.ff = FeedForward(cfg)\n",
    "        self.norm1 = RMSNorm(cfg[\"emb_dim\"],eps=1e-6)\n",
    "        self.norm2 = RMSNorm(cfg[\"emb_dim\"],eps=1e-6)\n",
    "\n",
    "    def forward(self,x,mask,cos,sin):\n",
    "        shortcut = x \n",
    "        x = self.norm1(x)\n",
    "        x = self.att(x,mask,cos,sin)\n",
    "        x = x + shortcut\n",
    "\n",
    "\n",
    "        shortcut = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ff(x)\n",
    "        x = x + shortcut\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e32753",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c68c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd7eee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202366e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542e2033",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
